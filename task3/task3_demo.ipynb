{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from data_generation import *\n",
    "import glob\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Hyperparameters search for omp\n",
    "\n",
    "##* Data Generation\n",
    "##* N (columns of dictionary) = 10k\n",
    "##* d (dimension of signal) = 300, 600, 900, 1200, 1500, 2000\n",
    "##* X_{ij} \\sim N(0, \\frac{1}{n}) (The same as N(0,1) them normalize)\n",
    "##* m (sparse level) = 20, 40, 80\n",
    "\n",
    "##* Noise level = 0.01, 0.05, 0.1, 0.2, 0.5\n",
    "\n",
    "N = 1000\n",
    "d = 400\n",
    "m = 40\n",
    "noise_level_lst = [0, 0.01, 0.05, 0.1, 0.2, 0.5]\n",
    "trial_num = 10\n",
    "cv_num = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##! Task 1: Given signal, dictionary, sparsity level and noise level, use testset (10% of the whole signal) to find the best K(depth) for omp\n",
    "\n",
    "\n",
    "\n",
    "seed = 0\n",
    "Data_Geneartor = GaussianDataGenerator(N, d, m, 0.05, seed)\n",
    "\n",
    "true_signal, dictionary, true_indices, true_coefficients, perturbed_signal = Data_Geneartor.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_split(true_signal, dictionary, cv_num):\n",
    "    true_signal = true_signal.ravel()\n",
    "    # true_signal is (1200, 1) and dictionary is (1200, 10000), cv both signal and dictionary by rows\n",
    "    cv_signal = np.split(true_signal, cv_num)\n",
    "    cv_dictionary = np.split(dictionary, cv_num)\n",
    "    # Get the list of train and test set\n",
    "    cv_res = []\n",
    "    for i in range(cv_num):\n",
    "        train_signal = np.concatenate(cv_signal[:i] + cv_signal[i + 1:], axis = 0)\n",
    "        train_dictionary = np.concatenate(cv_dictionary[:i] + cv_dictionary[i + 1:], axis=0)\n",
    "        test_signal = cv_signal[i]\n",
    "        test_dictionary = cv_dictionary[i]\n",
    "        cv_res.append((train_signal, train_dictionary, test_signal, test_dictionary))\n",
    "    return cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a OMP class to do the cross validation and it need a fit and score function\n",
    "\n",
    "# ? The algorithm is not optimized, it is just for a quick demonstration\n",
    "def cal_cv_error(algorithm, cv_num, signal, dictionary):\n",
    "    cv_res = cv_split(signal, dictionary, cv_num)\n",
    "    error_lst = []\n",
    "    for i in range(cv_num):\n",
    "        train_signal, train_dictionary, test_signal, test_dictionary = cv_res[i]\n",
    "        algorithm.fit(train_signal, train_dictionary)\n",
    "        error_lst.append(algorithm.score(test_signal, test_dictionary))\n",
    "    return np.mean(error_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0030546505329837265"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from algorithms import OMP\n",
    "\n",
    "cal_cv_error(OMP(10), 10, perturbed_signal, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.003184988568140968,\n",
       " 12,\n",
       " [0.0038866347899150014,\n",
       "  0.0036206407258789425,\n",
       "  0.003516773507850524,\n",
       "  0.003529572080913495,\n",
       "  0.0033409991742988305,\n",
       "  0.003184988568140968,\n",
       "  0.0032837326742993986,\n",
       "  0.0033955533098516434,\n",
       "  0.0033193742131390125,\n",
       "  0.0033919112519604786])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##! Task 2: Relationship between best K and noise level (std)\n",
    "\n",
    "##! Task 3: Relationship between Test Error and noise level (std)\n",
    "\n",
    "# Choose the best K for each noise level\n",
    "\n",
    "def cv_best_K(signal, dictionary, cv_num, K_lst):\n",
    "    K_cv_error = []\n",
    "    for K in K_lst:\n",
    "        OMP_tmp = OMP(K, ignore_warning=True)\n",
    "        K_cv_error.append(cal_cv_error(OMP_tmp, cv_num, signal, dictionary))\n",
    "    lowest_error = np.min(K_cv_error)\n",
    "    lowest_error_K = K_lst[np.argmin(K_cv_error)]\n",
    "    return lowest_error, lowest_error_K, K_cv_error\n",
    "\n",
    "cv_best_K(perturbed_signal, dictionary, 5, np.arange(2, 22, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improvement: Save the result to a file\n",
    "\n",
    "if not os.path.exists('./memory'):\n",
    "    os.mkdir('./memory')\n",
    "\n",
    "def cv_best_K_noise_level_multi_trial(N, d, m, noise_level_lst, cv_num, K_lst, trial_num, output_filename = None):\n",
    "    if output_filename is None:\n",
    "        output_filename = str(N) + '_' + str(d) + '_' + str(m) + '_' + str(trial_num) + '_' + str(cv_num) + '.pkl'\n",
    "    res_log = {\n",
    "        'parameters': {'N': N, 'd': d, 'm': m, 'noise_level_lst': noise_level_lst, 'cv_num': cv_num, 'trial_num': trial_num, 'K_lst': K_lst},\n",
    "        'noise_level_best_K': [],\n",
    "        'noise_level_lowest_MSE': [],\n",
    "        'log': []\n",
    "    }\n",
    "    noise_level_best_K = []\n",
    "    noise_level_lowest_MSE = []\n",
    "    for noise_level in noise_level_lst:\n",
    "        print(\"Cross validating K under noise level: \", noise_level)\n",
    "        trials_best_K_tmp = []\n",
    "        MSE_loweset_K_temp = []\n",
    "        for trial in range(trial_num):\n",
    "            Data_Geneartor = GaussianDataGenerator(N, d, m, noise_level, trial)\n",
    "            true_signal, dictionary, true_indices, true_coefficients, perturbed_signal = Data_Geneartor.shuffle()\n",
    "            lowest_error, lowest_error_K, cv_err_lst = cv_best_K(perturbed_signal, dictionary, cv_num, K_lst)\n",
    "            trials_best_K_tmp.append(lowest_error_K)\n",
    "            MSE_loweset_K_temp.append(lowest_error)\n",
    "            print(\"Trial: \", trial, \" Best K: \", lowest_error_K, \" Lowest Error: \", lowest_error)\n",
    "            log_tmp = {'noise_level': noise_level, 'trial': trial, 'data': Data_Geneartor, 'cv_error_lst': cv_err_lst, \n",
    "                       'lowest_error': lowest_error, 'lowest_error_K': lowest_error_K}\n",
    "            res_log['log'].append(log_tmp)\n",
    "        noise_level_best_K.append(np.mean(trials_best_K_tmp))\n",
    "        noise_level_lowest_MSE.append(np.mean(MSE_loweset_K_temp))\n",
    "        print(\"Average best K for noise level: \", noise_level, \" is: \", np.mean(trials_best_K_tmp), \" with MSE: \", np.mean(MSE_loweset_K_temp))\n",
    "    res_log['noise_level_best_K'] = noise_level_best_K\n",
    "    res_log['noise_level_lowest_MSE'] = noise_level_lowest_MSE\n",
    "    with open('./memory/' + output_filename, 'wb') as f:\n",
    "        pkl.dump(res_log, f)\n",
    "    print(\"Finished!\")\n",
    "    print(\"Log file saved to: \", './memory/' + output_filename)\n",
    "    return noise_level_best_K, noise_level_lowest_MSE, res_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if it is working\n",
    "# N = 1000\n",
    "# d = 500\n",
    "# m = 20\n",
    "# noise_level_lst = [0, 0.01, 0.05, 0.1, 0.2, 0.3]\n",
    "# trial_num = 5\n",
    "# # ? Maybe we need to increase the trial number  \n",
    "# cv_num = 5\n",
    "# # ? Is cv necessary? \n",
    "\n",
    "# noise_level_best_K, noise_level_lowest_MSE, res_log = cv_best_K_noise_level_multi_trial(N, d, m, noise_level_lst, cv_num, np.arange(1, 41, 1), trial_num, 'test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(noise_level_lst, noise_level_best_K)\n",
    "# plt.xlabel(\"Noise std\")\n",
    "# plt.ylabel(\"Best iteration number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(noise_level_lst, noise_level_lowest_MSE)\n",
    "# plt.xlabel(\"Noise std\")\n",
    "# plt.ylabel(\"CV prediction error for best K\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract noise level, trial, cv_error_lst from res_log\n",
    "\n",
    "# tmp = []\n",
    "# for i in range(len(res_log)):\n",
    "#     tmp.append([res_log[i]['noise_level'], res_log[i]['trial'], res_log[i]['cv_error_lst']])\n",
    "    \n",
    "# K_lst = np.arange(1, 41, 1).tolist()\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# # Plot the cv error for each K for each noise level\n",
    "# for i in range(len(tmp)):    \n",
    "#     if i % trial_num == 0:\n",
    "#         label = tmp[i][0]\n",
    "#     else:\n",
    "#         label = \"\"\n",
    "#     # Assign color to different noise level\n",
    "#     plt.plot(K_lst, tmp[i][2], label = label, color = plt.cm.Set2_r(i // trial_num))\n",
    "\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "# ax.get_legend().set_title(\"Noise std\")\n",
    "\n",
    "# plt.ylim([0, 0.01])\n",
    "\n",
    "# plt.xlabel(\"Iteration number\")\n",
    "# plt.ylabel(\"CV prediction error\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be working, testing with the following parameters:\n",
    "\n",
    "$$X \\in \\mathbb{R}^{n\\times p}$$\n",
    "$$p = 10000$$\n",
    "$$n = 300, 600, 900, 1200, 1500, 2000$$\n",
    "$$|\\beta|_0 = 20, 40, 80$$\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating K under noise level:  0\n",
      "Trial:  0  Best K:  41  Lowest Error:  1.0322818556519273e-33\n",
      "Trial:  1  Best K:  43  Lowest Error:  1.0038216363882612e-33\n",
      "Trial:  2  Best K:  40  Lowest Error:  1.1319008700903495e-33\n",
      "Trial:  3  Best K:  40  Lowest Error:  1.0429802737126707e-33\n",
      "Trial:  4  Best K:  42  Lowest Error:  1.2637811519537758e-33\n",
      "Average best K for noise level:  0  is:  41.2  with MSE:  1.094953157559397e-33\n",
      "Cross validating K under noise level:  0.01\n",
      "Trial:  0  Best K:  34  Lowest Error:  0.0001130748313154001\n",
      "Trial:  1  Best K:  35  Lowest Error:  9.980621765503768e-05\n",
      "Trial:  2  Best K:  55  Lowest Error:  0.0001109718238620182\n",
      "Trial:  3  Best K:  32  Lowest Error:  0.00010435679596586744\n",
      "Trial:  4  Best K:  27  Lowest Error:  0.00011557388908519266\n",
      "Average best K for noise level:  0.01  is:  36.6  with MSE:  0.0001087567115767032\n",
      "Cross validating K under noise level:  0.05\n",
      "Trial:  0  Best K:  28  Lowest Error:  0.0029047179922214355\n",
      "Trial:  1  Best K:  35  Lowest Error:  0.0023727832036476446\n",
      "Trial:  2  Best K:  36  Lowest Error:  0.002479309862392242\n",
      "Trial:  3  Best K:  45  Lowest Error:  0.0025039512671126843\n",
      "Trial:  4  Best K:  45  Lowest Error:  0.0027796387668272476\n",
      "Average best K for noise level:  0.05  is:  37.8  with MSE:  0.0026080802184402507\n",
      "Cross validating K under noise level:  0.1\n",
      "Trial:  0  Best K:  9  Lowest Error:  0.010899070877372005\n",
      "Trial:  1  Best K:  33  Lowest Error:  0.008796831153856457\n",
      "Trial:  2  Best K:  22  Lowest Error:  0.010121236484965452\n",
      "Trial:  3  Best K:  8  Lowest Error:  0.010245874713682613\n",
      "Trial:  4  Best K:  16  Lowest Error:  0.010904795285708226\n",
      "Average best K for noise level:  0.1  is:  17.6  with MSE:  0.010193561703116952\n",
      "Cross validating K under noise level:  0.2\n",
      "Trial:  0  Best K:  4  Lowest Error:  0.04270335529547694\n",
      "Trial:  1  Best K:  34  Lowest Error:  0.03626994130468169\n",
      "Trial:  2  Best K:  59  Lowest Error:  0.03697083743258013\n",
      "Trial:  3  Best K:  40  Lowest Error:  0.03655554291054217\n",
      "Trial:  4  Best K:  34  Lowest Error:  0.04082463036927334\n",
      "Average best K for noise level:  0.2  is:  34.2  with MSE:  0.03866486146251085\n",
      "Cross validating K under noise level:  0.3\n",
      "Trial:  0  Best K:  3  Lowest Error:  0.09521394079683551\n",
      "Trial:  1  Best K:  21  Lowest Error:  0.08106070194750525\n",
      "Trial:  2  Best K:  29  Lowest Error:  0.08438212606229938\n",
      "Trial:  3  Best K:  33  Lowest Error:  0.08598972999417773\n",
      "Trial:  4  Best K:  46  Lowest Error:  0.09200191293918777\n",
      "Average best K for noise level:  0.3  is:  26.4  with MSE:  0.08772968234800113\n",
      "Cross validating K under noise level:  0.4\n",
      "Trial:  0  Best K:  3  Lowest Error:  0.16823769737058597\n",
      "Trial:  1  Best K:  23  Lowest Error:  0.13949718315617235\n",
      "Trial:  2  Best K:  35  Lowest Error:  0.15070669166384043\n",
      "Trial:  3  Best K:  27  Lowest Error:  0.1525923102615751\n",
      "Trial:  4  Best K:  56  Lowest Error:  0.164588267578553\n",
      "Average best K for noise level:  0.4  is:  28.8  with MSE:  0.1551244300061454\n",
      "Cross validating K under noise level:  0.5\n",
      "Trial:  0  Best K:  3  Lowest Error:  0.2620436341686063\n",
      "Trial:  1  Best K:  43  Lowest Error:  0.22032700852376444\n",
      "Trial:  2  Best K:  7  Lowest Error:  0.2453015391992258\n",
      "Trial:  3  Best K:  31  Lowest Error:  0.2381390553458617\n",
      "Trial:  4  Best K:  25  Lowest Error:  0.2570369841153216\n",
      "Average best K for noise level:  0.5  is:  21.8  with MSE:  0.24456964427055597\n",
      "Finished!\n",
      "Log file saved to:  ./memory/10000_1200_40_5_5.pkl\n"
     ]
    }
   ],
   "source": [
    "N = 10000\n",
    "d = 1200\n",
    "m = 40\n",
    "noise_level_lst = [0, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "trial_num = 5\n",
    "cv_num = 5\n",
    "K_lst = np.arange(1, m+20+1, 1).tolist()\n",
    "\n",
    "noise_level_best_K, noise_level_lowest_MSE, res_log = cv_best_K_noise_level_multi_trial(N, d, m, noise_level_lst, cv_num, K_lst, trial_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeplots(res_log, savefig = True):\n",
    "    if not os.path.exists('./images'):\n",
    "        os.makedirs('./images')\n",
    "        \n",
    "    # res_log can either be a object name or path to the file\n",
    "    if isinstance(res_log, str):\n",
    "        path = os.path.join('./memory/', res_log)\n",
    "        with open(path, 'rb') as f:\n",
    "            res_log = pkl.load(f)\n",
    "    \n",
    "    # Extract parameters\n",
    "    parameters = res_log['parameters']\n",
    "    noise_level_best_K = res_log['noise_level_best_K']\n",
    "    noise_level_lowest_MSE = res_log['noise_level_lowest_MSE']\n",
    "    \n",
    "    K_lst = parameters['K_lst']\n",
    "    trial_num = res_log['parameters']['trial_num']\n",
    "    print('Parameters: ', parameters)\n",
    "    \n",
    "    # Get folder name for saving images\n",
    "    imgfolderPath = str(parameters['N']) + '_' + str(parameters['d']) + '_' + str(parameters['m']) + '_' + str(parameters['trial_num']) + '_' + str(parameters['cv_num'])\n",
    "    if savefig:\n",
    "        if not os.path.exists('./images/' + imgfolderPath):\n",
    "            os.makedirs('./images/' + imgfolderPath)\n",
    "    \n",
    "    # Generate plots\n",
    "    ## First plot: Iteration number vs. CV prediction error for each noise level\n",
    "    noise_level_lst = parameters['noise_level_lst']\n",
    "    tmp = []\n",
    "    for i in range(len(res_log['log'])):\n",
    "        tmp.append([res_log['log'][i]['noise_level'], res_log['log'][i]['trial'], res_log['log'][i]['cv_error_lst']])\n",
    "    fig, ax = plt.subplots()\n",
    "    # Plot the cv error for each K for each noise level\n",
    "    for i in range(len(tmp)):    \n",
    "        if i % trial_num == 0:\n",
    "            label = tmp[i][0]\n",
    "        else:\n",
    "            label = \"\"\n",
    "        # Assign color to different noise level\n",
    "        plt.plot(K_lst, tmp[i][2], label = label, color = plt.cm.Set2_r(i // trial_num))\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "    ax.get_legend().set_title(\"Noise std\")\n",
    "    plt.ylim([0, 0.5])\n",
    "    \n",
    "    plt.xlabel(\"Iteration number\")\n",
    "    plt.ylabel(\"CV prediction error\")\n",
    "    plt.title(\"CV prediction error for each noise level\\n n = \" + str(parameters['d']) + \", p = \" + str(parameters['N'])+ \", m = \" + str(parameters['m'])) \n",
    "    if savefig:\n",
    "        plt.savefig('./images/' + imgfolderPath + '/cv_error.png', dpi=200, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    ## Second plot: Noise std vs. best iteration number\n",
    "    plt.plot(noise_level_lst, noise_level_best_K)\n",
    "    plt.title(\"Best iteration number for each noise level\\n n = \" + str(parameters['d']) + \", p = \" + str(parameters['N'])+ \", m = \" + str(parameters['m']))\n",
    "    plt.xlabel(\"Noise std\")\n",
    "    plt.ylabel(\"Best iteration number\")\n",
    "    if savefig:\n",
    "        plt.savefig('./images/' + imgfolderPath + '/noise_vs_bestK.png', dpi=200, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    ## Third plot: Noise std vs. CV prediction error for best iteration number\n",
    "    plt.plot(noise_level_lst, noise_level_lowest_MSE)\n",
    "    plt.xlabel(\"Noise std\")\n",
    "    plt.ylabel(\"CV prediction error for best K\")\n",
    "    plt.title(\"CV prediction error for best iteration number for each noise level\\n n = \" + str(parameters['d']) + \", p = \" + str(parameters['N']) + \", m = \" + str(parameters['m']))\n",
    "    if savefig:\n",
    "        plt.savefig('./images/' + imgfolderPath + '/noise_vs_bestMSE.png', dpi=200, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/songtengyu/Documents/Projects/2023summer/Projection_Pursuit_Summer/task3/task3_demo.ipynb Cell 16\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/songtengyu/Documents/Projects/2023summer/Projection_Pursuit_Summer/task3/task3_demo.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m makeplots(res_log, savefig \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32m/Users/songtengyu/Documents/Projects/2023summer/Projection_Pursuit_Summer/task3/task3_demo.ipynb Cell 16\u001b[0m in \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/songtengyu/Documents/Projects/2023summer/Projection_Pursuit_Summer/task3/task3_demo.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         res_log \u001b[39m=\u001b[39m pkl\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/songtengyu/Documents/Projects/2023summer/Projection_Pursuit_Summer/task3/task3_demo.ipynb#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Extract parameters\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/songtengyu/Documents/Projects/2023summer/Projection_Pursuit_Summer/task3/task3_demo.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m parameters \u001b[39m=\u001b[39m res_log[\u001b[39m'\u001b[39;49m\u001b[39mparameters\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/songtengyu/Documents/Projects/2023summer/Projection_Pursuit_Summer/task3/task3_demo.ipynb#X21sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m noise_level_best_K \u001b[39m=\u001b[39m res_log[\u001b[39m'\u001b[39m\u001b[39mnoise_level_best_K\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/songtengyu/Documents/Projects/2023summer/Projection_Pursuit_Summer/task3/task3_demo.ipynb#X21sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m noise_level_lowest_MSE \u001b[39m=\u001b[39m res_log[\u001b[39m'\u001b[39m\u001b[39mnoise_level_lowest_MSE\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "makeplots(res_log, savefig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotting all the results\n",
    "# pkl_files = glob.glob(\"memory/*.pkl\")\n",
    "# parameter_dict_list = []\n",
    "# for i in range(len(pkl_files)):\n",
    "#     with open(pkl_files[i], 'rb') as f:\n",
    "#         tmp = pkl.load(f)\n",
    "#     makeplots(tmp, savefig = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intersting Phenomenon:\n",
    "1. Best CV error almost equals to the square of noise_level"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
