{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import product\n",
    "from datetime import datetime\n",
    "import json\n",
    "import hashlib\n",
    "import os\n",
    "from algorithms import OMP_Augmented\n",
    "from data_generation import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_params(config):\n",
    "    OMP_arg_lst = [\"K_lst\", \"select_atom_percent\", \"random_seed\",\"ignore_warning\"]\n",
    "    all_params = config[\"MODEL\"]\n",
    "    param_grid = {}\n",
    "    fixed_params = {}\n",
    "\n",
    "    Bag_lst = all_params[\"Bag_lst\"]\n",
    "    K_lst = all_params[\"K_lst\"]\n",
    "\n",
    "    del all_params[\"Bag_lst\"]\n",
    "    del all_params[\"K_lst\"]\n",
    "\n",
    "    for param, value in all_params.items():\n",
    "        if param in OMP_arg_lst:\n",
    "            if isinstance(value, list):\n",
    "                param_grid[param] = value\n",
    "            else:\n",
    "                fixed_params[param] = value\n",
    "\n",
    "    fixed_params[\"K_lst\"] = K_lst\n",
    "    return fixed_params, param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"configs/BOMP_300_500_10_nr_0721.yaml\"\n",
    "\n",
    "with open(path, \"r\") as path:\n",
    "    configs = yaml.load(path, Loader=yaml.FullLoader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MODEL': {'Bag_lst': [1, 100, 200, 300, 400, 500],\n",
       "  'K_lst': [1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148,\n",
       "   149,\n",
       "   150,\n",
       "   151,\n",
       "   152,\n",
       "   153,\n",
       "   154,\n",
       "   155,\n",
       "   156,\n",
       "   157,\n",
       "   158,\n",
       "   159,\n",
       "   160,\n",
       "   161,\n",
       "   162,\n",
       "   163,\n",
       "   164,\n",
       "   165,\n",
       "   166,\n",
       "   167,\n",
       "   168,\n",
       "   169,\n",
       "   170],\n",
       "  'agg_func': 'weight',\n",
       "  'atom_bag_percent': [0.5, 0.7, 0.8, 0.9],\n",
       "  'ignore_warning': True,\n",
       "  'random_seed': 1,\n",
       "  'replace_flag': False,\n",
       "  'select_atom_percent': 0,\n",
       "  'signal_bag_percent': [0.7, 0.8, 0.9]},\n",
       " 'TEST': {'cv_num': 5,\n",
       "  'm': 10,\n",
       "  'model': 'BOMP',\n",
       "  'n': 300,\n",
       "  'noise_levels': [0.12, 0.14, 0.16, 0.18, 0.2],\n",
       "  'p': 500,\n",
       "  'trial_num': 10},\n",
       " 'filename': 'BOMP_300_500_10_nr_0721.yaml',\n",
       " 'output_path': 'memory/0721/'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tmp = configs[\"TEST\"][\"n\"]\n",
    "p_tmp = configs[\"TEST\"][\"p\"]\n",
    "m_tmp = configs[\"TEST\"][\"m\"]\n",
    "noise_level_lst = configs[\"TEST\"][\"noise_levels\"]\n",
    "model_name = configs[\"TEST\"][\"model\"]\n",
    "cv_num = configs[\"TEST\"][\"cv_num\"]\n",
    "trial_num = configs[\"TEST\"][\"trial_num\"]\n",
    "\n",
    "# Get n, p, m, noise_level combinations\n",
    "if not isinstance(n_tmp, list):\n",
    "    n_tmp = [n_tmp]\n",
    "if not isinstance(p_tmp, list):\n",
    "    p_tmp = [p_tmp]\n",
    "if not isinstance(m_tmp, list):\n",
    "    m_tmp = [m_tmp]\n",
    "\n",
    "npm_lst = list(product(n_tmp, p_tmp, m_tmp))\n",
    "\n",
    "if not isinstance(noise_level_lst, list):\n",
    "    noise_level_lst = [noise_level_lst]\n",
    "\n",
    "# Get model parameters\n",
    "fixed_params, param_grid = get_model_params(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ignore_warning': True,\n",
       " 'random_seed': 1,\n",
       " 'select_atom_percent': 0,\n",
       " 'K_lst': [1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  53,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  59,\n",
       "  60,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  73,\n",
       "  74,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  94,\n",
       "  95,\n",
       "  96,\n",
       "  97,\n",
       "  98,\n",
       "  99,\n",
       "  100,\n",
       "  101,\n",
       "  102,\n",
       "  103,\n",
       "  104,\n",
       "  105,\n",
       "  106,\n",
       "  107,\n",
       "  108,\n",
       "  109,\n",
       "  110,\n",
       "  111,\n",
       "  112,\n",
       "  113,\n",
       "  114,\n",
       "  115,\n",
       "  116,\n",
       "  117,\n",
       "  118,\n",
       "  119,\n",
       "  120,\n",
       "  121,\n",
       "  122,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  126,\n",
       "  127,\n",
       "  128,\n",
       "  129,\n",
       "  130,\n",
       "  131,\n",
       "  132,\n",
       "  133,\n",
       "  134,\n",
       "  135,\n",
       "  136,\n",
       "  137,\n",
       "  138,\n",
       "  139,\n",
       "  140,\n",
       "  141,\n",
       "  142,\n",
       "  143,\n",
       "  144,\n",
       "  145,\n",
       "  146,\n",
       "  147,\n",
       "  148,\n",
       "  149,\n",
       "  150,\n",
       "  151,\n",
       "  152,\n",
       "  153,\n",
       "  154,\n",
       "  155,\n",
       "  156,\n",
       "  157,\n",
       "  158,\n",
       "  159,\n",
       "  160,\n",
       "  161,\n",
       "  162,\n",
       "  163,\n",
       "  164,\n",
       "  165,\n",
       "  166,\n",
       "  167,\n",
       "  168,\n",
       "  169,\n",
       "  170]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.12, 0.14, 0.16, 0.18, 0.2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_level_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = n_tmp[0]\n",
    "p = p_tmp[0]\n",
    "m = m_tmp[0]\n",
    "\n",
    "noise_level = 0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OMP_Augmented(**fixed_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_id = 1\n",
    "Data_Geneartor = GaussianDataGenerator(p, n, m, noise_level, trial_id)\n",
    "(\n",
    "    true_signal,\n",
    "    dictionary,\n",
    "    true_indices,\n",
    "    true_coefficients,\n",
    "    perturbed_signal,\n",
    ") = Data_Geneartor.shuffle()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dictionary, perturbed_signal, test_size=0.2, random_state=trial_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.02963101,  0.06034284, -0.01860876, -0.04080628,  0.01250148,\n",
       "        -0.01356313,  0.00942813, -0.07214399,  0.0250147 , -0.01157247,\n",
       "         0.0088984 , -0.02773164,  0.07344428, -0.12257993, -0.0129917 ,\n",
       "         0.03183239, -0.05303426,  0.02887242, -0.02819892,  0.0155397 ,\n",
       "        -0.06475611,  0.09352532, -0.01602831,  0.01976662, -0.01759588,\n",
       "        -0.11666707,  0.00459419, -0.05259657, -0.08866643, -0.11682676,\n",
       "        -0.0056279 ,  0.0113685 ,  0.05684153, -0.03253778, -0.0676847 ,\n",
       "         0.08133003,  0.02002691,  0.00436147,  0.01796147,  0.04667126,\n",
       "        -0.00418362, -0.06299868,  0.03320004,  0.02114957,  0.06720135,\n",
       "         0.11071086,  0.04379502, -0.07310846, -0.01963151, -0.03518139,\n",
       "        -0.01792364, -0.0101306 ,  0.06017013,  0.02726948,  0.02964775,\n",
       "        -0.06853595,  0.02934064, -0.03059471,  0.01288256, -0.11219385,\n",
       "         0.02385188, -0.0525922 ,  0.00199547, -0.04378006,  0.01695887,\n",
       "         0.0322783 , -0.04450347,  0.03605178,  0.03059394, -0.04313323,\n",
       "        -0.0134277 , -0.00472011,  0.0266385 ,  0.06940897,  0.02403584,\n",
       "        -0.02252383, -0.00926362, -0.11178171, -0.05846505,  0.12313565,\n",
       "         0.04107361,  0.01756044,  0.08438661, -0.00640891, -0.03383149,\n",
       "        -0.0659973 , -0.03238196,  0.04614875,  0.06602998, -0.08145365,\n",
       "        -0.01797146, -0.08996418,  0.03929502, -0.01046868,  0.02823425,\n",
       "         0.04095151,  0.02596918,  0.00226196,  0.02850551, -0.02371335,\n",
       "        -0.03130948,  0.03983557, -0.07677204, -0.06818367,  0.00706274,\n",
       "        -0.02556098, -0.04419525, -0.05861672, -0.03374353, -0.03831113,\n",
       "        -0.04678069, -0.04619474, -0.06659741,  0.07271946, -0.07672715,\n",
       "         0.03017608,  0.03807991,  0.04269738,  0.02531977,  0.0235661 ,\n",
       "         0.04233219,  0.0284547 , -0.01177264, -0.00577414,  0.114867  ,\n",
       "         0.00070827,  0.07188818, -0.02179765,  0.04161918,  0.07741225,\n",
       "        -0.09033165, -0.05266604,  0.00723213, -0.03903557,  0.00679673,\n",
       "         0.02637365, -0.01436627,  0.04090609, -0.0494845 , -0.09757297,\n",
       "        -0.02709325,  0.03648296, -0.03712665,  0.07675354,  0.0150677 ,\n",
       "         0.05010076, -0.02942304,  0.13281498,  0.05152885,  0.02193327,\n",
       "         0.04662841,  0.04553874,  0.01278989,  0.06190194,  0.00068149,\n",
       "         0.03231925,  0.02742672, -0.03256859,  0.06039708, -0.04339722,\n",
       "        -0.00937805, -0.03718895,  0.03470104, -0.02271261, -0.0353377 ,\n",
       "        -0.02555423,  0.0174389 , -0.10134773,  0.02360073,  0.0044786 ,\n",
       "         0.01036493, -0.02988037,  0.01057594,  0.04341321,  0.04994331,\n",
       "         0.00094415, -0.01574662,  0.02236885, -0.06290977, -0.01900461,\n",
       "         0.06715808, -0.04289403, -0.02762303, -0.03035096, -0.0073447 ,\n",
       "         0.02616367, -0.00049263,  0.02543745, -0.03198716, -0.10690928,\n",
       "        -0.03969263, -0.06505283,  0.13513416, -0.05493651,  0.0281726 ,\n",
       "        -0.00066017, -0.03519473,  0.03253592,  0.05672416, -0.11768136,\n",
       "        -0.10273289, -0.00337809, -0.03054843, -0.03711732, -0.01313835,\n",
       "        -0.08340508,  0.02846657,  0.0334374 , -0.00383598, -0.04403612,\n",
       "        -0.10330122, -0.05681432, -0.05962335, -0.10363086, -0.0321059 ,\n",
       "        -0.04376596, -0.03240097,  0.12035678, -0.04239852, -0.00848636,\n",
       "         0.01302869,  0.03291457, -0.02775279,  0.03804924,  0.01571714,\n",
       "        -0.02280157,  0.02775347,  0.04353521, -0.03745322,  0.07626067,\n",
       "         0.03546419, -0.0364619 ,  0.02302284, -0.01893474,  0.03468646,\n",
       "        -0.03008827, -0.03228126,  0.02887809,  0.06171198,  0.1213865 ]),\n",
       " array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.85206213, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimal_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_lst = fixed_params[\"K_lst\"]\n",
    "random_seed = fixed_params[\"random_seed\"]\n",
    "select_atom_percent = 0\n",
    "atom_weak_select_flag = False\n",
    "\n",
    "indices = []\n",
    "coefficients = None\n",
    "coefficients_matrix = None\n",
    "error_series = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = y_train\n",
    "phi = X_train\n",
    "a = np.zeros_like(s)\n",
    "coefficients = np.zeros(phi.shape[1])\n",
    "r = s.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients_matrix = np.zeros((phi.shape[1], len(K_lst)))\n",
    "error_series = np.zeros(len(K_lst))\n",
    "if random_seed is not None:\n",
    "    np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_lst = [1,10,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(np.max(K_lst)):\n",
    "    inner_products = (phi.T @ r).flatten()\n",
    "    # so that we will not select the same atom\n",
    "    inner_products[indices] = 0\n",
    "    lambda_k = np.argmax(np.abs(inner_products))\n",
    "\n",
    "    # Ordinary least squares\n",
    "    X = phi[:, indices + [lambda_k]]\n",
    "\n",
    "    try:\n",
    "        betas = np.linalg.inv(X.T @ X) @ X.T @ s\n",
    "    except:\n",
    "        print(\"Singular matrix encountered in OMP\")\n",
    "        break\n",
    "\n",
    "    # Update indices\n",
    "    indices.append(lambda_k)\n",
    "\n",
    "\n",
    "    ## FIXME:: Lazy David found that you can skip determining the optimal k and calculate the error with the whole matrix with the right indexing\n",
    "    # Update Coefficients\n",
    "    temp_coefficients_vector = np.zeros(phi.shape[1])\n",
    "    temp_coefficients_vector[indices] = betas.flatten()\n",
    "    temp_projection_vector = phi @ temp_coefficients_vector\n",
    "    temp_residual_vector = s - temp_projection_vector\n",
    "\n",
    "    if (k+1) in K_lst:\n",
    "        coefficients_matrix[:, K_lst.index(k+1)] = temp_coefficients_vector\n",
    "        error_series[K_lst.index(k+1)] = np.mean(temp_residual_vector**2)\n",
    "\n",
    "minimal_k_index = np.argmin(error_series)\n",
    "\n",
    "optimal_k = K_lst[minimal_k_index]\n",
    "\n",
    "# Update Coefficients\n",
    "\n",
    "coefficients = coefficients_matrix[:, minimal_k_index]\n",
    "\n",
    "# Update Projection\n",
    "a = phi @ coefficients\n",
    "\n",
    "# Update Residual\n",
    "r = s - a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
