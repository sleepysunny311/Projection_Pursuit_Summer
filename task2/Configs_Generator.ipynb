{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import yaml\n","import os"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["#YAML Generator For Single MP/OMP model\n","\n","#Configures Output Path\n","output_dir = \"./single_model_configs/\"\n","\n","# Ensure the output directory exists\n","os.makedirs(output_dir, exist_ok=True)\n","\n","\n","# The base configuration for your YAML files\n","base_config  = {\n","    \"SIGNAL\":{\n","        \"N\": 100000,\n","        \"d\": 300,\n","        \"noise_level\": [0, 0.01, 0.05, 0.1],\n","        \"true_sparsity\": [2, 5, 10]\n","    },\n","    \"MODEL\": {\n","        \"method\": \"MP\",\n","        \"signal_bag_flag\": True,\n","        \"signal_bag_percent\": 0.7,\n","        \"atom_bag_percent\": 0.7,\n","        \"select_atom_percent\": 0,\n","        \"replace_flag\": True,\n","        \"agg_func\": \"weight\"\n","    },\n","    \"TEST\": {\n","        \"trial_num\": 100,\n","    },\n","    \"hydra\": {\n","        \"hydra_logging\": {\n","            \"level\": \"CRITICAL\"\n","        },\n","        \"job_logging\": {\n","            \"level\": \"CRITICAL\"\n","        },\n","        \"run\": {\n","            \"dir\": \"./outputs\",\n","        }\n","    }\n","}\n","output_file = os.path.join(output_dir, \"test.yaml\")\n","with open(output_file, 'w') as f:\n","    yaml.dump(base_config,f)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\"\"\"\n","Here is what I am thinking about how to do this testing:\n","\n","We could be testing whole many combinations of hyper parameters\n","But they can be classified into 3 classes: SIGNAL, MODEL, TEST, and hydra\n","We should start with the simplest idea: For every single combination of hyper parameters, we test 100 times\n","And we use ith trial_number as the seed in that trial. So that maybe we decide to do 1000 trials we do not waste 1000\n","it leads to next intersting question: how to recycle the data we have used?\n","\n","As you can see I found a way to hash the dictionary, we can use a dictionary of SIGNAL and MODEL to do the hashing\n","and use that value for filename. Just to be sure even when we find the same hash value we should check hyper parameter one by one\n","\n","All testing results and their corresponding hyper parameter should be stored in the .pkl file. \n","Each .pkl file should correspond to (100) trials results we have got for one possible combination of (SIGNAL, TEST)\n","\n","Configs are totally different bewteen single MP/OMP and bunches of MP/OMP\n","But i still suggest we should separate their configs and results path.\n","\n","More details:\n","We input many of the hyper parameters in the forms of list. We should make our main function to be robust:\n","main.py should include all the parameters we need in all possible combinations of (100) trials we are gotta make:\n","So I suggest we make a class/function for testing and do the next things:\n","1. locate and get all combinations of hyper parameters in this yaml file and distribute the jobs\n","2. feed each combination to one function named run_one_possiblity(SIGNAL,MODEL,TEST): this function should iterate all (100) trials for one certain possible combination of hyper parameter\n","3. run_one_possiblity(SIGNAL,MODEL,TEST),this function would look into output and find if there is any previous unknown results to avoid possible calculation, runs a for loop with 2 function: Load_Data(SIGNAL,seed = trial_num),Load_Model(MODEL,seed=trial_num), Predict(),this process could use parallel computation\n","4. After run_one_possiblity(), we load whatever results (details left to decide, but i think only hyper parameters and MSE, sparsity recovery ratio is enough), dump everything into a file named by hash value given by hyper parameters\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### TODO: YAML Generator For Bagging of MP/OMP"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Hashing\n","def hash_dict(dictionary):\n","    return hash(frozenset(dictionary.items()))\n","\n","my_dict = {\"name\": \"John\", \"age\": 25, \"country\": \"USA\"}\n","my_dict1 = {\"age\": 25, \"country\": \"USA\", \"name\": \"John\"}\n","a = hash_dict(my_dict)\n","b = hash_dict(my_dict1)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["-6702312827062868661"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["a"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["-6702312827062868661"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["b"]}],"metadata":{"kernelspec":{"display_name":"summer2023","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
