{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dictionary of Unit-norm vectors\n",
    "\n",
    "def generate_gaussian_noises_dict(N, d):\n",
    "    gaussian_noises = np.random.normal(size=(d, N))\n",
    "    norms = np.linalg.norm(gaussian_noises, axis=0, keepdims=True)\n",
    "    # Create unit-norm vectors\n",
    "    unit_vectors = gaussian_noises / norms\n",
    "    return unit_vectors\n",
    "\n",
    "def generate_sparse_response(gaussian_matrix, m):\n",
    "    indices = np.random.choice(gaussian_matrix.shape[1], size=m, replace=False)\n",
    "    selected_vectors = gaussian_matrix[:, indices]\n",
    "    coefficients = np.random.normal(size=(m, 1))  # random coefficients for each selected vector\n",
    "    y = selected_vectors @ coefficients\n",
    "    return y, indices, coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the functions to generate a Gaussian noise matrix and a sparse response\n",
    "np.random.seed(0)\n",
    "N = 100000\n",
    "d = 300\n",
    "m = 2\n",
    "gaussian_noises_matrix = generate_gaussian_noises_dict(N, d)\n",
    "y, indices, coefficients = generate_sparse_response(gaussian_noises_matrix, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34249941],\n",
       "       [1.7701584 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16274, 83612])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching Pursuit\n",
    "\n",
    "def matching_pursuit(s, phi, K):\n",
    "    \"\"\"\n",
    "    Perform the Matching Pursuit algorithm\n",
    "\n",
    "    Args:\n",
    "    s (numpy.ndarray): Input signal\n",
    "    phi (numpy.ndarray): Dictionary\n",
    "    K (int): Number of iterations (sparsity)\n",
    "\n",
    "    Returns:\n",
    "    a (numpy.ndarray): Sparse representation of s\n",
    "    indices (list): List of indices of selected atoms\n",
    "    coefficients (list): List of coefficients of selected atoms\n",
    "    \"\"\"\n",
    "    # Initialize a and r\n",
    "    a = np.zeros_like(s)\n",
    "    r = s.copy()\n",
    "    indices = []\n",
    "    coefficients = []\n",
    "    # Perform Matching Pursuit\n",
    "    for _ in range(K):\n",
    "        # Compute inner products\n",
    "        inner_products = phi.T @ r\n",
    "\n",
    "        # Find the index with maximum absolute correlation\n",
    "        lambda_k = np.argmax(np.abs(inner_products), axis=0)\n",
    "\n",
    "        # Save the index\n",
    "        indices.append(lambda_k[0])\n",
    "\n",
    "        # Save the coefficient\n",
    "        coefficients.append(inner_products[lambda_k])\n",
    "\n",
    "        # Update a\n",
    "        a += coefficients[-1] * phi[:, lambda_k]\n",
    "\n",
    "        # Update r\n",
    "        r = s - a\n",
    "\n",
    "    return a, indices, coefficients\n",
    "\n",
    "# Perform Matching Pursuit\n",
    "MP_residual, MP_indices, MP_coefficients = matching_pursuit(y, gaussian_noises_matrix, 2*m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.77858963]]),\n",
       " array([[0.34229186]]),\n",
       " array([[-0.00842612]]),\n",
       " array([[0.00020742]])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MP_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[83612, 16274, 83612, 16274]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MP_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orthogonal Matching Pursuit\n",
    "\n",
    "def orthogonal_matching_pursuit(s, phi, K):\n",
    "    \"\"\"\n",
    "    Perform the Orthogonal Matching Pursuit algorithm\n",
    "\n",
    "    Args:\n",
    "    s (numpy.ndarray): Input signal\n",
    "    phi (numpy.ndarray): Dictionary\n",
    "    K (int): Number of iterations (sparsity)\n",
    "\n",
    "    Returns:\n",
    "    a (numpy.ndarray): Sparse representation of s\n",
    "    indices (list): Indices of the selected atoms\n",
    "    coefficients (list): Coefficients of the selected atoms\n",
    "    \"\"\"\n",
    "    # Initialize a and r\n",
    "    a = np.zeros_like(s)\n",
    "    r = s.copy()\n",
    "    indices = []\n",
    "    coefficients = []\n",
    "\n",
    "    for _ in range(K):\n",
    "        # Compute inner products\n",
    "        inner_products = phi.T @ r\n",
    "        \n",
    "        # Though paper says OMP will not choose the same index twice, it does.\n",
    "        inner_products[indices] = np.min(np.abs(inner_products))\n",
    "\n",
    "        # Find the index with maximum absolute correlation\n",
    "        lambda_k = np.argmax(np.abs(inner_products), axis=0)\n",
    "        # print(np.max(np.abs(inner_products)))\n",
    "        \n",
    "        # Save the index\n",
    "        indices.append(lambda_k[0])\n",
    "        # print(indices)\n",
    "\n",
    "        # Ordinary Least Squares\n",
    "        X = phi[:, indices]\n",
    "        betas = np.linalg.inv(X.T @ X) @ X.T @ s\n",
    "\n",
    "        # Save the coefficient\n",
    "        coefficients = betas\n",
    "\n",
    "        # Update a\n",
    "        a = X @ betas\n",
    "\n",
    "        # Update r\n",
    "        r = s - a\n",
    "\n",
    "    return a, indices, coefficients\n",
    "\n",
    "# Perform Orthogonal Matching Pursuit\n",
    "OMP_residual, OMP_indices, OMP_coefficients = orthogonal_matching_pursuit(y, gaussian_noises_matrix, 2*m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.77015840e+00],\n",
       "       [ 3.42499410e-01],\n",
       "       [ 1.35308431e-16],\n",
       "       [-6.93889390e-17]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OMP_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[83612, 16274, 20541, 65973]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OMP_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weak Orthogonal Matching Pursuit\n",
    "\n",
    "def weak_orthogonal_matching_pursuit(s, phi, alpha):\n",
    "    \"\"\"\n",
    "    Perform the Weak Orthogonal Matching Pursuit algorithm\n",
    "\n",
    "    Args:\n",
    "    s (numpy.ndarray): Input signal\n",
    "    phi (numpy.ndarray): Dictionary\n",
    "    alpha (float): Threshold for stopping the algorithm\n",
    "\n",
    "    Returns:\n",
    "    a (numpy.ndarray): Sparse representation of s\n",
    "    indices (list): Indices of the selected atoms\n",
    "    coefficients (list): Coefficients of the selected atoms\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize a and r\n",
    "    a = np.zeros_like(s)\n",
    "    r = s.copy()\n",
    "    indices = []\n",
    "    coefficients = []\n",
    "    flag = True\n",
    "\n",
    "    while flag:\n",
    "        # Compute inner products\n",
    "        inner_products = phi.T @ r\n",
    "\n",
    "        # Create a copy of inner_products to find out the largest inner product\n",
    "        # Though paper says OMP will not choose the same index twice, it does.\n",
    "        inner_products_copy = inner_products.copy()\n",
    "        inner_products_copy[indices] = np.min(np.abs(inner_products_copy))\n",
    "\n",
    "        # Find the index with maximum absolute correlation\n",
    "        lambda_k = np.argmax(np.abs(inner_products_copy), axis=0)\n",
    "\n",
    "        # Save the index\n",
    "        indices.append(lambda_k[0])\n",
    "\n",
    "        # Ordinary Least Squares\n",
    "        X = phi[:, indices]\n",
    "        betas = np.linalg.inv(X.T @ X) @ X.T @ s\n",
    "\n",
    "        # Save the coefficient\n",
    "        coefficients = betas\n",
    "\n",
    "        # Update a\n",
    "        a = X @ betas\n",
    "\n",
    "        # Update r\n",
    "        r = s - a\n",
    "\n",
    "        # Check if the largest inner product is greater than alpha times the largest inner product\n",
    "        largest_inner_product = np.abs(inner_products[lambda_k][0][0])\n",
    "        if largest_inner_product >= alpha * np.max(np.abs(inner_products)):\n",
    "            flag = False\n",
    "    return a, indices, coefficients\n",
    "\n",
    "# Perform Weak Orthogonal Matching Pursuit\n",
    "WOMP_residual, WOMP_indices, WOMP_coefficients = weak_orthogonal_matching_pursuit(y_train, X_train, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 0.0001}\n",
      "Best score (neg_mean_squared_error): -6.0769806502645135e-06\n",
      "Testing set MSE: 5.920689195738421e-06\n"
     ]
    }
   ],
   "source": [
    "# LASSO Regression\n",
    "np.random.seed(0)\n",
    "\n",
    "# Reduced Standardization because the data is already unit-norm\n",
    "\n",
    "lasso = Lasso()\n",
    "LASSO_alphas = {\"alpha\": [1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]}\n",
    "LASSO_cv = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "# Perform grid search on training data\n",
    "grid = GridSearchCV(lasso, LASSO_alphas, scoring='neg_mean_squared_error', cv=LASSO_cv, return_train_score=True)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print('Best parameters:', grid.best_params_)\n",
    "print('Best score (neg_mean_squared_error):', grid.best_score_)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "y_pred = grid.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "print('Testing set MSE:', mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0., -0., -0., ...,  0.,  0., -0.])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.coef_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VSC_Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
