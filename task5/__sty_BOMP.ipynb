{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import pickle as pkl\n",
    "import hashlib\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from datetime import datetime\n",
    "\n",
    "def get_parser():\n",
    "    parser = argparse.ArgumentParser(description='Testing')\n",
    "    parser.add_argument('--config-file', type=str, default='configs/bomp_default.yaml', metavar= \"FILE\" ,help='path to config file')\n",
    "    parser.add_argument(\"--output\", type=str, help=\"Output path\")\n",
    "    return parser\n",
    "\n",
    "\n",
    "def get_cfg(config_file):\n",
    "    with open(config_file, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return config\n",
    "\n",
    "\n",
    "def merge_cfg(default_dict, input_dict):\n",
    "    merged_dict = default_dict.copy()  # Start with default values.\n",
    "    sections = ['MODEL', 'TEST', 'UTILS']  # Specify sections to update\n",
    "\n",
    "    for section in sections:\n",
    "        if section in default_dict and section in input_dict:\n",
    "            for key in default_dict[section]:\n",
    "                # Check if the key is in the user input dictionary\n",
    "                if key in input_dict[section]:\n",
    "                    # If it is, update the merged dictionary\n",
    "                    merged_dict[section][key] = input_dict[section][key]\n",
    "                else:\n",
    "                    # If not, print a message about using the default value\n",
    "                    print(f\"Missing parameter '{key}' in section '{section}', default value '{default_dict[section][key]}' will be used.\")\n",
    "        else:\n",
    "            print(f\"Missing section '{section}' in the user input, default values will be used.\")\n",
    "\n",
    "    # Check for invalid keys in the user input dictionary\n",
    "    for section in input_dict:\n",
    "        if section in sections:\n",
    "            for key in input_dict[section]:\n",
    "                if key not in default_dict[section]:\n",
    "                    print(f\"Invalid key '{key}' in section '{section}'. This key will be ignored.\")\n",
    "\n",
    "    return merged_dict\n",
    "    \n",
    "def get_output_path(output_path, config_filename):\n",
    "    if output_path is None:\n",
    "        # output file will be a pickle file in the outputs folder\n",
    "        output_path = os.path.join(\"./memory\", config_filename.split(\"/\")[-1].split(\".\")[0] + \".pkl\")\n",
    "    else:\n",
    "        # output file will be a pickle file in the specified folder\n",
    "        output_path = os.path.join(output_path, config_filename.split(\"/\")[-1].split(\".\")[0] + \".pkl\")\n",
    "    return output_path    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TEST': {'n': 600,\n",
       "  'p': 1000,\n",
       "  'm': 20,\n",
       "  'noise_level': [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5],\n",
       "  'model': 'BOMP',\n",
       "  'cv_num': 5,\n",
       "  'trial_num': 10},\n",
       " 'MODEL': {'signal_bag_flag': False,\n",
       "  'signal_bag_percent': 0.7,\n",
       "  'atom_bag_percent': 0.7,\n",
       "  'select_atom_percent': 0.3,\n",
       "  'replace_flag': False,\n",
       "  'agg_func': 'weight',\n",
       "  'K_start': 1,\n",
       "  'K_end': 40,\n",
       "  'K_step': 1},\n",
       " 'UTILS': {'ignore_warning': True, 'random_seed': 0}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default\n",
    "cfg = get_cfg(\"configs/bomp_default.yaml\")\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_params(cfg):\n",
    "    import numpy as np\n",
    "    all_params = cfg['MODEL']\n",
    "    param_grid = {}\n",
    "    fixed_params = {}\n",
    "    K_start, K_end, K_step = all_params['K_start'], all_params['K_end'], all_params['K_step']\n",
    "    if K_start >= K_end:\n",
    "        raise ValueError(\"K_start must be smaller than K_end\")\n",
    "    if K_step <= 0:\n",
    "        raise ValueError(\"K_step must be positive\")\n",
    "    # Check if K_start, K_end, K_step are integers\n",
    "    if not isinstance(K_start, int) or not isinstance(K_end, int) or not isinstance(K_step, int):\n",
    "        raise ValueError(\"K_start, K_end, K_step must be integers\")\n",
    "    K_list = np.arange(K_start, K_end, K_step, dtype=int)\n",
    "    # Check if the param is a list or a single value if it is a list save to param_grid or else save to fixed_params\n",
    "    for param, value in all_params.items():\n",
    "        if param in ['K_start', 'K_end', 'K_step']:\n",
    "            continue\n",
    "        if isinstance(value, list):\n",
    "            param_grid[param] = value\n",
    "        else:\n",
    "            fixed_params[param] = value\n",
    "    param_grid['K'] = K_list\n",
    "    return fixed_params, param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing parameter 'signal_bag_percent' in section 'MODEL', default value '0.7' will be used.\n",
      "Missing parameter 'atom_bag_percent' in section 'MODEL', default value '0.7' will be used.\n",
      "Missing section 'UTILS' in the user input, default values will be used.\n",
      "Invalid key 'N_bag' in section 'MODEL'. This key will be ignored.\n",
      "Invalid key 'ignore_warning' in section 'MODEL'. This key will be ignored.\n",
      "Invalid key 'random_seed' in section 'MODEL'. This key will be ignored.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'TEST': {'n': 600,\n",
       "  'p': 1000,\n",
       "  'm': 20,\n",
       "  'noise_level': [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5],\n",
       "  'model': 'BOMP',\n",
       "  'cv_num': 5,\n",
       "  'trial_num': 10},\n",
       " 'MODEL': {'signal_bag_flag': False,\n",
       "  'signal_bag_percent': 0.7,\n",
       "  'atom_bag_percent': 0.7,\n",
       "  'select_atom_percent': [0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "  'replace_flag': False,\n",
       "  'agg_func': ['avg', 'weight'],\n",
       "  'K_start': 1,\n",
       "  'K_end': 41,\n",
       "  'K_step': 1},\n",
       " 'UTILS': {'ignore_warning': True, 'random_seed': 0}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_config = get_cfg(\"configs/bomp_default.yaml\")\n",
    "input_config = get_cfg(\"configs/bomp_test.yaml\")\n",
    "config = merge_cfg(default_config, input_config)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'signal_bag_flag': False, 'signal_bag_percent': 0.7, 'atom_bag_percent': 0.7, 'replace_flag': False}\n",
      "{'select_atom_percent': [0, 0.1, 0.2, 0.3, 0.4, 0.5], 'agg_func': ['avg', 'weight'], 'K': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
      "       35, 36, 37, 38, 39, 40])}\n"
     ]
    }
   ],
   "source": [
    "fixed_params, param_grid = get_model_params(config)\n",
    "\n",
    "print(fixed_params)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'signal_bag_flag': False,\n",
       " 'signal_bag_percent': 0.5,\n",
       " 'atom_bag_percent': 0.7,\n",
       " 'replace_flag': False}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_params['signal_bag_percent'] = 0.5\n",
    "\n",
    "fixed_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BOMP(atom_bag_percent=0.7, replace_flag=False, signal_bag_flag=False,\n",
       "     signal_bag_percent=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BOMP</label><div class=\"sk-toggleable__content\"><pre>BOMP(atom_bag_percent=0.7, replace_flag=False, signal_bag_flag=False,\n",
       "     signal_bag_percent=None)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BOMP(atom_bag_percent=0.7, replace_flag=False, signal_bag_flag=False,\n",
       "     signal_bag_percent=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from algorithms import BOMP\n",
    "\n",
    "my_bomp = BOMP(**fixed_params)\n",
    "\n",
    "my_bomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 1), (400, 1000))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_generation import GaussianDataGenerator\n",
    "\n",
    "N = 1000\n",
    "d = 400\n",
    "m = 40\n",
    "noise_level = 0.05\n",
    "seed = 0\n",
    "\n",
    "Data_Geneartor = GaussianDataGenerator(N, d, m, 0.05, 0)\n",
    "\n",
    "true_signal, dictionary, true_indices, true_coefficients, perturbed_signal = Data_Geneartor.shuffle()\n",
    "\n",
    "perturbed_signal.shape, dictionary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 480 candidates, totalling 2400 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 2400 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n2400 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/homebrew/Caskroom/miniforge/base/envs/env_base/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/songtengyu/Documents/Projects/2023summer/Projection_Pursuit_Summer/task5/algorithms.py\", line 582, in fit\n    self.SignalBagging.fit(self.phi, self.s)\n  File \"/Users/songtengyu/Documents/Projects/2023summer/Projection_Pursuit_Summer/task5/algorithms.py\", line 122, in fit\n    num_samples = int(self.signal_bag_percent * len(self.s))\nTypeError: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/songtengyu/Documents/Projects/2023summer/Projection_Pursuit_Summer/task5/__sty_BOMP.ipynb Cell 8\u001b[0m in \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/songtengyu/Documents/Projects/2023summer/Projection_Pursuit_Summer/task5/__sty_BOMP.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m GridSearchCV\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/songtengyu/Documents/Projects/2023summer/Projection_Pursuit_Summer/task5/__sty_BOMP.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m gs \u001b[39m=\u001b[39m GridSearchCV(my_bomp, param_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mneg_mean_squared_error\u001b[39m\u001b[39m'\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/songtengyu/Documents/Projects/2023summer/Projection_Pursuit_Summer/task5/__sty_BOMP.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m gs\u001b[39m.\u001b[39mfit(dictionary, perturbed_signal)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_base/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_base/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1378\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1379\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_base/lib/python3.10/site-packages/sklearn/model_selection/_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m!=\u001b[39m n_candidates \u001b[39m*\u001b[39m n_splits:\n\u001b[1;32m    846\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    847\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcv.split and cv.get_n_splits returned \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    848\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minconsistent results. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    849\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msplits, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_splits, \u001b[39mlen\u001b[39m(out) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_candidates)\n\u001b[1;32m    850\u001b[0m     )\n\u001b[0;32m--> 852\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_score)\n\u001b[1;32m    854\u001b[0m \u001b[39m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[39m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[39m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[39m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39mif\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_base/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[1;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 2400 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n2400 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/homebrew/Caskroom/miniforge/base/envs/env_base/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/songtengyu/Documents/Projects/2023summer/Projection_Pursuit_Summer/task5/algorithms.py\", line 582, in fit\n    self.SignalBagging.fit(self.phi, self.s)\n  File \"/Users/songtengyu/Documents/Projects/2023summer/Projection_Pursuit_Summer/task5/algorithms.py\", line 122, in fit\n    num_samples = int(self.signal_bag_percent * len(self.s))\nTypeError: unsupported operand type(s) for *: 'NoneType' and 'int'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "gs = GridSearchCV(my_bomp, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "\n",
    "gs.fit(dictionary, perturbed_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
