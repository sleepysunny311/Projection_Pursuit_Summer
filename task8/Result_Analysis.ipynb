{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import pickle as pkl\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_omp_logs_to_dataframe(input_text):\n",
    "    lines = input_text.split(\"\\n\")\n",
    "    current_trial_group = None\n",
    "    current_noise_level = None\n",
    "    data = []\n",
    "    \n",
    "    for line in lines:\n",
    "        if \"Running trials for n =\" in line:\n",
    "            current_trial_group = tuple(map(int, re.findall(r'\\d+', line)))\n",
    "        elif \"Cross validating alpha under noise level:\" in line:\n",
    "            current_noise_level = float(line.split()[-1])\n",
    "        elif \"Trial:\" in line and current_trial_group and current_noise_level is not None:\n",
    "            trial_info = re.findall(r'{.*?}', line)[0]\n",
    "            trial_info = eval(trial_info)\n",
    "            trial_info[\"Trial\"] = int(line.split()[1])\n",
    "            trial_info[\"Lowest CV Error\"] = float(re.findall(r'(?<=Lowest CV Error:  )\\d+\\.\\d+', line)[0])\n",
    "            trial_info[\"Training Error\"] = float(re.findall(r'(?<=Training Error:  )\\d+\\.\\d+', line)[0])\n",
    "            trial_info[\"Testing Error\"] = float(re.findall(r'(?<=Testing Error:  )\\d+\\.\\d+', line)[0])\n",
    "            trial_info[\"n\"] = current_trial_group[0]\n",
    "            trial_info[\"p\"] = current_trial_group[1]\n",
    "            trial_info[\"m\"] = current_trial_group[2]\n",
    "            trial_info[\"Noise Level\"] = current_noise_level\n",
    "            data.append(trial_info)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "file_path = 'outputs/0718/slurm-8042307.out'  # replace with your .out file path\n",
    "omp_out_summary = parse_omp_logs_to_dataframe(open(file_path).read())\n",
    "omp_error_dataframe = omp_out_summary[['Noise Level', 'Testing Error', 'Training Error', 'n', 'p', 'm']].groupby(['n', 'p', 'm','Noise Level']).mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bomp_logs_to_dataframe(input_text):\n",
    "    lines = input_text.split(\"\\n\")\n",
    "    current_trial_group = None\n",
    "    current_noise_level = None\n",
    "    data = []\n",
    "    \n",
    "    for line in lines:\n",
    "        if \"Running trials for n =\" in line:\n",
    "            current_trial_group = tuple(map(int, re.findall(r'\\d+', line)))\n",
    "        elif \"Cross validating alpha under noise level:\" in line:\n",
    "            current_noise_level = float(line.split()[-1])\n",
    "        elif \"Trial:\" in line and current_trial_group and current_noise_level is not None:\n",
    "            trial_info = re.findall(r'{.*?}', line)[0]\n",
    "            trial_info = eval(trial_info)\n",
    "            trial_info[\"Trial\"] = int(line.split()[1])\n",
    "            trial_info[\"Lowest CV Error\"] = float(re.findall(r'(?<=Lowest CV Error:  )\\d+\\.\\d+', line)[0])\n",
    "            trial_info[\"Training Error\"] = float(re.findall(r'(?<=Training Error:  )\\d+\\.\\d+', line)[0])\n",
    "            trial_info[\"Testing Error\"] = float(re.findall(r'(?<=Testing Error:  )\\d+\\.\\d+', line)[0])\n",
    "            trial_info[\"n\"] = current_trial_group[0]\n",
    "            trial_info[\"p\"] = current_trial_group[1]\n",
    "            trial_info[\"m\"] = current_trial_group[2]\n",
    "            trial_info[\"Noise Level\"] = current_noise_level\n",
    "            data.append(trial_info)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "file_path = 'outputs/0718/slurm-8021496.out'  # replace with your .out file path\n",
    "bomp_out_summary = parse_bomp_logs_to_dataframe(open(file_path).read())\n",
    "bomp_error_dataframe = bomp_out_summary[['Noise Level', 'Testing Error', 'Training Error', 'n', 'p', 'm']].groupby(['n', 'p', 'm','Noise Level']).mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100    73\n",
       "200    12\n",
       "10      8\n",
       "40      2\n",
       "20      2\n",
       "90      1\n",
       "60      1\n",
       "30      1\n",
       "Name: best_k, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bomp_out_summary['best_k'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "      <th>m</th>\n",
       "      <th>Noise Level</th>\n",
       "      <th>omp_Testing Error</th>\n",
       "      <th>omp_Training Error</th>\n",
       "      <th>bomp_Testing Error</th>\n",
       "      <th>bomp_Training Error</th>\n",
       "      <th>testing_error_improvement</th>\n",
       "      <th>training_error_improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.015201</td>\n",
       "      <td>0.015418</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.903184</td>\n",
       "      <td>0.972011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>0.016805</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.776552</td>\n",
       "      <td>0.931046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.018522</td>\n",
       "      <td>0.018987</td>\n",
       "      <td>0.006592</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.644081</td>\n",
       "      <td>0.899957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.021421</td>\n",
       "      <td>0.021965</td>\n",
       "      <td>0.010767</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>0.497372</td>\n",
       "      <td>0.841477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.026213</td>\n",
       "      <td>0.025723</td>\n",
       "      <td>0.017413</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.335717</td>\n",
       "      <td>0.790722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.050262</td>\n",
       "      <td>0.044469</td>\n",
       "      <td>0.006332</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.874028</td>\n",
       "      <td>0.975206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.052411</td>\n",
       "      <td>0.045978</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.847977</td>\n",
       "      <td>0.970205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.054397</td>\n",
       "      <td>0.048302</td>\n",
       "      <td>0.011909</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.781075</td>\n",
       "      <td>0.964220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.058109</td>\n",
       "      <td>0.051249</td>\n",
       "      <td>0.016361</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>0.718449</td>\n",
       "      <td>0.946814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.061757</td>\n",
       "      <td>0.054950</td>\n",
       "      <td>0.021508</td>\n",
       "      <td>0.004331</td>\n",
       "      <td>0.651737</td>\n",
       "      <td>0.921192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     n    p   m  Noise Level  omp_Testing Error  omp_Training Error  \\\n",
       "0  300  500  10         0.02           0.015201            0.015418   \n",
       "1  300  500  10         0.04           0.016448            0.016805   \n",
       "2  300  500  10         0.06           0.018522            0.018987   \n",
       "3  300  500  10         0.08           0.021421            0.021965   \n",
       "4  300  500  10         0.10           0.026213            0.025723   \n",
       "5  300  500  20         0.02           0.050262            0.044469   \n",
       "6  300  500  20         0.04           0.052411            0.045978   \n",
       "7  300  500  20         0.06           0.054397            0.048302   \n",
       "8  300  500  20         0.08           0.058109            0.051249   \n",
       "9  300  500  20         0.10           0.061757            0.054950   \n",
       "\n",
       "   bomp_Testing Error  bomp_Training Error  testing_error_improvement  \\\n",
       "0            0.001472             0.000432                   0.903184   \n",
       "1            0.003675             0.001159                   0.776552   \n",
       "2            0.006592             0.001900                   0.644081   \n",
       "3            0.010767             0.003482                   0.497372   \n",
       "4            0.017413             0.005383                   0.335717   \n",
       "5            0.006332             0.001103                   0.874028   \n",
       "6            0.007968             0.001370                   0.847977   \n",
       "7            0.011909             0.001728                   0.781075   \n",
       "8            0.016361             0.002726                   0.718449   \n",
       "9            0.021508             0.004331                   0.651737   \n",
       "\n",
       "   training_error_improvement  \n",
       "0                    0.972011  \n",
       "1                    0.931046  \n",
       "2                    0.899957  \n",
       "3                    0.841477  \n",
       "4                    0.790722  \n",
       "5                    0.975206  \n",
       "6                    0.970205  \n",
       "7                    0.964220  \n",
       "8                    0.946814  \n",
       "9                    0.921192  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we need to add prefixes to the column names of each dataframe\n",
    "temp_omp_error_dataframe = omp_error_dataframe.copy().add_prefix('omp_')\n",
    "temp_bomp_error_dataframe = bomp_error_dataframe.copy().add_prefix('bomp_')\n",
    "\n",
    "# then we remove the prefix from the columns we will merge on\n",
    "temp_omp_error_dataframe.rename(columns={'omp_n':'n', 'omp_p':'p', 'omp_m':'m', 'omp_Noise Level':'Noise Level'}, inplace=True)\n",
    "temp_bomp_error_dataframe.rename(columns={'bomp_n':'n', 'bomp_p':'p', 'bomp_m':'m', 'bomp_Noise Level':'Noise Level'}, inplace=True)\n",
    "\n",
    "# now we can merge\n",
    "merged_df = pd.merge(temp_omp_error_dataframe, temp_bomp_error_dataframe, on=['n', 'p', 'm', 'Noise Level'], suffixes=('_omp', '_bomp'))\n",
    "\n",
    "merged_df['testing_error_improvement'] = (merged_df['omp_Testing Error'] - merged_df['bomp_Testing Error'])/ merged_df['omp_Testing Error']\n",
    "merged_df['training_error_improvement'] = (merged_df['omp_Training Error'] - merged_df['bomp_Training Error'])/ merged_df['omp_Training Error']\n",
    "\n",
    "\n",
    "groups = merged_df.groupby(['n', 'p', 'm'])\n",
    "list_of_groups = [groups.get_group(x) for x in groups.groups]\n",
    "\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m = 10\n",
      "\\begin{tabular}{rrrrrrr}\n",
      "\\toprule\n",
      " Noise Level &  omp\\_Testing  &  omp\\_Training  &  bomp\\_Testing  &  bomp\\_Training  &  testing\\_improvement &  training\\_improvement \\\\\n",
      "\\midrule\n",
      "        0.02 &      0.015201 &       0.015418 &       0.001472 &        0.000432 &             0.903184 &              0.972011 \\\\\n",
      "        0.04 &      0.016448 &       0.016805 &       0.003675 &        0.001159 &             0.776552 &              0.931046 \\\\\n",
      "        0.06 &      0.018522 &       0.018987 &       0.006592 &        0.001900 &             0.644081 &              0.899957 \\\\\n",
      "        0.08 &      0.021421 &       0.021965 &       0.010767 &        0.003482 &             0.497372 &              0.841477 \\\\\n",
      "        0.10 &      0.026213 &       0.025723 &       0.017413 &        0.005383 &             0.335717 &              0.790722 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "m = 20\n",
      "\\begin{tabular}{rrrrrrr}\n",
      "\\toprule\n",
      " Noise Level &  omp\\_Testing  &  omp\\_Training  &  bomp\\_Testing  &  bomp\\_Training  &  testing\\_improvement &  training\\_improvement \\\\\n",
      "\\midrule\n",
      "        0.02 &      0.050262 &       0.044469 &       0.006332 &        0.001103 &             0.874028 &              0.975206 \\\\\n",
      "        0.04 &      0.052411 &       0.045978 &       0.007968 &        0.001370 &             0.847977 &              0.970205 \\\\\n",
      "        0.06 &      0.054397 &       0.048302 &       0.011909 &        0.001728 &             0.781075 &              0.964220 \\\\\n",
      "        0.08 &      0.058109 &       0.051249 &       0.016361 &        0.002726 &             0.718449 &              0.946814 \\\\\n",
      "        0.10 &      0.061757 &       0.054950 &       0.021508 &        0.004331 &             0.651737 &              0.921192 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r9/cr3fkwq558n9mv4z9n1c01k00000gn/T/ipykernel_76723/3533740765.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(group.drop(columns=['n', 'p', 'm']).to_latex(index=False))\n",
      "/var/folders/r9/cr3fkwq558n9mv4z9n1c01k00000gn/T/ipykernel_76723/3533740765.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(group.drop(columns=['n', 'p', 'm']).to_latex(index=False))\n"
     ]
    }
   ],
   "source": [
    "for group in list_of_groups:\n",
    "    group.columns = group.columns.str.replace('Error', '')\n",
    "    group.columns = group.columns.str.replace('_error', '')\n",
    "    print(f\"m = {group['m'].iloc[0]}\")\n",
    "    print(group.drop(columns=['n', 'p', 'm']).to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOMP_log_name = 'outputs/0718/BOMP_300_500_1020_nr_0718_0718-205341.pkl'\n",
    "BOMP_log_name = \"memory/BOMP_30_50_10_nr_0719_0719-181603.pkl\"\n",
    "\n",
    "npm_lists = None\n",
    "with open(BOMP_log_name, 'rb') as f:\n",
    "    npm_lists = pkl.load(f)\n",
    "single_npm = npm_lists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_npm_logs = single_npm['log']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agg_func': 'weight',\n",
       " 'ignore_warning': True,\n",
       " 'random_seed': 1,\n",
       " 'replace_flag': False,\n",
       " 'select_atom_percent': 0,\n",
       " 'Bag_lst': [1, 20],\n",
       " 'K_lst': [1, 5, 10, 15, 20, 25, 30]}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_npm['parameters']['fixed_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_npm_Bag_lst = single_npm['parameters']['fixed_params']['Bag_lst']\n",
    "single_npm_K_lst  = single_npm['parameters']['fixed_params']['K_lst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 250, 300]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_npm_K_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['noise_level', 'trial', 'cv_error_lst', 'lowest_cv_error', 'training_error', 'best_params', 'param_lst', 'testing_error', 'best_bag_k_error_matrix'])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_npm_logs[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 1.00000000e+00, 2.36773828e-01],\n",
       "       [1.00000000e+00, 5.00000000e+00, 2.02679618e-01],\n",
       "       [1.00000000e+00, 1.00000000e+01, 2.62788738e-01],\n",
       "       [1.00000000e+00, 1.50000000e+01, 9.61296683e-01],\n",
       "       [1.00000000e+00, 2.00000000e+01, 1.72704300e+01],\n",
       "       [1.00000000e+00, 2.50000000e+01, 4.57723977e+00],\n",
       "       [1.00000000e+00, 3.00000000e+01, 8.88470908e+01],\n",
       "       [2.00000000e+01, 1.00000000e+00, 6.25748513e-02],\n",
       "       [2.00000000e+01, 5.00000000e+00, 1.32439462e-01],\n",
       "       [2.00000000e+01, 1.00000000e+01, 1.97924039e-01],\n",
       "       [2.00000000e+01, 1.50000000e+01, 2.87392801e-01],\n",
       "       [2.00000000e+01, 2.00000000e+01, 4.72106712e+04],\n",
       "       [2.00000000e+01, 2.50000000e+01, 1.18169224e+02],\n",
       "       [2.00000000e+01, 3.00000000e+01, 4.07873357e+07]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_npm_logs[0]['best_bag_k_error_matrix']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
