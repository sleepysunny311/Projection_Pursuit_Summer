{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task4 Incorperate CV and OMP class better, and make it more general so we can use it later for ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "from itertools import product\n",
    "from algorithms import OMP\n",
    "from data_generation import GaussianDataGenerator\n",
    "import yaml\n",
    "from omegaconf import DictConfig\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_split(true_signal, dictionary, cv_num):\n",
    "    \"\"\"\n",
    "    Split the signal and dictionary into cv_num folds\n",
    "    \n",
    "    Args:\n",
    "        true_signal: the true signal\n",
    "        dictionary: the dictionary\n",
    "        cv_num: the number of folds\n",
    "    Returns:\n",
    "        cv_res: a list of tuples, each tuple is a fold of train signal, train dictionary, test signal, test dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    true_signal = true_signal.ravel()\n",
    "    # true_signal is (1200, 1) and dictionary is (1200, 10000), cv both signal and dictionary by rows\n",
    "    cv_signal = np.split(true_signal, cv_num)\n",
    "    cv_dictionary = np.split(dictionary, cv_num)\n",
    "    # Get the list of train and test set\n",
    "    cv_res = []\n",
    "    for i in range(cv_num):\n",
    "        train_signal = np.concatenate(cv_signal[:i] + cv_signal[i + 1:], axis = 0)\n",
    "        train_dictionary = np.concatenate(cv_dictionary[:i] + cv_dictionary[i + 1:], axis=0)\n",
    "        test_signal = cv_signal[i]\n",
    "        test_dictionary = cv_dictionary[i]\n",
    "        cv_res.append((train_signal, train_dictionary, test_signal, test_dictionary))\n",
    "    return cv_res\n",
    "\n",
    "def cal_cv_error(algorithm, cv_num, signal, dictionary):\n",
    "    \"\"\"\n",
    "    Calculate the cross validation error of the algorithm\n",
    "\n",
    "    Args:\n",
    "        algorithm: the algorithm to calculate the error\n",
    "        cv_num: the number of folds\n",
    "        signal: the true signal\n",
    "        dictionary: the dictionary\n",
    "    Returns:\n",
    "        error: the cross validation error\n",
    "    \"\"\"\n",
    "    cv_res = cv_split(signal, dictionary, cv_num)\n",
    "    error_lst = []\n",
    "    for i in range(cv_num):\n",
    "        train_signal, train_dictionary, test_signal, test_dictionary = cv_res[i]\n",
    "        algorithm.fit(train_signal, train_dictionary)\n",
    "        error_lst.append(algorithm.score(test_signal, test_dictionary))\n",
    "    return np.mean(error_lst)\n",
    "\n",
    "def cv_best_K(signal, dictionary, cv_num, K_lst):\n",
    "    \"\"\"\n",
    "    Calculate the best K for OMP algorithm using cross validation\n",
    "\n",
    "    Args:\n",
    "        signal: the true signal\n",
    "        dictionary: the dictionary\n",
    "        cv_num: the number of folds\n",
    "        K_lst: the list of K to try\n",
    "    Returns:\n",
    "        lowest_error: the lowest error\n",
    "        lowest_error_K: the K that gives the lowest error\n",
    "        K_cv_error: the list of cross validation error for each K\n",
    "    \"\"\"\n",
    "    K_cv_error = []\n",
    "    for K in K_lst:\n",
    "        OMP_tmp = OMP(K, ignore_warning=True)\n",
    "        K_cv_error.append(cal_cv_error(OMP_tmp, cv_num, signal, dictionary))\n",
    "    lowest_error = np.min(K_cv_error)\n",
    "    lowest_error_K = K_lst[np.argmin(K_cv_error)]\n",
    "    return lowest_error, lowest_error_K, K_cv_error\n",
    "\n",
    "\n",
    "# Improvement: Save the result to a file\n",
    "\n",
    "if not os.path.exists('./memory'):\n",
    "    os.mkdir('./memory')\n",
    "\n",
    "def cv_best_K_noise_level_multi_trial(N, d, m, noise_level_lst, cv_num, K_lst, trial_num, output_filename = None):\n",
    "    if output_filename is None:\n",
    "        output_filename = str(N) + '_' + str(d) + '_' + str(m) + '_' + str(trial_num) + '_' + str(cv_num) + '.pkl'\n",
    "    res_log = {\n",
    "        'parameters': {'N': N, 'd': d, 'm': m, 'noise_level_lst': noise_level_lst, 'cv_num': cv_num, 'trial_num': trial_num, 'K_lst': K_lst},\n",
    "        'noise_level_best_K': [],\n",
    "        'noise_level_lowest_MSE': [],\n",
    "        'log': []\n",
    "    }\n",
    "    noise_level_best_K = []\n",
    "    noise_level_lowest_MSE = []\n",
    "    for noise_level in noise_level_lst:\n",
    "        print(\"Cross validating K under noise level: \", noise_level)\n",
    "        trials_best_K_tmp = []\n",
    "        MSE_loweset_K_temp = []\n",
    "        for trial in range(trial_num):\n",
    "            Data_Geneartor = GaussianDataGenerator(N, d, m, noise_level, trial)\n",
    "            true_signal, dictionary, true_indices, true_coefficients, perturbed_signal = Data_Geneartor.shuffle()\n",
    "            lowest_error, lowest_error_K, cv_err_lst = cv_best_K(perturbed_signal, dictionary, cv_num, K_lst)\n",
    "            trials_best_K_tmp.append(lowest_error_K)\n",
    "            MSE_loweset_K_temp.append(lowest_error)\n",
    "            print(\"Trial: \", trial, \" Best K: \", lowest_error_K, \" Lowest Error: \", lowest_error)\n",
    "            log_tmp = {'noise_level': noise_level, 'trial': trial, 'data': Data_Geneartor, 'cv_error_lst': cv_err_lst, \n",
    "                       'lowest_error': lowest_error, 'lowest_error_K': lowest_error_K}\n",
    "            res_log['log'].append(log_tmp)\n",
    "        noise_level_best_K.append(np.mean(trials_best_K_tmp))\n",
    "        noise_level_lowest_MSE.append(np.mean(MSE_loweset_K_temp))\n",
    "        print(\"Average best K for noise level: \", noise_level, \" is: \", np.mean(trials_best_K_tmp), \" with MSE: \", np.mean(MSE_loweset_K_temp))\n",
    "    res_log['noise_level_best_K'] = noise_level_best_K\n",
    "    res_log['noise_level_lowest_MSE'] = noise_level_lowest_MSE\n",
    "    with open('./memory/' + output_filename, 'wb') as f:\n",
    "        pkl.dump(res_log, f)\n",
    "    print(\"Finished!\")\n",
    "    print(\"Log file saved to: \", './memory/' + output_filename)\n",
    "    return noise_level_best_K, noise_level_lowest_MSE, res_log\n",
    "\n",
    "\n",
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossValidator:\n",
    "    def __init__(self, signal, dictionary,cv_num,algorithm):\n",
    "        \"\"\"\n",
    "        Initialize the CrossValidator class\n",
    "\n",
    "        Args:\n",
    "            signal: the true signal\n",
    "            dictionary: the dictionary\n",
    "            cv_num: the number of folds\n",
    "        \"\"\"\n",
    "        self.signal = signal.ravel()\n",
    "        self.dictionary = dictionary\n",
    "        self.cv_num = cv_num\n",
    "        self.updated = False\n",
    "        self.cv_res = None\n",
    "        self.lowest_error = None\n",
    "        self.lowest_error_K = None\n",
    "        self.K_cv_error = None\n",
    "        self.algorithm = algorithm\n",
    "    def cv_split(self):\n",
    "        \"\"\"\n",
    "        Split the signal and dictionary into cv_num folds\n",
    "\n",
    "        Returns:\n",
    "            cv_res: a list of tuples, each tuple is a fold of train signal, train dictionary, test signal, test dictionary\n",
    "        \"\"\"\n",
    "        self.cv_res = []\n",
    "        true_signal = self.signal.ravel()\n",
    "        cv_signal = np.split(true_signal,self.cv_num)\n",
    "        cv_dictionary = np.split(self.dictionary, self.cv_num)\n",
    "        for i in range(self.cv_num):\n",
    "            train_signal = np.concatenate(cv_signal[:i] + cv_signal[i + 1:], axis = 0)\n",
    "            train_dictionary = np.concatenate(cv_dictionary[:i] + cv_dictionary[i + 1:], axis=0)\n",
    "            test_signal = cv_signal[i]\n",
    "            test_dictionary = cv_dictionary[i]\n",
    "            self.cv_res.append((train_signal, train_dictionary, test_signal, test_dictionary))\n",
    "\n",
    "    def cal_cv_error(self):\n",
    "        \"\"\"\n",
    "        Calculate the cross validation error of the algorithm\n",
    "\n",
    "        Args:\n",
    "            algorithm: the algorithm to calculate the error\n",
    "        Returns:\n",
    "            error: the cross validation error\n",
    "        \"\"\"\n",
    "        if not self.updated:\n",
    "            error_lst = []\n",
    "            for i in range(self.cv_num):\n",
    "                train_signal, train_dictionary, test_signal, test_dictionary = self.cv_res[i]\n",
    "                self.algorithm.fit(train_signal, train_dictionary)\n",
    "                error_lst.append(self.algorithm.score(test_signal, test_dictionary))\n",
    "        return np.mean(error_lst)\n",
    "\n",
    "    def cv_best_K(self, cv_num, K_lst):\n",
    "        \"\"\"\n",
    "        Calculate the best K for OMP algorithm using cross validation\n",
    "\n",
    "        Args:\n",
    "            signal: the true signal\n",
    "            dictionary: the dictionary\n",
    "            cv_num: the number of folds\n",
    "            K_lst: the list of K to try\n",
    "        Returns:\n",
    "            lowest_error: the lowest error\n",
    "            lowest_error_K: the K that gives the lowest error\n",
    "            K_cv_error: the list of cross validation error for each K\n",
    "        \"\"\"\n",
    "        if not self.updated:\n",
    "            self.cv_split()\n",
    "            self.K_cv_error = []\n",
    "            for K in K_lst:\n",
    "                current_K_algorithm = self.algorithm(K, ignore_warning=True)\n",
    "                self.K_cv_error.append(self.cal_cv_error(current_K_algorithm, cv_num))\n",
    "            self.lowest_error = np.min(self.K_cv_error)\n",
    "            self.lowest_error_K = K_lst[np.argmin(self.K_cv_error)]\n",
    "            self.updated = True\n",
    "        return self.lowest_error, self.lowest_error_K, self.K_cv_error\n",
    "\n",
    "    def update_signal(self, new_signal):\n",
    "        \"\"\"\n",
    "        Update the signal and reset the updated flag\n",
    "\n",
    "        Args:\n",
    "            new_signal: the new signal\n",
    "        \"\"\"\n",
    "        self.signal = new_signal\n",
    "        self.updated = False\n",
    "    \n",
    "    def update_algorithm(self, new_algorithm):\n",
    "        \"\"\"\n",
    "        Update the algorithm and reset the updated flag\n",
    "\n",
    "        Args:\n",
    "            new_algorithm: the new algorithm\n",
    "        \"\"\"\n",
    "        self.algorithm = new_algorithm\n",
    "        self.updated = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleTesting:\n",
    "    def __init__(self, configs: DictConfig):\n",
    "        \"\"\"\n",
    "        Initialize the EnsembleTesting class\n",
    "\n",
    "        Args:\n",
    "            configs: the configuration\n",
    "        \"\"\"\n",
    "        self.N = configs.N\n",
    "        self.d = configs.d\n",
    "        self.m = configs.m\n",
    "        self.noise_level_lst = configs.noise_level_lst\n",
    "        self.cv_num = configs.cv_num\n",
    "        self.K_lst = configs.K_lst\n",
    "        self.trial_num = configs.trial_num\n",
    "        self.output_filename = configs.output_filename+ str(self.N) + '_' + str(self.d) + '_' + str(self.m) + '_' + str(self.trial_num) + '_' + str(self.cv_num) + '.pkl'\n",
    "        if not os.path.exists('./memory'):\n",
    "            os.mkdir('./memory')\n",
    "\n",
    "    def cv_best_K_noise_level_multi_trial(self):\n",
    "        res_log = {\n",
    "            'parameters': {\n",
    "                'N': self.N, \n",
    "                'd': self.d, \n",
    "                'm': self.m, \n",
    "                'noise_level_lst': self.noise_level_lst, \n",
    "                'cv_num': self.cv_num, \n",
    "                'trial_num': self.trial_num, \n",
    "                'K_lst': self.K_lst\n",
    "            },\n",
    "            'noise_level_best_K': [],\n",
    "            'noise_level_lowest_MSE': [],\n",
    "            'log': []\n",
    "        }\n",
    "        noise_level_best_K = []\n",
    "        noise_level_lowest_MSE = []\n",
    "        for noise_level in self.noise_level_lst:\n",
    "            print(\"Cross validating K under noise level: \", noise_level)\n",
    "            trials_best_K_tmp = []\n",
    "            MSE_loweset_K_temp = []\n",
    "            for trial in range(self.trial_num):\n",
    "                Data_Geneartor = GaussianDataGenerator(self.N, self.d, self.m, noise_level, trial)\n",
    "                true_signal, dictionary, true_indices, true_coefficients, perturbed_signal = Data_Geneartor.shuffle()\n",
    "                lowest_error, lowest_error_K, cv_err_lst = cv_best_K(perturbed_signal, dictionary, self.cv_num, self.K_lst)\n",
    "                trials_best_K_tmp.append(lowest_error_K)\n",
    "                MSE_loweset_K_temp.append(lowest_error)\n",
    "                print(\"Trial: \", trial, \" Best K: \", lowest_error_K, \" Lowest Error: \", lowest_error)\n",
    "                log_tmp = {\n",
    "                    'noise_level': noise_level, \n",
    "                    'trial': trial, \n",
    "                    'data': Data_Geneartor, \n",
    "                    'cv_error_lst': cv_err_lst, \n",
    "                    'lowest_error': lowest_error, \n",
    "                    'lowest_error_K': lowest_error_K\n",
    "                }\n",
    "                res_log['log'].append(log_tmp)\n",
    "            noise_level_best_K.append(np.mean(trials_best_K_tmp))\n",
    "            noise_level_lowest_MSE.append(np.mean(MSE_loweset_K_temp))\n",
    "            print(\"Average best K for noise level: \", noise_level, \" is: \", np.mean(trials_best_K_tmp), \" with MSE: \", np.mean(MSE_loweset_K_temp))\n",
    "        res_log['noise_level_best_K'] = noise_level_best_K\n",
    "        res_log['noise_level_lowest_MSE'] = noise_level_lowest_MSE\n",
    "        with open('./memory/' + self.output_filename, 'wb') as f:\n",
    "            pkl.dump(res_log, f)\n",
    "        print(\"Finished!\")\n",
    "        print(\"Log file saved to: \", './memory/' + self.output_filename)\n",
    "        return noise_level_best_K, noise_level_lowest_MSE, res_log\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
