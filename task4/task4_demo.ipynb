{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task4 Incorperate CV and OMP class better, and make it more general so we can use it later for ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "from itertools import product\n",
    "from algorithms import OMP\n",
    "from data_generation import GaussianDataGenerator\n",
    "from crossvalidation import CrossValidator\n",
    "import yaml\n",
    "from omegaconf import DictConfig\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 1000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000\n",
    "d = 600\n",
    "m = 20\n",
    "seed = 10\n",
    "\n",
    "Data_Geneartor = GaussianDataGenerator(N, d, m, 0, seed)\n",
    "\n",
    "true_signal, dictionary, true_indices, true_coefficients, perturbed_signal = Data_Geneartor.shuffle()\n",
    "\n",
    "K_lst = np.arange(1, m+20+1, 1).tolist()\n",
    "\n",
    "dictionary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.1130680102711943e-32,\n",
       " 20,\n",
       " [0.0076198510201475975,\n",
       "  0.004069316612261802,\n",
       "  0.002137968529945831,\n",
       "  0.0013949372826701585,\n",
       "  0.0008829274714864061,\n",
       "  0.0005220518071904683,\n",
       "  0.00030171448497390947,\n",
       "  0.00018800966708506196,\n",
       "  0.00012747155016087187,\n",
       "  7.169540216554605e-05,\n",
       "  5.0032965372596205e-05,\n",
       "  3.581876478177004e-05,\n",
       "  2.3305478296258957e-05,\n",
       "  1.8830332705877132e-05,\n",
       "  1.3597016923790235e-05,\n",
       "  9.710030324504057e-06,\n",
       "  5.685545388237914e-06,\n",
       "  2.492047845805853e-06,\n",
       "  1.4087190706205076e-06,\n",
       "  2.1130680102711943e-32,\n",
       "  2.242547803965305e-32,\n",
       "  2.681008826840851e-32,\n",
       "  2.748039840543949e-32,\n",
       "  2.863487930578132e-32,\n",
       "  2.7912098862511556e-32,\n",
       "  3.446862392390281e-32,\n",
       "  3.2695832054632975e-32,\n",
       "  4.100907449187801e-32,\n",
       "  4.859295653867513e-32,\n",
       "  4.201705180721848e-32,\n",
       "  5.297158083673105e-32,\n",
       "  5.020403329911364e-32,\n",
       "  5.434567198020574e-32,\n",
       "  6.024224097227322e-32,\n",
       "  9.502357280293451e-32,\n",
       "  7.422947521071139e-32,\n",
       "  7.747823816210911e-32,\n",
       "  6.268524172932728e-32,\n",
       "  1.2237920494327431e-31,\n",
       "  1.2832796713837895e-31])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cv = CrossValidator(OMP, K_lst, 5, shuffle_split=True, seed=10)\n",
    "my_cv.fit(perturbed_signal, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Algorithm_Manager(method_name):\n",
    "\n",
    "    \"\"\"\n",
    "    This function can return the algorithm based on the method name\n",
    "\n",
    "    Args:\n",
    "        method_name: the name of the algorithm\n",
    "    Returns:\n",
    "        algorithm: the algorithm (class)\n",
    "    \"\"\"\n",
    "    \n",
    "    match method_name:\n",
    "        case \"OMP\":\n",
    "            return OMP\n",
    "        case _:\n",
    "            raise ValueError(\"Invalid method name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleTesting:\n",
    "    \"\"\"\n",
    "\n",
    "    This class can do the ensemble testing for the all EnsembleTesting \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, configs: DictConfig):\n",
    "        \n",
    "        \"\"\"\n",
    "        Initialize the EnsembleTesting class\n",
    "\n",
    "        Args:\n",
    "            configs: the configuration\n",
    "        \"\"\"\n",
    "\n",
    "        ## FIXME:: No default yaml file is provided neither the yaml file generator, I think we could build up a base class so that we can inherit from it and overwrite the function\n",
    "        \n",
    "        self.N = configs.N\n",
    "        self.d = configs.d\n",
    "        self.m = configs.m\n",
    "        self.noise_level_lst = configs.noise_level_lst\n",
    "        self.cv_num = configs.cv_num\n",
    "        self.K_lst = configs.K_lst\n",
    "        self.trial_num = configs.trial_num\n",
    "        self.method_name = configs.method_name\n",
    "        self.algorithm = Algorithm_Manager(self.method_name)\n",
    "        self.output_filename = configs.output_filename+ str(self.N) + '_' + str(self.d) + '_' + str(self.m) + '_' + str(self.trial_num) + '_' + str(self.cv_num) + '.pkl'\n",
    "        if not os.path.exists('./memory'):\n",
    "            os.mkdir('./memory')\n",
    "\n",
    "    def cv_best_K_noise_level_multi_trial(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Cross validate the best K for selected algorithm under different noise level and different trials\n",
    "\n",
    "        Returns:\n",
    "            cv_res_log: the log of cross validation results\n",
    "        \"\"\"\n",
    "\n",
    "        res_log = {\n",
    "            'parameters': {\n",
    "                'N': self.N, \n",
    "                'd': self.d, \n",
    "                'm': self.m, \n",
    "                'noise_level_lst': self.noise_level_lst, \n",
    "                'cv_num': self.cv_num, \n",
    "                'trial_num': self.trial_num, \n",
    "                'K_lst': self.K_lst\n",
    "            },\n",
    "            'log': []\n",
    "        }\n",
    "        \n",
    "        for trial in range(self.trial_num):\n",
    "            Data_Geneartor = GaussianDataGenerator(self.N, self.d, self.m, trial)\n",
    "            true_signal, dictionary, true_indices, true_coefficients = Data_Geneartor.shuffle()\n",
    "            cross_validation = CrossValidator(true_signal, dictionary, self.cv_num, self.K_lst, self.algorithm)\n",
    "            # In the same trial we have the same true signal and dictionary, so that it is comparable between different noise level\n",
    "            for noise_level in self.noise_level_lst:\n",
    "                print(\"Cross validating K under noise level: \", noise_level)\n",
    "                true_signal, dictionary, true_indices, true_coefficients, perturbed_signal = Data_Geneartor.update_noise_level(noise_level)\n",
    "                # We only need to update the signal and change the corresponding part in the cv_res\n",
    "                cross_validation.update_signal(perturbed_signal)\n",
    "                cv_err_lst = cross_validation.cross_validate()\n",
    "                # We do not need to store the lowest error and lowest error K because we can calculate it from the cv_err_lst\n",
    "                log_tmp = {\n",
    "                    'noise_level': noise_level, \n",
    "                    'trial': trial, \n",
    "                    'data': Data_Geneartor, \n",
    "                    'cv_error_lst': cv_err_lst \n",
    "                    # 'lowest_error': lowest_error, \n",
    "                    # 'lowest_error_K': lowest_error_K\n",
    "                }\n",
    "                res_log['log'].append(log_tmp)\n",
    "                print(\"trial {} at noise level {} finished!\".format(trial, noise_level))\n",
    "            print(\"trial {} finished!\".format(trial))\n",
    "\n",
    "\n",
    "        ##FIXME:: Calculate the lowest error and lowest error K from the res_log or we can do that later when we visualize the final results\n",
    "        \n",
    "\n",
    "\n",
    "        # Save the log file\n",
    "        with open('./memory/' + self.output_filename, 'wb') as f:\n",
    "            pkl.dump(res_log, f)\n",
    "            print(\"Log file saved to: \", './memory/' + self.output_filename)\n",
    "        print(\"Finished!\")\n",
    "        return res_log\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
