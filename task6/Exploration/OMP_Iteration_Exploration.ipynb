{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from sklearn.base import BaseEstimator\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from data_generation import GaussianDataGenerator\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtomBaggingBase(BaseEstimator):\n",
    "    # Submodel base\n",
    "    def __init__(\n",
    "        self,\n",
    "        K,\n",
    "        atom_bag_percent=1,\n",
    "        select_atom_percent=0,\n",
    "        random_seed=0,\n",
    "        ignore_warning=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "\n",
    "        This class is used to perform atom bagging\n",
    "        Each object of this class is a submodel\n",
    "\n",
    "        K (int): Number of iterations\n",
    "        atom_bag_percent (float): Percentage of the original dictionary\n",
    "        select_atom_percent (float): Percentage of the selected atoms\n",
    "        random_seed (int): Random seed\n",
    "        \"\"\"\n",
    "\n",
    "        self.K = K\n",
    "        self.atom_bag_percent = np.max([0, np.min([1, atom_bag_percent])])\n",
    "        self.select_atom_percent = np.max([0, np.min([1, select_atom_percent])])\n",
    "        self.atom_bag_flag = atom_bag_percent < 1\n",
    "        self.atom_weak_select_flag = select_atom_percent > 0\n",
    "\n",
    "        self.indices = []\n",
    "        self.s = None\n",
    "        self.phi = None\n",
    "        self.a = None\n",
    "        self.coefficients = None\n",
    "        self.r = None\n",
    "\n",
    "        self.random_seed = random_seed\n",
    "        self.ignore_warning = ignore_warning\n",
    "\n",
    "    def fit(self, phi, s):\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        self.indices = []\n",
    "        self.s = None\n",
    "        self.phi = None\n",
    "        self.a = None\n",
    "        self.coefficients = None\n",
    "        self.r = None\n",
    "\n",
    "    def fit(self, phi, s):\n",
    "        return None\n",
    "\n",
    "    def predict(self, phi_test):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        phi_test (numpy.ndarray): Test data\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray: Predicted output\n",
    "        \"\"\"\n",
    "\n",
    "        return phi_test @ self.coefficients\n",
    "\n",
    "    def score(self, phi_test, s_test):\n",
    "        s_pred = phi_test @ self.final_c\n",
    "        pred_mse = np.mean((s_pred - s_test) ** 2)\n",
    "        return pred_mse\n",
    "\n",
    "    def input_coefficients(self, coefficients):\n",
    "        self.coefficients = coefficients\n",
    "\n",
    "    def update_seed(self, random_seed):\n",
    "        self.random_seed = random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OMP_Explore(AtomBaggingBase):\n",
    "    def __init__(\n",
    "        self, K_lst, select_atom_percent=0, random_seed=None, ignore_warning=False\n",
    "    ):\n",
    "        self.K_lst = K_lst\n",
    "        self.random_seed = random_seed\n",
    "        self.select_atom_percent = select_atom_percent\n",
    "        if select_atom_percent == 0:\n",
    "            self.atom_weak_select_flag = False\n",
    "\n",
    "        self.indices = []\n",
    "        self.coefficients = None\n",
    "        self.ignore_warning = ignore_warning\n",
    "\n",
    "        self.coefficients_matrix = None\n",
    "        self.error_series = []\n",
    "\n",
    "    def fit(self, phi, s):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        s (numpy.ndarray): Input signal\n",
    "        phi (numpy.ndarray): Dictionary\n",
    "        \"\"\"\n",
    "        self.reset()\n",
    "        self.s = s\n",
    "        self.phi = phi\n",
    "        self.a = np.zeros_like(self.s)\n",
    "        self.coefficients = np.zeros(phi.shape[1])\n",
    "        self.r = self.s.copy()\n",
    "\n",
    "        self.coefficients_matrix = np.zeros((phi.shape[1], len(self.K_lst)))\n",
    "\n",
    "        if self.random_seed is not None:\n",
    "            np.random.seed(self.random_seed)\n",
    "\n",
    "        for k in range(np.max(self.K_lst)+1):\n",
    "            inner_products = (phi.T @ self.r).flatten()\n",
    "            # so that we will not select the same atom\n",
    "            inner_products[self.indices] = 0\n",
    "            if self.atom_weak_select_flag:\n",
    "                top_ind = np.argsort(np.abs(inner_products))[::-1][\n",
    "                    : int(phi.shape[1] * self.select_atom_percent)\n",
    "                ]\n",
    "                # randomly select one atom\n",
    "                lambda_k = np.random.choice(top_ind)\n",
    "            else:\n",
    "                lambda_k = np.argmax(np.abs(inner_products))\n",
    "\n",
    "            # Ordinary least squares\n",
    "            X = phi[:, self.indices + [lambda_k]]\n",
    "\n",
    "            try:\n",
    "                betas = np.linalg.inv(X.T @ X) @ X.T @ self.s\n",
    "            except:\n",
    "                if not self.ignore_warning:\n",
    "                    print(\"Singular matrix encountered in OMP\")\n",
    "                break\n",
    "\n",
    "            # Update indices\n",
    "            self.indices.append(lambda_k)\n",
    "\n",
    "            # Update Coefficients\n",
    "            self.coefficients = np.zeros(phi.shape[1])\n",
    "            self.coefficients[self.indices] = betas.flatten()\n",
    "\n",
    "            # Update Projection\n",
    "            self.a = X @ betas\n",
    "\n",
    "            # Update Residual\n",
    "            self.r = self.s - self.a\n",
    "            if k in self.K_lst:\n",
    "                self.coefficients_matrix[:, self.K_lst.index(k)] = self.coefficients\n",
    "                self.error_series.append(np.sum(self.r**2))\n",
    "\n",
    "\n",
    "        minimal_k_index = np.argmin(self.error_series)\n",
    "\n",
    "        # Update Coefficients\n",
    "\n",
    "        self.coefficients = self.coefficients_matrix[:,minimal_k_index]\n",
    "\n",
    "        # Update Projection\n",
    "        self.a = phi @ self.coefficients\n",
    "\n",
    "        # Update Residual\n",
    "        self.r = self.s - self.a\n",
    "\n",
    "        return self.a, self.coefficients\n",
    "\n",
    "    def multi_score(self, phi_test, s_test):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        phi_test (numpy.ndarray): Test data\n",
    "        s_test (numpy.ndarray): Test labels\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray: Predicted output\n",
    "        \"\"\"\n",
    "\n",
    "        test_score = []\n",
    "        projection_matrix = phi_test @ self.coefficients_matrix\n",
    "        residual_matrix = s_test.reshape(-1, 1) - projection_matrix\n",
    "        test_score = np.mean(residual_matrix**2,axis = 0)\n",
    "        return test_score\n",
    "\n",
    "    def reset(self):\n",
    "        super().reset()\n",
    "        self.coefficients_matrix = None\n",
    "        self.error_series = []\n",
    "\n",
    "def cv_split(true_signal, dictionary, cv_num):\n",
    "    true_signal = true_signal.ravel()\n",
    "    cv_signal = np.split(true_signal, cv_num)\n",
    "    cv_dictionary = np.split(dictionary, cv_num)\n",
    "    # Get the list of train and test set\n",
    "    cv_res = []\n",
    "    for i in range(cv_num):\n",
    "        train_signal = np.concatenate(cv_signal[:i] + cv_signal[i + 1 :], axis=0)\n",
    "        train_dictionary = np.concatenate(\n",
    "            cv_dictionary[:i] + cv_dictionary[i + 1 :], axis=0\n",
    "        )\n",
    "        test_signal = cv_signal[i]\n",
    "        test_dictionary = cv_dictionary[i]\n",
    "        cv_res.append((train_signal, train_dictionary, test_signal, test_dictionary))\n",
    "    return cv_res\n",
    "\n",
    "\n",
    "def cal_cv_error(algorithm, cv_num, signal, dictionary):\n",
    "    cv_res = cv_split(signal, dictionary, cv_num)\n",
    "    error_matrix = np.zeros((cv_num, len(algorithm.K_lst)))\n",
    "    for i in range(cv_num):\n",
    "        train_signal, train_dictionary, test_signal, test_dictionary = cv_res[i]\n",
    "        algorithm.fit(train_dictionary,train_signal)\n",
    "        error_matrix[i,:] = algorithm.multi_score(test_dictionary,test_signal)\n",
    "    return np.mean(error_matrix,axis = 0)\n",
    "\n",
    "\n",
    "def cv_best_K(signal, dictionary, cv_num, K_lst):\n",
    "\n",
    "    K_cv_error = []\n",
    "    OMP_tmp = OMP_Explore(K_lst, ignore_warning=True)\n",
    "    K_cv_error = cal_cv_error(OMP_tmp, cv_num, signal, dictionary)\n",
    "    lowest_error = np.min(K_cv_error)\n",
    "    lowest_error_K = K_lst[np.argmin(K_cv_error)]\n",
    "    return lowest_error, lowest_error_K, K_cv_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating K under noise level:  0.1\n",
      "Trial:  0  Best K:  12  Lowest Error:  0.011804923923324656\n",
      "Trial:  1  Best K:  14  Lowest Error:  0.009751582425454446\n",
      "Trial:  2  Best K:  17  Lowest Error:  0.01051267407359402\n",
      "Trial:  3  Best K:  17  Lowest Error:  0.011083424058424543\n",
      "Trial:  4  Best K:  16  Lowest Error:  0.010625423024419493\n",
      "Trial:  5  Best K:  11  Lowest Error:  0.010547946303916568\n",
      "Trial:  6  Best K:  13  Lowest Error:  0.011492231874623084\n",
      "Trial:  7  Best K:  17  Lowest Error:  0.012630563987436458\n",
      "Trial:  8  Best K:  13  Lowest Error:  0.010954758886104449\n",
      "Trial:  9  Best K:  15  Lowest Error:  0.01034220334737489\n",
      "Average best K for noise level:  0.1  is:  14.5  with MSE:  0.01097457319046726\n",
      "Cross validating K under noise level:  0.3\n",
      "Trial:  0  Best K:  8  Lowest Error:  0.10426860801834041\n",
      "Trial:  1  Best K:  2  Lowest Error:  0.09556435060037785\n",
      "Trial:  2  Best K:  9  Lowest Error:  0.10275167040559799\n",
      "Trial:  3  Best K:  2  Lowest Error:  0.10707146772214686\n",
      "Trial:  4  Best K:  8  Lowest Error:  0.10505393877465392\n",
      "Trial:  5  Best K:  6  Lowest Error:  0.09090143627738942\n",
      "Trial:  6  Best K:  1  Lowest Error:  0.10617414297524845\n",
      "Trial:  7  Best K:  6  Lowest Error:  0.11787557449034973\n",
      "Trial:  8  Best K:  5  Lowest Error:  0.10538574870105788\n",
      "Trial:  9  Best K:  8  Lowest Error:  0.10498234710529768\n",
      "Average best K for noise level:  0.3  is:  5.5  with MSE:  0.10400292850704602\n",
      "Cross validating K under noise level:  0.5\n",
      "Trial:  0  Best K:  2  Lowest Error:  0.2960846008456508\n",
      "Trial:  1  Best K:  4  Lowest Error:  0.255307987115838\n",
      "Trial:  2  Best K:  2  Lowest Error:  0.2874253428349661\n",
      "Trial:  3  Best K:  2  Lowest Error:  0.2783849059656115\n",
      "Trial:  4  Best K:  2  Lowest Error:  0.27612429841755204\n",
      "Trial:  5  Best K:  2  Lowest Error:  0.25295686716153826\n",
      "Trial:  6  Best K:  1  Lowest Error:  0.2855008538899871\n",
      "Trial:  7  Best K:  2  Lowest Error:  0.3202424507187342\n",
      "Trial:  8  Best K:  2  Lowest Error:  0.284850112124076\n",
      "Trial:  9  Best K:  1  Lowest Error:  0.29392376332061454\n",
      "Average best K for noise level:  0.5  is:  2.0  with MSE:  0.28308011823945683\n",
      "Finished!\n",
      "Log file saved to:  ./memory/OMPtest_002_01.pkl.pkl\n"
     ]
    }
   ],
   "source": [
    "output_path = \"./memory/\"  # your specified path here\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "\n",
    "def cv_best_K_noise_level_multi_trial(\n",
    "    N, d, m, noise_level_lst, cv_num, K_lst, trial_num, output_filename=None\n",
    "):\n",
    "    if output_filename is None:\n",
    "        output_filename = (\n",
    "            \"OMP\"\n",
    "            + str(N)\n",
    "            + \"_\"\n",
    "            + str(d)\n",
    "            + \"_\"\n",
    "            + str(m)\n",
    "            + \"_\"\n",
    "            + str(trial_num)\n",
    "            + \"_\"\n",
    "            + str(cv_num)\n",
    "            + \".pkl\"\n",
    "        )\n",
    "    else:\n",
    "        output_filename = \"OMP\" + output_filename + \".pkl\"\n",
    "    res_log = {\n",
    "        \"parameters\": {\n",
    "            \"N\": N,\n",
    "            \"d\": d,\n",
    "            \"m\": m,\n",
    "            \"noise_level_lst\": noise_level_lst,\n",
    "            \"cv_num\": cv_num,\n",
    "            \"trial_num\": trial_num,\n",
    "            \"K_lst\": K_lst,\n",
    "        },\n",
    "        \"noise_level_best_K\": [],\n",
    "        \"noise_level_lowest_MSE\": [],\n",
    "        \"log\": [],\n",
    "    }\n",
    "    noise_level_best_K = []\n",
    "    noise_level_lowest_MSE = []\n",
    "    for noise_level in noise_level_lst:\n",
    "        print(\"Cross validating K under noise level: \", noise_level)\n",
    "        trials_best_K_tmp = []\n",
    "        MSE_loweset_K_temp = []\n",
    "        for trial in range(trial_num):\n",
    "            Data_Geneartor = GaussianDataGenerator(N, d, m, noise_level, trial)\n",
    "            (\n",
    "                true_signal,\n",
    "                dictionary,\n",
    "                true_indices,\n",
    "                true_coefficients,\n",
    "                perturbed_signal,\n",
    "            ) = Data_Geneartor.shuffle()\n",
    "            lowest_error, lowest_error_K, cv_err_lst = cv_best_K(\n",
    "                perturbed_signal, dictionary, cv_num, K_lst\n",
    "            )\n",
    "            trials_best_K_tmp.append(lowest_error_K)\n",
    "            MSE_loweset_K_temp.append(lowest_error)\n",
    "            print(\n",
    "                \"Trial: \",\n",
    "                trial,\n",
    "                \" Best K: \",\n",
    "                lowest_error_K,\n",
    "                \" Lowest Error: \",\n",
    "                lowest_error,\n",
    "            )\n",
    "            log_tmp = {\n",
    "                \"noise_level\": noise_level,\n",
    "                \"trial\": trial,\n",
    "                \"data\": Data_Geneartor,\n",
    "                \"cv_error_lst\": cv_err_lst,\n",
    "                \"lowest_error\": lowest_error,\n",
    "                \"lowest_error_K\": lowest_error_K,\n",
    "            }\n",
    "            res_log[\"log\"].append(log_tmp)\n",
    "        noise_level_best_K.append(np.mean(trials_best_K_tmp))\n",
    "        noise_level_lowest_MSE.append(np.mean(MSE_loweset_K_temp))\n",
    "        print(\n",
    "            \"Average best K for noise level: \",\n",
    "            noise_level,\n",
    "            \" is: \",\n",
    "            np.mean(trials_best_K_tmp),\n",
    "            \" with MSE: \",\n",
    "            np.mean(MSE_loweset_K_temp),\n",
    "        )\n",
    "    res_log[\"noise_level_best_K\"] = noise_level_best_K\n",
    "    res_log[\"noise_level_lowest_MSE\"] = noise_level_lowest_MSE\n",
    "    with open(os.path.join(output_path, output_filename), \"wb\") as f:\n",
    "        pkl.dump(res_log, f)\n",
    "    print(\"Finished!\")\n",
    "    print(\"Log file saved to: \", os.path.join(output_path, output_filename))\n",
    "    return noise_level_best_K, noise_level_lowest_MSE, res_log\n",
    "\n",
    "\n",
    "noise_level_lst = [0.1, 0.3, 0.5]\n",
    "N = 1000\n",
    "d = 600\n",
    "m = 20\n",
    "trial_num = 10\n",
    "cv_num = 5\n",
    "K_lst = list(range(1, 21, 1))\n",
    "\n",
    "\n",
    "noise_level_best_K,noise_level_lowest_MSE,res_log= cv_best_K_noise_level_multi_trial(N,d,m,noise_level_lst,cv_num,K_lst,trial_num,output_filename=\"test_002_01.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignalAtomBagging:\n",
    "    def __init__(\n",
    "        self,\n",
    "        N,\n",
    "        signal_bag_percent=0.7,\n",
    "        atom_bag_percent=0.7,\n",
    "        replace_flag=True,\n",
    "        random_seed=None,\n",
    "    ):\n",
    "        \"\"\" \"\n",
    "        This class is used to perform signal bagging\n",
    "\n",
    "        Args:\n",
    "        N (int): Number of bootstrap samples\n",
    "        signal_bag_percent (float): Percentage of the original signal\n",
    "        replace_flag (bool): Whether to sample with replacement\n",
    "        random_seed (int): Random\n",
    "        \"\"\"\n",
    "        self.s = None\n",
    "        self.phi = None\n",
    "        self.N = N\n",
    "        self.replace_flag = replace_flag\n",
    "        self.random_seed = random_seed\n",
    "        self.signal_bag_percent = signal_bag_percent\n",
    "        self.atom_bag_percent = atom_bag_percent\n",
    "        self.s_bag = []\n",
    "        self.phi_bag = []\n",
    "        self.col_idx_bag = []\n",
    "\n",
    "    def fit(self, phi, s):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        s (numpy.ndarray): Input signal\n",
    "        phi (numpy.ndarray): Dictionary\n",
    "        \"\"\"\n",
    "\n",
    "        self.s = s\n",
    "        self.phi = phi\n",
    "\n",
    "        num_samples = int(self.signal_bag_percent * self.s.shape[0])\n",
    "        num_atoms = int(self.atom_bag_percent * self.phi.shape[1])\n",
    "\n",
    "        if self.random_seed is not None:\n",
    "            np.random.seed(self.random_seed)\n",
    "\n",
    "        if self.signal_bag_percent:\n",
    "            for _ in range(self.N):\n",
    "                row_indices = np.random.choice(\n",
    "                    self.s.shape[0], num_samples, replace=self.replace_flag\n",
    "                )\n",
    "                col_indices = np.random.choice(\n",
    "                    self.phi.shape[1], num_atoms, replace=False\n",
    "                )\n",
    "                s_tmp = self.s[row_indices]\n",
    "                phi_tmp = self.phi[row_indices, :][:, col_indices]\n",
    "                self.s_bag.append(s_tmp)\n",
    "                self.phi_bag.append(phi_tmp)\n",
    "                self.col_idx_bag.append(col_indices)\n",
    "        else:\n",
    "            self.s_bag = [self.s] * self.N\n",
    "            for _ in range(self.N):\n",
    "                col_indices = np.random.choice(\n",
    "                    self.phi.shape[1], num_atoms, replace=False\n",
    "                )\n",
    "                phi_tmp = self.phi[:, col_indices]\n",
    "                self.phi_bag.append(phi_tmp)\n",
    "                self.col_idx_bag.append(col_indices)\n",
    "\n",
    "        return self.s_bag, self.phi_bag, self.col_idx_bag\n",
    "\n",
    "class OMP_Augmented(AtomBaggingBase):\n",
    "    def __init__(\n",
    "        self, K_lst, select_atom_percent=0, random_seed=None, ignore_warning=False\n",
    "    ):\n",
    "        self.K_lst = K_lst\n",
    "        self.random_seed = random_seed\n",
    "        self.select_atom_percent = select_atom_percent\n",
    "        if select_atom_percent == 0:\n",
    "            self.atom_weak_select_flag = False\n",
    "\n",
    "        self.indices = []\n",
    "        self.coefficients = None\n",
    "        self.ignore_warning = ignore_warning\n",
    "\n",
    "        self.coefficients_matrix = None\n",
    "        self.error_series = []\n",
    "\n",
    "    def fit(self, phi, s):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        s (numpy.ndarray): Input signal\n",
    "        phi (numpy.ndarray): Dictionary\n",
    "        \"\"\"\n",
    "        self.reset()\n",
    "        self.s = s\n",
    "        self.phi = phi\n",
    "        self.a = np.zeros_like(self.s)\n",
    "        self.coefficients = np.zeros(phi.shape[1])\n",
    "        self.r = self.s.copy()\n",
    "\n",
    "        self.coefficients_matrix = np.zeros((phi.shape[1], len(self.K_lst)))\n",
    "\n",
    "        if self.random_seed is not None:\n",
    "            np.random.seed(self.random_seed)\n",
    "\n",
    "        for k in range(np.max(self.K_lst)+1):\n",
    "            inner_products = (phi.T @ self.r).flatten()\n",
    "            # so that we will not select the same atom\n",
    "            inner_products[self.indices] = 0\n",
    "            if self.atom_weak_select_flag:\n",
    "                top_ind = np.argsort(np.abs(inner_products))[::-1][\n",
    "                    : int(phi.shape[1] * self.select_atom_percent)\n",
    "                ]\n",
    "                # randomly select one atom\n",
    "                lambda_k = np.random.choice(top_ind)\n",
    "            else:\n",
    "                lambda_k = np.argmax(np.abs(inner_products))\n",
    "\n",
    "            # Ordinary least squares\n",
    "            X = phi[:, self.indices + [lambda_k]]\n",
    "\n",
    "            try:\n",
    "                betas = np.linalg.inv(X.T @ X) @ X.T @ self.s\n",
    "            except:\n",
    "                if not self.ignore_warning:\n",
    "                    print(\"Singular matrix encountered in OMP\")\n",
    "                break\n",
    "\n",
    "            # Update indices\n",
    "            self.indices.append(lambda_k)\n",
    "\n",
    "            # Update Coefficients\n",
    "            self.coefficients = np.zeros(phi.shape[1])\n",
    "            self.coefficients[self.indices] = betas.flatten()\n",
    "\n",
    "            # Update Projection\n",
    "            self.a = X @ betas\n",
    "\n",
    "            # Update Residual\n",
    "            self.r = self.s - self.a\n",
    "            if k in self.K_lst:\n",
    "                self.coefficients_matrix[:, self.K_lst.index(k)] = self.coefficients\n",
    "                self.error_series.append(np.sum(self.r**2))\n",
    "\n",
    "\n",
    "        minimal_k_index = np.argmin(self.error_series)\n",
    "\n",
    "        # Update Coefficients\n",
    "\n",
    "        self.coefficients = self.coefficients_matrix[:,minimal_k_index]\n",
    "\n",
    "        # Update Projection\n",
    "        self.a = phi @ self.coefficients\n",
    "\n",
    "        # Update Residual\n",
    "        self.r = self.s - self.a\n",
    "\n",
    "        return self.a, self.coefficients\n",
    "\n",
    "    def multi_score(self, phi_test, s_test):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        phi_test (numpy.ndarray): Test data\n",
    "        s_test (numpy.ndarray): Test labels\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray: Predicted output\n",
    "        \"\"\"\n",
    "\n",
    "        test_score = []\n",
    "        projection_matrix = phi_test @ self.coefficients_matrix\n",
    "        residual_matrix = s_test.reshape(-1, 1) - projection_matrix\n",
    "        test_score = np.mean(residual_matrix**2,axis = 0)\n",
    "        return test_score\n",
    "\n",
    "    def reset(self):\n",
    "        super().reset()\n",
    "        self.coefficients_matrix = None\n",
    "        self.error_series = []\n",
    "\n",
    "class BOMP(AtomBaggingBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        N_bag=10,\n",
    "        K_lst=list(range(1, 21)),\n",
    "        signal_bag_percent=0.7,\n",
    "        atom_bag_percent=1,\n",
    "        select_atom_percent=0,\n",
    "        replace_flag=True,\n",
    "        agg_func=\"weight\",\n",
    "        random_seed=None,\n",
    "        ignore_warning=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        N (int): Number of submodels\n",
    "        K (int): Number of iterations\n",
    "        signal_bag_percent (float): Percentage of the original signal\n",
    "        atom_bag_percent (float): Percentage of the original dictionary\n",
    "        select_atom_percent (float): Percentage of the selected atoms\n",
    "        replace_flag (bool): Whether to replace the samples\n",
    "        agg_func (str): Aggregation function\n",
    "        random_seed (int): Random seed\n",
    "        \"\"\"\n",
    "        self.N_bag = N_bag\n",
    "        self.K_lst = K_lst\n",
    "        self.signal_bag_percent = signal_bag_percent\n",
    "        self.atom_bag_percent = atom_bag_percent\n",
    "        self.select_atom_percent = select_atom_percent\n",
    "        self.replace_flag = replace_flag\n",
    "        self.agg_func = agg_func\n",
    "        self.random_seed = random_seed\n",
    "        self.ignore_warning = ignore_warning\n",
    "        self.s = None\n",
    "        self.phi = None\n",
    "        self.tmpPursuitModel = OMP_Augmented(\n",
    "            K_lst, select_atom_percent, random_seed, ignore_warning\n",
    "        )\n",
    "        self.SignalBagging = None\n",
    "        self.coefficients_lst = []\n",
    "        self.mse_lst = []\n",
    "        self.coefficients = None\n",
    "        self.a = None\n",
    "        self.bag_k_lst = []\n",
    "\n",
    "    def agg_weight_with_error(self, c_lst, mse_lst):\n",
    "        \"\"\"\n",
    "        This function is used to aggregate the coefficients with the inverse of the mean squared error\n",
    "\n",
    "        Args:\n",
    "        c_lst (list): List of coefficients\n",
    "        mse_lst (list): List of mean squared errors\n",
    "        \"\"\"\n",
    "        # Calculate the weight\n",
    "        mse_lst = np.array(mse_lst)\n",
    "        weight = 1 / mse_lst\n",
    "        weight = weight / np.sum(weight)\n",
    "\n",
    "        # Calculate the weighted average\n",
    "        tot = np.zeros_like(c_lst[0])\n",
    "        for i in range(len(c_lst)):\n",
    "            tot += c_lst[i] * weight[i]\n",
    "        return tot\n",
    "\n",
    "    def agg_weight_with_avg(self, c_lst):\n",
    "        \"\"\"\n",
    "        This function is used to aggregate the coefficients with the inverse of the mean squared error\n",
    "\n",
    "        Args:\n",
    "        c_lst (list): List of coefficients\n",
    "        \"\"\"\n",
    "        # Calculate the weighted average\n",
    "        tot = np.zeros_like(c_lst[0])\n",
    "        for i in range(len(c_lst)):\n",
    "            tot += c_lst[i]\n",
    "        return tot / len(c_lst)\n",
    "\n",
    "    def fit(self, phi, s):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        s (numpy.ndarray): Input signal\n",
    "        phi (numpy.ndarray): Dictionary\n",
    "        \"\"\"\n",
    "        self.reset()\n",
    "\n",
    "        self.s = s\n",
    "        self.phi = phi\n",
    "        self.SignalBagging = SignalAtomBagging(\n",
    "            self.N_bag,\n",
    "            self.signal_bag_percent,\n",
    "            self.atom_bag_percent,\n",
    "            self.replace_flag,\n",
    "            self.random_seed,\n",
    "        )\n",
    "        self.SignalBagging.fit(self.phi, self.s)\n",
    "\n",
    "        s_bag = self.SignalBagging.s_bag\n",
    "        phi_bag = self.SignalBagging.phi_bag\n",
    "        col_idx_bag = self.SignalBagging.col_idx_bag\n",
    "        self.coefficients_cubic = np.zeros((self.N_bag, phi.shape[1], len(self.k_lst)))\n",
    "\n",
    "        for i in range(self.N_bag):\n",
    "            sub_s = s_bag[i]\n",
    "            sub_phi = phi_bag[i]\n",
    "            sub_idx = col_idx_bag[i]\n",
    "            self.tmpPursuitModel = OMP_Augmented(\n",
    "                self.K_lst,\n",
    "                self.select_atom_percent,\n",
    "                np.random.randint(10000),\n",
    "                self.ignore_warning,\n",
    "            )\n",
    "            self.tmpPursuitModel.fit(sub_phi, sub_s)\n",
    "            real_sub_coefficients = np.zeros((phi.shape[1], len(self.K_lst)))\n",
    "            real_sub_coefficients[:,sub_idx] = np.array(self.tmpPursuitModel.coefficients_list)\n",
    "            self.coefficients_cubic[i] = real_sub_coefficients\n",
    "            self.tmpPursuitModel.reset()\n",
    "        self.coefficients_per_k = self.coefficients_cubic.mean(axis=0)\n",
    "\n",
    "        self.a = self.phi @ self.coefficients\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        This function is used to reset the model\n",
    "        \"\"\"\n",
    "        super().reset()\n",
    "        self.coefficients_lst = []\n",
    "        self.mse_lst = []\n",
    "        self.coefficients = None\n",
    "        self.a = None\n",
    "        self.bag_k_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
