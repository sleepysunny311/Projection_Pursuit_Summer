{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import product\n",
    "from datetime import datetime\n",
    "# from algorithms import BOMP\n",
    "from data_generation import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_trials_npm_multi_noise_lvl(\n",
    "    n, p, m, noise_level_lst, model_name, fixed_params, param_grid, cv_num, trial_num\n",
    "):\n",
    "    # get the model\n",
    "\n",
    "    if model_name == \"BOMP\":\n",
    "        model = BOMP(**fixed_params)\n",
    "\n",
    "    res_log_npm = {\n",
    "        \"parameters\": {\n",
    "            \"n\": n,\n",
    "            \"p\": p,\n",
    "            \"m\": m,\n",
    "            \"noise_level_lst\": noise_level_lst,\n",
    "            \"model_name\": model_name,\n",
    "            \"cv_num\": cv_num,\n",
    "            \"trial_num\": trial_num,\n",
    "            \"param_grid\": param_grid,\n",
    "            \"fixed_params\": fixed_params,\n",
    "        },\n",
    "        \"noise_level_lowest_MSE\": [],\n",
    "        \"log\": [],\n",
    "    }\n",
    "    print(f\"Running trials for n = {n}, p = {p}, m = {m}\")\n",
    "    for noise_level in noise_level_lst:\n",
    "        print(\"Cross validating alpha under noise level: \", noise_level)\n",
    "        trials_loweset_cv_MSE_temp = []\n",
    "        trials_testing_score_temp = []\n",
    "        for trial_id in range(trial_num):\n",
    "            print(\"Trial: \", trial_id)\n",
    "            Data_Geneartor = GaussianDataGenerator(p, n, m, noise_level, trial_id)\n",
    "            (\n",
    "                true_signal,\n",
    "                dictionary,\n",
    "                true_indices,\n",
    "                true_coefficients,\n",
    "                perturbed_signal,\n",
    "            ) = Data_Geneartor.shuffle()\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                dictionary, perturbed_signal, test_size=0.2, random_state=trial_id\n",
    "            )\n",
    "            gs = GridSearchCV(\n",
    "                model,\n",
    "                param_grid,\n",
    "                cv=cv_num,\n",
    "                scoring=\"neg_mean_squared_error\",\n",
    "                n_jobs=-1,\n",
    "                verbose=0,\n",
    "            )\n",
    "            gs.fit(X_train, y_train)\n",
    "            cv_err_lst = -gs.cv_results_[\"mean_test_score\"]\n",
    "            param_lst = gs.cv_results_[\"params\"]\n",
    "            best_estimator = gs.best_estimator_\n",
    "            best_estimator.set_bag_lst([best_estimator.optimal_bag])\n",
    "            best_estimator.set_K_lst([best_estimator.optimal_k])\n",
    "            best_estimator.fit(X_train, y_train)\n",
    "            testing_error = mean_squared_error(y_test, best_estimator.predict(X_test))\n",
    "            trials_testing_score_temp.append(testing_error)\n",
    "            lowest_cv_error = np.min(cv_err_lst)\n",
    "            trials_loweset_cv_MSE_temp.append(lowest_cv_error)\n",
    "            best_params = gs.best_params_\n",
    "            reslog_one_trial = {\n",
    "                \"noise_level\": noise_level,\n",
    "                \"trial\": trial_id,\n",
    "                \"cv_error_lst\": cv_err_lst,\n",
    "                \"lowest_cv_error\": lowest_cv_error,\n",
    "                \"best_params\": best_params,\n",
    "                \"best_bag\": best_estimator.optimal_bag,\n",
    "                \"best_k\": best_estimator.optimal_k,\n",
    "                \"param_lst\": param_lst,\n",
    "                \"testing_error\": testing_error,\n",
    "            }\n",
    "            res_log_npm[\"log\"].append(reslog_one_trial)\n",
    "            print(\n",
    "                \"Trial: \",\n",
    "                trial_id,\n",
    "                \" Best params: \",\n",
    "                best_params,\n",
    "                \" Lowest Error: \",\n",
    "                lowest_cv_error,\n",
    "                \" Testing Error: \",\n",
    "                testing_error,\n",
    "            )\n",
    "        res_log_npm[\"noise_level_lowest_cv_MSE\"].append(\n",
    "            np.mean(trials_loweset_cv_MSE_temp)\n",
    "        )\n",
    "        res_log_npm[\"trials_testing_score\"].append(np.mean(trials_testing_score_temp))\n",
    "        print(\n",
    "            \"Noise level: \",\n",
    "            noise_level,\n",
    "            \" Avg Testing Lowest MSE: \",\n",
    "            np.mean(trials_testing_score_temp),\n",
    "        )\n",
    "    return res_log_npm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_params(config):\n",
    "    # all_params = OmegaConf.to_container(config, resolve=True)[\"MODEL\"]\n",
    "    all_params = config[\"MODEL\"]\n",
    "    param_grid = {}\n",
    "    fixed_params = {}\n",
    "\n",
    "    Bag_lst = all_params[\"Bag_lst\"]\n",
    "    K_lst = all_params[\"K_lst\"]\n",
    "\n",
    "    del all_params[\"Bag_lst\"]\n",
    "    del all_params[\"K_lst\"]\n",
    "\n",
    "    for param, value in all_params.items():\n",
    "        if isinstance(value, list):\n",
    "            param_grid[param] = value\n",
    "        else:\n",
    "            fixed_params[param] = value\n",
    "\n",
    "    fixed_params[\"Bag_lst\"] = Bag_lst\n",
    "    fixed_params[\"K_lst\"] = K_lst\n",
    "    return fixed_params, param_grid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "\"MODEL\": {\n",
    "    \"Bag_lst\": [1, 50, 100],\n",
    "    \"K_lst\": [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    \"agg_func\": \"weight\",\n",
    "    \"atom_bag_percent\": [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    \"ignore_warning\": True,\n",
    "    \"random_seed\": 1,\n",
    "    \"replace_flag\": False,\n",
    "    \"select_atom_percent\": 0,\n",
    "    \"signal_bag_percent\": [0.6, 0.8, 1],\n",
    "},\n",
    "\"TEST\": {\n",
    "    \"cv_num\": 5,\n",
    "    \"m\": 20,\n",
    "    \"model\": \"BOMP\",\n",
    "    \"n\": 600,\n",
    "    \"noise_levels\": [0.12,0.14],\n",
    "    \"p\": 1000,\n",
    "    \"trial_num\": 20,\n",
    "},\n",
    "\"filename\": \"BOMP_600_1000_20_nr_0713.yaml\",\n",
    "\"hydra\": {\n",
    "    \"hydra_logging\": {\n",
    "        \"level\": \"CRITICAL\"\n",
    "    },\n",
    "    \"job_logging\": {\n",
    "        \"level\": \"CRITICAL\"\n",
    "    },\n",
    "    \"run\": {\n",
    "        \"dir\": \"memory/0713/\"\n",
    "    }\n",
    "}\n",
    "}\n",
    "\n",
    "n_tmp = configs[\"TEST\"][\"n\"]\n",
    "p_tmp = configs[\"TEST\"][\"p\"]\n",
    "m_tmp = configs[\"TEST\"][\"m\"]\n",
    "noise_level_lst = configs[\"TEST\"][\"noise_levels\"]\n",
    "model_name = configs[\"TEST\"][\"model\"]\n",
    "cv_num = configs[\"TEST\"][\"cv_num\"]\n",
    "trial_num = configs[\"TEST\"][\"trial_num\"]\n",
    "\n",
    "# Get n, p, m, noise_level combinations\n",
    "if not isinstance(n_tmp, list):\n",
    "    n_tmp = [n_tmp]\n",
    "if not isinstance(p_tmp, list):\n",
    "    p_tmp = [p_tmp]\n",
    "if not isinstance(m_tmp, list):\n",
    "    m_tmp = [m_tmp]\n",
    "\n",
    "npm_lst = list(product(n_tmp, p_tmp, m_tmp))\n",
    "\n",
    "if not isinstance(noise_level_lst, list):\n",
    "    noise_level_lst = [noise_level_lst]\n",
    "\n",
    "# Get model parameters\n",
    "fixed_params, param_grid = get_model_params(configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "# This file contains classes for different pursuit algorithms\n",
    "\n",
    "\n",
    "class SignalAtomBagging:\n",
    "    def __init__(\n",
    "        self,\n",
    "        N,\n",
    "        signal_bag_percent=0.7,\n",
    "        atom_bag_percent=0.7,\n",
    "        replace_flag=True,\n",
    "        random_seed=None,\n",
    "    ):\n",
    "        \"\"\" \"\n",
    "        This class is used to perform signal bagging\n",
    "\n",
    "        Args:\n",
    "        N (int): Number of bootstrap samples\n",
    "        signal_bag_percent (float): Percentage of the original signal\n",
    "        replace_flag (bool): Whether to sample with replacement\n",
    "        random_seed (int): Random\n",
    "        \"\"\"\n",
    "        self.s = None\n",
    "        self.phi = None\n",
    "        self.N = N\n",
    "        self.replace_flag = replace_flag\n",
    "        self.random_seed = random_seed\n",
    "        self.signal_bag_percent = signal_bag_percent\n",
    "        self.atom_bag_percent = atom_bag_percent\n",
    "        self.s_bag = []\n",
    "        self.phi_bag = []\n",
    "        self.col_idx_bag = []\n",
    "\n",
    "    def fit(self, phi, s):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        s (numpy.ndarray): Input signal\n",
    "        phi (numpy.ndarray): Dictionary\n",
    "        \"\"\"\n",
    "\n",
    "        self.s = s\n",
    "        self.phi = phi\n",
    "\n",
    "        num_samples = int(self.signal_bag_percent * self.s.shape[0])\n",
    "        num_atoms = int(self.atom_bag_percent * self.phi.shape[1])\n",
    "\n",
    "        if self.random_seed is not None:\n",
    "            np.random.seed(self.random_seed)\n",
    "\n",
    "        if self.signal_bag_percent:\n",
    "            for _ in range(self.N):\n",
    "                row_indices = np.random.choice(\n",
    "                    self.s.shape[0], num_samples, replace=self.replace_flag\n",
    "                )\n",
    "                col_indices = np.random.choice(\n",
    "                    self.phi.shape[1], num_atoms, replace=False\n",
    "                )\n",
    "                s_tmp = self.s[row_indices]\n",
    "                phi_tmp = self.phi[row_indices, :][:, col_indices]\n",
    "                self.s_bag.append(s_tmp)\n",
    "                self.phi_bag.append(phi_tmp)\n",
    "                self.col_idx_bag.append(col_indices)\n",
    "        else:\n",
    "            self.s_bag = [self.s] * self.N\n",
    "            for _ in range(self.N):\n",
    "                col_indices = np.random.choice(\n",
    "                    self.phi.shape[1], num_atoms, replace=False\n",
    "                )\n",
    "                phi_tmp = self.phi[:, col_indices]\n",
    "                self.phi_bag.append(phi_tmp)\n",
    "                self.col_idx_bag.append(col_indices)\n",
    "\n",
    "        return self.s_bag, self.phi_bag, self.col_idx_bag\n",
    "\n",
    "\n",
    "class AtomBaggingBase(BaseEstimator):\n",
    "    # Submodel base\n",
    "    def __init__(\n",
    "        self,\n",
    "        K,\n",
    "        select_atom_percent=0,\n",
    "        random_seed=0,\n",
    "        ignore_warning=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "\n",
    "        This class is used to perform atom bagging\n",
    "        Each object of this class is a submodel\n",
    "\n",
    "        K (int): Number of iterations\n",
    "        atom_bag_percent (float): Percentage of the original dictionary\n",
    "        select_atom_percent (float): Percentage of the selected atoms\n",
    "        random_seed (int): Random seed\n",
    "        \"\"\"\n",
    "\n",
    "        self.K = K\n",
    "        self.select_atom_percent = np.max([0, np.min([1, select_atom_percent])])\n",
    "        self.atom_weak_select_flag = select_atom_percent > 0\n",
    "\n",
    "        self.indices = []\n",
    "        self.s = None\n",
    "        self.phi = None\n",
    "        self.a = None\n",
    "        self.coefficients = None\n",
    "        self.r = None\n",
    "\n",
    "        self.random_seed = random_seed\n",
    "        self.ignore_warning = ignore_warning\n",
    "\n",
    "    def reset(self):\n",
    "        self.indices = []\n",
    "        self.s = None\n",
    "        self.phi = None\n",
    "        self.a = None\n",
    "        self.coefficients = None\n",
    "        self.r = None\n",
    "\n",
    "    def fit(self, phi, s):\n",
    "        return None\n",
    "\n",
    "    def predict(self, phi_test):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        phi_test (numpy.ndarray): Test data\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray: Predicted output\n",
    "        \"\"\"\n",
    "        return (phi_test @ self.coefficients).reshape(-1, 1)\n",
    "\n",
    "    def score(self, phi_test, s_test):\n",
    "        # return self.coefficients\n",
    "        s_pred = phi_test @ self.coefficients\n",
    "        pred_mse = np.mean((s_pred - s_test) ** 2)\n",
    "        return pred_mse\n",
    "\n",
    "    def input_coefficients(self, coefficients):\n",
    "        self.coefficients = coefficients\n",
    "\n",
    "    def update_seed(self, random_seed):\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "\n",
    "class AtomBaggingMatchingPursuit(AtomBaggingBase):\n",
    "    def __init__(self, K, atom_bag_percent=1, select_atom_percent=0, random_seed=0):\n",
    "        \"\"\"\n",
    "        This class is used to perform atom bagging with matching pursuit\n",
    "\n",
    "        Args:\n",
    "        K (int): Number of iterations\n",
    "        atom_bag_percent (float): Percentage of the original dictionary\n",
    "        select_atom_percent (float): Percentage of the selected atoms\n",
    "        random_seed (int): Random seed\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(K, atom_bag_percent, select_atom_percent, random_seed)\n",
    "\n",
    "    def fit(self, phi, s):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        s (numpy.ndarray): Input signal\n",
    "        phi (numpy.ndarray): Dictionary\n",
    "        \"\"\"\n",
    "        self.reset()\n",
    "\n",
    "        if s.ndim == 1:\n",
    "            self.s = s.reshape(-1, 1)\n",
    "        else:\n",
    "            self.s = s\n",
    "        self.phi = phi\n",
    "        self.a = np.zeros_like(self.s)\n",
    "        self.coefficients = np.zeros(phi.shape[1])\n",
    "        self.r = self.s.copy()\n",
    "\n",
    "        if self.random_seed is not None:\n",
    "            np.random.seed(self.random_seed)\n",
    "\n",
    "        for i in range(self.K):\n",
    "            inner_products = (phi.T @ self.r).flatten()\n",
    "            if self.atom_bag_flag:\n",
    "                dropping_indices = np.random.choice(\n",
    "                    phi.shape[1],\n",
    "                    int(phi.shape[1] * (1 - self.atom_bag_percent)),\n",
    "                    replace=False,\n",
    "                )\n",
    "                inner_products[dropping_indices] = 0\n",
    "            if self.atom_weak_select_flag:\n",
    "                top_ind = np.argsort(np.abs(inner_products))[::-1][\n",
    "                    : int(phi.shape[1] * self.select_atom_percent)\n",
    "                ]\n",
    "                # randomly select one atom\n",
    "                lambda_k = np.random.choice(top_ind)\n",
    "            else:\n",
    "                lambda_k = np.argmax(np.abs(inner_products))\n",
    "            self.indices.append(lambda_k)\n",
    "            self.coefficients[lambda_k] = (\n",
    "                self.coefficients[lambda_k] + inner_products[lambda_k]\n",
    "            )\n",
    "            self.a += inner_products[lambda_k] * phi[:, lambda_k].reshape(-1, 1)\n",
    "            self.r = self.s - self.a\n",
    "        return self.a, self.coefficients\n",
    "\n",
    "\n",
    "class OMP_Augmented(AtomBaggingBase):\n",
    "    def __init__(\n",
    "        self, K_lst, select_atom_percent=0, random_seed=None, ignore_warning=False\n",
    "    ):\n",
    "        self.K_lst = K_lst\n",
    "        self.random_seed = random_seed\n",
    "        self.select_atom_percent = select_atom_percent\n",
    "        if select_atom_percent == 0:\n",
    "            self.atom_weak_select_flag = False\n",
    "\n",
    "        self.indices = []\n",
    "        self.coefficients = None\n",
    "        self.ignore_warning = ignore_warning\n",
    "\n",
    "        self.coefficients_matrix = None\n",
    "        self.error_series = []\n",
    "\n",
    "    def fit(self, phi, s):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        s (numpy.ndarray): Input signal\n",
    "        phi (numpy.ndarray): Dictionary\n",
    "        \"\"\"\n",
    "        self.reset()\n",
    "        self.s = s\n",
    "        self.phi = phi\n",
    "        self.a = np.zeros_like(self.s)\n",
    "        self.coefficients = np.zeros(phi.shape[1])\n",
    "        self.r = self.s.copy()\n",
    "\n",
    "        self.coefficients_matrix = np.zeros((phi.shape[1], len(self.K_lst)))\n",
    "        self.error_series = []\n",
    "        if self.random_seed is not None:\n",
    "            np.random.seed(self.random_seed)\n",
    "\n",
    "        for k in range(np.max(self.K_lst)):\n",
    "            inner_products = (phi.T @ self.r).flatten()\n",
    "            # so that we will not select the same atom\n",
    "            inner_products[self.indices] = 0\n",
    "            if self.atom_weak_select_flag:\n",
    "                top_ind = np.argsort(np.abs(inner_products))[::-1][\n",
    "                    : int(phi.shape[1] * self.select_atom_percent)\n",
    "                ]\n",
    "                # randomly select one atom\n",
    "                lambda_k = np.random.choice(top_ind)\n",
    "            else:\n",
    "                lambda_k = np.argmax(np.abs(inner_products))\n",
    "\n",
    "            # Ordinary least squares\n",
    "            X = phi[:, self.indices + [lambda_k]]\n",
    "\n",
    "            try:\n",
    "                betas = np.linalg.inv(X.T @ X) @ X.T @ self.s\n",
    "            except:\n",
    "                if not self.ignore_warning:\n",
    "                    print(\"Singular matrix encountered in OMP\")\n",
    "                break\n",
    "\n",
    "            # Update indices\n",
    "            self.indices.append(lambda_k)\n",
    "\n",
    "            # Update Coefficients\n",
    "            self.coefficients = np.zeros(phi.shape[1])\n",
    "            self.coefficients[self.indices] = betas.flatten()\n",
    "\n",
    "            # Update Projection\n",
    "            self.a = X @ betas\n",
    "\n",
    "            # Update Residual\n",
    "            self.r = self.s - self.a\n",
    "            if (k+1) in self.K_lst:\n",
    "                self.coefficients_matrix[:, self.K_lst.index(k+1)] = self.coefficients\n",
    "                self.error_series.append(np.sum(self.r**2))\n",
    "\n",
    "        minimal_k_index = np.argmin(self.error_series)\n",
    "\n",
    "        # Update Coefficients\n",
    "\n",
    "        self.coefficients = self.coefficients_matrix[:, minimal_k_index]\n",
    "\n",
    "        # Update Projection\n",
    "        self.a = phi @ self.coefficients\n",
    "\n",
    "        # Update Residual\n",
    "        self.r = self.s - self.a\n",
    "\n",
    "        return self.a, self.coefficients\n",
    "\n",
    "    def multi_score(self, phi_test, s_test):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        phi_test (numpy.ndarray): Test data\n",
    "        s_test (numpy.ndarray): Test labels\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray: Predicted output\n",
    "        \"\"\"\n",
    "\n",
    "        test_score = []\n",
    "        projection_matrix = phi_test @ self.coefficients_matrix\n",
    "        residual_matrix = s_test.reshape(-1, 1) - projection_matrix\n",
    "        test_score = np.mean(residual_matrix**2, axis=0)\n",
    "        return test_score\n",
    "\n",
    "    def reset(self):\n",
    "        super().reset()\n",
    "        self.coefficients_matrix = None\n",
    "        self.error_series = []\n",
    "\n",
    "\n",
    "class BOMP(AtomBaggingBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        Bag_lst= list(range(1,11)),\n",
    "        K_lst = list(range(1, 11)),\n",
    "        signal_bag_percent=0.7,\n",
    "        atom_bag_percent=1,\n",
    "        select_atom_percent=0,\n",
    "        replace_flag=True,\n",
    "        agg_func=\"weight\",\n",
    "        random_seed=None,\n",
    "        ignore_warning=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        N (int): Number of submodels\n",
    "        K (int): Number of iterations\n",
    "        signal_bag_percent (float): Percentage of the original signal\n",
    "        atom_bag_percent (float): Percentage of the original dictionary\n",
    "        select_atom_percent (float): Percentage of the selected atoms\n",
    "        replace_flag (bool): Whether to replace the samples\n",
    "        agg_func (str): Aggregation function\n",
    "        random_seed (int): Random seed\n",
    "        \"\"\"\n",
    "\n",
    "        self.Bag_lst = Bag_lst\n",
    "        self.K_lst = K_lst\n",
    "        self.signal_bag_percent = signal_bag_percent\n",
    "        self.atom_bag_percent = atom_bag_percent\n",
    "        self.select_atom_percent = select_atom_percent\n",
    "        self.replace_flag = replace_flag\n",
    "        self.agg_func = agg_func\n",
    "        self.random_seed = random_seed\n",
    "        self.ignore_warning = ignore_warning\n",
    "        self.s = None\n",
    "        self.phi = None\n",
    "        self.tmpPursuitModel = OMP_Augmented(\n",
    "            K_lst, select_atom_percent, random_seed, ignore_warning\n",
    "        )\n",
    "        self.SignalBagging = None\n",
    "        self.coefficients = None\n",
    "        self.a = None\n",
    "\n",
    "    def agg_weight_with_error(self, c_lst, mse_lst):\n",
    "        \"\"\"\n",
    "        This function is used to aggregate the coefficients with the inverse of the mean squared error\n",
    "\n",
    "        Args:\n",
    "        c_lst (list): List of coefficients\n",
    "        mse_lst (list): List of mean squared errors\n",
    "        \"\"\"\n",
    "        # Calculate the weight\n",
    "        mse_lst = np.array(mse_lst)\n",
    "        weight = 1 / mse_lst\n",
    "        weight = weight / np.sum(weight)\n",
    "\n",
    "        # Calculate the weighted average\n",
    "        tot = np.zeros_like(c_lst[0])\n",
    "        for i in range(len(c_lst)):\n",
    "            tot += c_lst[i] * weight[i]\n",
    "        return tot\n",
    "\n",
    "    def agg_weight_with_avg(self, c_lst):\n",
    "        \"\"\"\n",
    "        This function is used to aggregate the coefficients with the inverse of the mean squared error\n",
    "\n",
    "        Args:\n",
    "        c_lst (list): List of coefficients\n",
    "        \"\"\"\n",
    "        # Calculate the weighted average\n",
    "        tot = np.zeros_like(c_lst[0])\n",
    "        for i in range(len(c_lst)):\n",
    "            tot += c_lst[i]\n",
    "        return tot / len(c_lst)\n",
    "\n",
    "    def fit(self, phi, s):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        s (numpy.ndarray): Input signal\n",
    "        phi (numpy.ndarray): Dictionary\n",
    "        \"\"\"\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "        self.s = s\n",
    "        self.phi = phi\n",
    "        self.SignalBagging = SignalAtomBagging(\n",
    "            np.max(self.Bag_lst),\n",
    "            self.signal_bag_percent,\n",
    "            self.atom_bag_percent,\n",
    "            self.replace_flag,\n",
    "            self.random_seed,\n",
    "        )\n",
    "        self.SignalBagging.fit(self.phi, self.s)\n",
    "        self.coefficients_matrix = None\n",
    "        s_bag = self.SignalBagging.s_bag\n",
    "        phi_bag = self.SignalBagging.phi_bag\n",
    "        col_idx_bag = self.SignalBagging.col_idx_bag\n",
    "        self.coefficients_cubic = np.zeros((np.max(self.Bag_lst), phi.shape[1], len(self.K_lst)))\n",
    "        self.coefficients_matrix = np.zeros((phi.shape[1], len(self.K_lst)))\n",
    "        self.bag_k_error_matrix = np.zeros((len(self.Bag_lst), 3))\n",
    "\n",
    "\n",
    "        if self.random_seed is not None:\n",
    "            np.random.seed(self.random_seed)\n",
    "\n",
    "        for i in range(np.max(self.Bag_lst)):\n",
    "            sub_s = s_bag[i]\n",
    "            sub_phi = phi_bag[i]\n",
    "            sub_idx = col_idx_bag[i]\n",
    "            self.tmpPursuitModel = OMP_Augmented(\n",
    "                self.K_lst,\n",
    "                self.select_atom_percent,\n",
    "                np.random.randint(10 * np.max(self.Bag_lst)),\n",
    "                self.ignore_warning,\n",
    "            )\n",
    "            self.tmpPursuitModel.fit(sub_phi, sub_s)\n",
    "            real_sub_coefficients = np.zeros((phi.shape[1], len(self.K_lst)))\n",
    "            real_sub_coefficients[sub_idx, :] = self.tmpPursuitModel.coefficients_matrix\n",
    "            self.coefficients_cubic[i,:,:] = real_sub_coefficients\n",
    "            self.tmpPursuitModel.reset()\n",
    "            if (i+1) in self.Bag_lst:\n",
    "                counted_array = np.array(\n",
    "                    np.unique(np.concatenate(col_idx_bag[: i + 1]), return_counts=True)\n",
    "                )\n",
    "                temp_coefficients_matrix = self.coefficients_cubic.sum(axis=0)\n",
    "                counted_array = counted_array[:,np.argsort(counted_array[0])]\n",
    "                filled_array = np.zeros_like(phi[0])\n",
    "\n",
    "                if (counted_array.shape[1] < phi.shape[1]):\n",
    "                    temp_coefficients_matrix[counted_array[0, :], :] = ((temp_coefficients_matrix[counted_array[0, :], :]).T/ counted_array[1, :]).T\n",
    "                else:\n",
    "                    temp_coefficients_matrix = ((temp_coefficients_matrix).T/ counted_array[1, :]).T\n",
    "                temp_projection_matrix = phi @ temp_coefficients_matrix\n",
    "                temp_residual_matrix = s.reshape(-1, 1) - temp_projection_matrix\n",
    "                temp_error_series = np.mean(temp_residual_matrix ** 2, axis=0)\n",
    "                temp_optimal_idx = np.argmin(temp_error_series)\n",
    "                self.bag_k_error_matrix[self.Bag_lst.index(i+1), :] = np.array([i+1, self.K_lst[temp_optimal_idx], temp_error_series[temp_optimal_idx]])\n",
    "\n",
    "        self.optimal_idx = np.argmin(self.bag_k_error_matrix[:, 2])\n",
    "\n",
    "        self.optimal_k = int(self.bag_k_error_matrix[self.optimal_idx, 1])\n",
    "\n",
    "        self.optimal_bag = int(self.bag_k_error_matrix[self.optimal_idx, 0])\n",
    "\n",
    "\n",
    "        counted_array = np.array(\n",
    "            np.unique(np.concatenate(col_idx_bag[: self.optimal_bag]), return_counts=True)\n",
    "        )\n",
    "        temp_coefficients_matrix = self.coefficients_cubic.sum(axis=0)\n",
    "        counted_array = counted_array[:,np.argsort(counted_array[0])]\n",
    "        filled_array = np.zeros_like(phi[0])\n",
    "        if (counted_array.shape[1] < phi.shape[1]):\n",
    "            self.coefficients_matrix[counted_array[0, :], :] = ((temp_coefficients_matrix[counted_array[0, :], :]).T/ counted_array[1, :]).T\n",
    "        else:\n",
    "            self.coefficients_matrix = ((temp_coefficients_matrix).T/ counted_array[1, :]).T\n",
    "\n",
    "        self.coefficients = self.coefficients_matrix[:, self.K_lst.index(self.optimal_k)]\n",
    "\n",
    "        # Update Projection\n",
    "        self.a = phi @ self.coefficients\n",
    "\n",
    "        # Update Residual\n",
    "        self.r = self.s - self.a\n",
    "        return self.a, self.coefficients\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        This function is used to reset the model\n",
    "        \"\"\"\n",
    "        super().reset()\n",
    "        self.coefficients_matrix = None\n",
    "        self.coefficients_cubic = None\n",
    "        self.error_series = []\n",
    "        self.coefficients = None\n",
    "        self.a = None\n",
    "\n",
    "    def set_Bag_lst(self, bag_lst):\n",
    "        \"\"\"\n",
    "        This function is used to set the bag_lst\n",
    "\n",
    "        Args:\n",
    "        bag_lst (list): List of bag size\n",
    "        \"\"\"\n",
    "        self.Bag_lst = bag_lst\n",
    "    \n",
    "    def set_K_lst(self, k_lst):\n",
    "        self.K_lst = k_lst\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "    # This assumes all parameters are primitives\n",
    "        return {\n",
    "            \"Bag_lst\": self.Bag_lst,\n",
    "            \"K_lst\": self.K_lst,\n",
    "            \"signal_bag_percent\": self.signal_bag_percent,\n",
    "            \"atom_bag_percent\": self.atom_bag_percent,\n",
    "            \"select_atom_percent\": self.select_atom_percent,\n",
    "            \"replace_flag\": self.replace_flag,\n",
    "            \"agg_func\": self.agg_func,\n",
    "            \"random_seed\": self.random_seed,\n",
    "            \"ignore_warning\": self.ignore_warning,\n",
    "        }\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = np.arange(100)\n",
    "np.random.shuffle(test_array)\n",
    "chosen = test_array[:60]\n",
    "counted_array = np.array(\n",
    "    np.unique(chosen, return_counts=True)\n",
    ")\n",
    "# Create a new array filled with zeros\n",
    "filled_array = np.zeros_like(test_array)\n",
    "# Put the counted values with their corresponding index in the new array\n",
    "filled_array[counted_array[0]] = counted_array[1]\n",
    "non_zero_idx = counted_array[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.81511933e-02,  1.01722459e-01, -3.00705959e-01, -2.57130683e-01,\n",
       "        -4.31151317e-01, -6.76168481e-02,  5.90171082e-02, -8.35489350e-02,\n",
       "        -4.02525978e-02, -2.72826389e-01,  1.00383045e-01, -2.38160455e-02,\n",
       "        -5.76591471e-02,  7.73288011e-02,  8.95581979e-02,  1.79916256e-01,\n",
       "        -1.98328507e-01, -2.56895552e-02, -1.59716271e-01, -4.52044746e-01,\n",
       "        -6.86218994e-04, -1.95897634e-01, -1.13165087e-01,  1.48071296e-01,\n",
       "        -2.54993490e-01, -3.15419133e-01, -2.31398154e-01,  1.89817758e-01,\n",
       "        -2.46644257e-01, -1.28533603e-01, -1.09594686e-01, -1.32967121e-01,\n",
       "         1.37834383e-02,  2.34380424e-03,  3.47138167e-01,  2.40401239e-01,\n",
       "         3.25598053e-01, -1.30954191e-01, -1.56820863e-01, -1.31206749e-01,\n",
       "        -1.53254947e-01, -1.55380209e-01,  2.59314590e-02, -1.14410030e-01,\n",
       "        -1.46879773e-01,  3.61213519e-01, -8.66151012e-02,  1.66836982e-01,\n",
       "        -2.20509239e-01,  5.48171310e-03, -1.43460921e-02,  2.26123754e-01,\n",
       "        -8.63581090e-02,  1.59826649e-01, -2.85100720e-02,  1.91915287e-01,\n",
       "        -1.45094791e-01, -3.08975451e-01, -1.02015312e-01,  1.36585555e-01,\n",
       "         3.41313627e-01, -8.53617558e-02, -9.71100784e-02,  1.28519724e-01,\n",
       "         2.91296205e-02, -1.85116663e-01, -2.06773598e-01,  4.53202530e-02,\n",
       "         2.19579706e-01,  2.05206197e-01,  7.24182079e-02, -3.43542741e-01,\n",
       "        -1.25991102e-01,  1.85051089e-01,  9.92384062e-02, -8.40714693e-02,\n",
       "         1.18163370e-01, -2.03137248e-01,  6.99118830e-02,  1.72471856e-01,\n",
       "         2.65391645e-01,  2.55780205e-01,  1.62646625e-01, -2.87494000e-01,\n",
       "        -2.69625389e-01,  1.00489945e-01, -1.34007826e-01,  2.26969959e-01,\n",
       "         6.27021823e-02,  3.27147953e-01, -3.47424992e-02,  2.64478253e-01,\n",
       "        -1.05654589e-01,  8.57763630e-02,  8.95584401e-02, -3.40049519e-01,\n",
       "        -3.92007689e-02,  2.79565761e-01,  4.69384463e-01,  2.50254307e-01,\n",
       "         2.31099667e-01,  1.89400058e-01,  7.19152512e-02, -1.13826688e-01,\n",
       "        -1.18841631e-01,  2.11938828e-01, -6.19387181e-02,  1.07276913e-01,\n",
       "        -1.67966808e-01,  2.57854052e-02,  1.20082416e-02, -2.29793205e-01,\n",
       "        -1.26881315e-01,  9.85171618e-02,  7.60135843e-02,  2.25049312e-01,\n",
       "        -9.96843169e-02, -1.76907740e-01,  6.45566754e-02, -1.35052197e-01,\n",
       "        -1.80881736e-01, -1.94704806e-01,  3.31119631e-02,  1.73477199e-01,\n",
       "         1.00544742e-02,  2.62273950e-02,  5.26469794e-02, -1.04219426e-01,\n",
       "         3.43251770e-01, -1.77523956e-01, -7.24962853e-02,  3.15627835e-02,\n",
       "        -2.24303453e-01,  1.74413254e-01,  3.28881125e-01, -9.55816523e-02,\n",
       "         5.03340235e-01, -1.15309014e-03, -5.09538013e-02, -4.19125356e-01,\n",
       "        -2.34587292e-02, -8.20857053e-02,  4.15106532e-01,  1.21982093e-02,\n",
       "        -7.67622289e-02, -2.40429378e-01,  1.36238297e-01,  4.51429950e-01,\n",
       "         1.00306232e-02,  1.80561424e-01, -2.18539872e-01,  7.02498281e-02,\n",
       "         2.88406725e-01, -1.27437585e-01,  4.59358819e-02, -2.89617536e-02,\n",
       "        -1.81145003e-02, -3.83529126e-02,  4.20043435e-02, -7.25163428e-02,\n",
       "         2.46292025e-01, -1.42263682e-02,  1.21127387e-01, -7.11701025e-02,\n",
       "        -8.70907685e-02, -1.27548625e-01,  1.26808454e-01,  2.48557552e-01,\n",
       "         1.71025253e-02, -1.95249860e-01,  9.23545573e-02,  2.16577805e-01,\n",
       "         2.44450754e-01, -4.65180925e-02,  1.53088631e-01, -1.00150076e-01,\n",
       "         3.87741812e-01,  2.12015375e-01, -3.18073616e-01,  1.56849944e-02,\n",
       "        -8.10732965e-02,  1.68141028e-01,  3.85080568e-01,  1.83745918e-02,\n",
       "         1.90295307e-02,  2.14376251e-02, -2.06812264e-01, -1.40446579e-01,\n",
       "         7.97594504e-02, -1.66156004e-01, -2.86975012e-02, -4.10645302e-02,\n",
       "        -3.62852367e-01,  8.94847771e-02, -4.38798433e-01, -1.58523473e-01,\n",
       "         3.51640564e-01,  2.36486202e-01, -4.79338662e-02,  8.05168085e-03,\n",
       "        -8.51129745e-02, -1.11779572e-01, -4.05310241e-02,  1.90281032e-01,\n",
       "        -4.05017056e-03, -2.61537224e-01,  7.30442508e-03,  7.22506238e-02,\n",
       "        -1.03272685e-01, -2.65148207e-01, -4.31539993e-02, -5.93269180e-02,\n",
       "         4.57420980e-01,  1.57816222e-01,  4.00477981e-02, -1.42106717e-01,\n",
       "         4.28292194e-01,  2.25405845e-01, -1.95206531e-01, -1.02702891e-01,\n",
       "        -1.49836915e-02,  1.10644433e-01,  3.05223255e-01,  1.35299544e-02,\n",
       "        -1.36237423e-01, -2.55323391e-01, -2.07786977e-01,  1.73686764e-01,\n",
       "        -3.90079546e-01,  2.18437477e-02, -2.39378875e-01, -6.10903819e-02,\n",
       "         1.97967620e-01, -4.14950770e-02, -6.75080727e-01, -8.76489539e-02,\n",
       "         6.23365484e-03, -1.07561234e-01, -6.98056207e-02,  2.45463287e-01,\n",
       "         9.72564176e-02, -1.37418140e-01, -7.77740552e-02, -5.57717797e-02,\n",
       "         1.64004924e-01, -7.79556325e-02,  2.09627607e-01, -1.29739342e-02,\n",
       "        -7.06734877e-02, -3.48580416e-01,  8.47688751e-02,  1.71707014e-01,\n",
       "        -5.68564799e-02,  1.25101197e-01,  8.48211538e-02,  4.19256452e-02,\n",
       "        -4.14739527e-02,  2.30062357e-03, -8.35421966e-02,  2.15650015e-01,\n",
       "         1.27206713e-01,  2.59991779e-01,  1.77290866e-01,  1.53174220e-01,\n",
       "         1.93086739e-01, -3.48435805e-02,  1.72941430e-01, -6.73038087e-02,\n",
       "        -2.19683206e-02,  4.80701731e-02,  2.99041016e-02, -1.90479958e-01,\n",
       "        -5.30948892e-02,  4.06551531e-01, -1.51103608e-01, -9.82390321e-02,\n",
       "        -1.70886791e-01, -5.72264035e-02,  1.38820841e-01,  2.77770168e-02,\n",
       "        -1.96652561e-01, -4.10088326e-01, -4.66674666e-01,  3.07626487e-01,\n",
       "        -1.79187778e-02,  4.77229630e-03,  1.29570327e-01, -3.39271367e-01,\n",
       "        -1.96468097e-04,  3.45243993e-01, -4.26611734e-02,  4.62680272e-02,\n",
       "         2.04565979e-01,  6.59058191e-02, -1.74184605e-01, -1.19808175e-01,\n",
       "         1.42532039e-01,  7.55821774e-02, -1.38426336e-01, -9.73738244e-04,\n",
       "        -2.48532580e-01, -1.94357496e-01,  1.34044016e-01, -2.51308266e-01,\n",
       "         1.00549054e-01,  1.53977295e-01, -6.57380350e-02,  1.23867661e-01,\n",
       "        -1.15320025e-01,  3.30463015e-01, -3.61787719e-02, -2.74409072e-02,\n",
       "        -3.01643744e-01, -7.25050642e-02, -2.53052369e-01,  3.50562780e-02,\n",
       "        -4.77733419e-01, -3.51906321e-02, -1.29464322e-02, -4.47267235e-01,\n",
       "         2.32640639e-01,  1.67903919e-01, -1.80316728e-02,  5.88727033e-02,\n",
       "        -9.45206603e-03,  4.06168902e-01,  2.38827342e-01,  6.25978490e-02,\n",
       "        -1.91700728e-01, -3.76861866e-01,  1.60124417e-02,  2.44847134e-02,\n",
       "         7.65386559e-02, -2.63218516e-03,  1.53599264e-01,  3.37705043e-01,\n",
       "         1.47627320e-01,  2.38251789e-01,  3.00579690e-01,  8.24696882e-02,\n",
       "        -1.11046890e-01,  5.53973944e-01, -4.35086632e-02, -2.62467664e-02,\n",
       "         5.29586475e-02, -9.52920782e-02,  1.93753436e-01,  1.42278561e-02,\n",
       "         1.42451607e-01, -3.54437063e-02,  7.61208989e-02, -2.55292122e-01,\n",
       "         2.07418536e-01, -7.89044326e-02,  1.14677393e-01,  3.43741297e-01,\n",
       "        -1.46377329e-01, -2.66218461e-01,  1.70300593e-01, -9.08599869e-02,\n",
       "         1.43091713e-01, -1.41261504e-01,  2.88401218e-01, -1.23497854e-01,\n",
       "        -5.85490169e-01, -3.30683803e-02, -5.90423852e-02,  5.71130876e-02,\n",
       "         6.92820654e-02,  3.23857209e-01,  1.12605657e-02,  3.54716457e-01,\n",
       "        -1.85713970e-01, -4.77970871e-01, -3.89258064e-01, -1.78798130e-01,\n",
       "         2.24367833e-01, -1.19699653e-01, -2.52381848e-01, -6.21607435e-02,\n",
       "         3.50727823e-02,  7.69957855e-02,  1.20658645e-01, -1.46908654e-01,\n",
       "         8.27639596e-02,  3.04982033e-01, -1.52682920e-01,  1.99667649e-01,\n",
       "        -1.45642285e-01, -7.01976913e-02, -1.52910935e-01, -2.29792858e-02,\n",
       "        -3.73694935e-02,  1.04107872e-01, -1.85742431e-01, -1.13069941e-01,\n",
       "        -1.48492637e-01,  1.28802493e-01, -6.14086041e-02,  3.27526928e-01,\n",
       "        -6.59741793e-02, -9.49350697e-03,  7.34495359e-02, -2.09251505e-01,\n",
       "         3.59576170e-02,  7.96177177e-02, -1.57488718e-01, -5.01010825e-02,\n",
       "         1.22591314e-01, -1.12806116e-01, -2.18712534e-01,  6.72666551e-02,\n",
       "        -6.60523407e-02,  3.66386392e-01,  4.76271110e-01, -8.83667524e-02,\n",
       "         7.89442014e-02,  6.41328136e-01, -2.05710776e-01,  1.02909240e-02,\n",
       "        -3.73679324e-02, -3.83222379e-01,  2.32398672e-01, -1.76937897e-01,\n",
       "        -1.52414009e-01,  2.22275522e-01, -9.74752825e-02, -6.12544264e-02,\n",
       "         4.02789452e-02, -2.99279218e-02, -1.44958727e-01, -2.77894765e-01,\n",
       "        -1.01499338e-01, -4.28502590e-02,  1.89452138e-01,  3.21437924e-01,\n",
       "         1.07557496e-01, -6.64135528e-02, -5.98653526e-02,  4.92141404e-01,\n",
       "        -2.14423570e-02,  4.92941735e-02,  2.29699782e-01, -3.43303282e-01,\n",
       "         8.20951910e-02, -3.97182582e-01, -1.26235708e-01,  2.27711236e-02,\n",
       "         7.92684030e-02, -2.19848596e-01, -2.31009619e-03, -2.00589748e-01,\n",
       "        -9.19434452e-02, -1.32102900e-02,  2.50021453e-01,  3.06857434e-02,\n",
       "         1.09348096e-01,  1.17564587e-01, -2.44608846e-01,  7.54106916e-03,\n",
       "        -1.19543672e-01, -2.36694622e-01,  2.08748381e-01, -2.10397570e-01,\n",
       "        -2.86492644e-01,  2.53632970e-01, -1.29353438e-01, -5.03663524e-01,\n",
       "        -4.04538188e-01, -6.12956874e-02, -2.82136915e-01, -3.57623788e-01,\n",
       "         5.28642882e-01, -2.79068502e-01, -3.78291582e-01,  2.49726632e-01,\n",
       "         4.87683201e-01, -1.08154001e-01, -7.13086526e-02,  2.19749491e-01]),\n",
       " array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.11188155,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.12538236,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -0.17675691,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -0.42084269,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.10450068,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -0.1993095 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -0.17604266,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -0.25047409,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.26328623,  0.09149753,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.18801394,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.18654112,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.15273061,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.18855483,  0.        ,\n",
       "         0.        ,  0.        ,  0.        , -0.2344921 ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -0.16615049,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.24648369,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -0.18018214,\n",
       "         0.        ,  0.        , -0.13636019, -0.10668789,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.16054154,  0.        , -0.08539175,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.139886  ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.73933749,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.09535801,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.36587948,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.15387848,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.16892621,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.17488584,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.12162198,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.19961383,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.32203402,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -0.10970928,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        , -0.12988321,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.11641587,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.0980984 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -0.10869061,  0.        ,  0.        ,  1.11428035,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        , -0.19328098,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.15568106,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -0.08933063,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.24641371,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.20386099,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        , -0.10829496,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        , -0.11542212,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.26690106,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -1.99922543,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        , -0.74269839,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         2.36170421,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.62073453,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.12846468,  0.        ,\n",
       "         0.        , -0.19787226,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.08397597,  0.        ,  0.        ,  0.        ,\n",
       "         0.13091776,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.19787473,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -0.15360958,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        , -0.24271219,  0.        , -0.36621962,\n",
       "        -1.44276537, -0.49961181,  0.        , -0.23620571,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.08200369,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.10051726,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.11172531,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -0.18849281,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.19262976,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.18285521,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.27999205,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.29778123,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BOMP(**fixed_params)\n",
    "\n",
    "\n",
    "n = npm_lst[0][0]\n",
    "p = npm_lst[0][1]\n",
    "m = npm_lst[0][2]\n",
    "noise_level = noise_level_lst[0]\n",
    "trial_id = 1\n",
    "\n",
    "Data_Geneartor = GaussianDataGenerator(p, n, m, noise_level, trial_id)\n",
    "(\n",
    "    true_signal,\n",
    "    dictionary,\n",
    "    true_indices,\n",
    "    true_coefficients,\n",
    "    perturbed_signal,\n",
    ") = Data_Geneartor.shuffle()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dictionary, perturbed_signal, test_size=0.2, random_state=trial_id\n",
    ")\n",
    "temp = BOMP(atom_bag_percent=0.5,signal_bag_percent=0.6)\n",
    "temp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    }
   ],
   "source": [
    "model = BOMP(**fixed_params)\n",
    "\n",
    "\n",
    "n = npm_lst[0][0]\n",
    "p = npm_lst[0][1]\n",
    "m = npm_lst[0][2]\n",
    "noise_level = noise_level_lst[0]\n",
    "trial_id = 1\n",
    "\n",
    "Data_Geneartor = GaussianDataGenerator(p, n, m, noise_level, trial_id)\n",
    "(\n",
    "    true_signal,\n",
    "    dictionary,\n",
    "    true_indices,\n",
    "    true_coefficients,\n",
    "    perturbed_signal,\n",
    ") = Data_Geneartor.shuffle()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dictionary, perturbed_signal, test_size=0.2, random_state=trial_id\n",
    ")\n",
    "gs = GridSearchCV(\n",
    "    model,\n",
    "    param_grid,\n",
    "    cv=cv_num,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "gs.fit(X_train, y_train)\n",
    "cv_err_lst = -gs.cv_results_[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.00818286e-02, 1.94018281e-02, 8.67035617e+01, 2.04968373e-02,\n",
       "       2.01437268e-02, 1.25108641e+02, 2.07596826e-02, 2.22894233e-02,\n",
       "       1.33960626e+02, 1.91418538e-02, 2.15422021e-02, 2.51623050e-02,\n",
       "       1.82988671e-02, 2.04391895e-02, 3.49850498e-02])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = gs.best_estimator_\n",
    "temp.coefficients.shape\n",
    "-gs.cv_results_[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BOMP(Bag_lst=[1, 50, 100], K_lst=[1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
       "     ignore_warning=True, random_seed=1, replace_flag=False,\n",
       "     signal_bag_percent=0.8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BOMP</label><div class=\"sk-toggleable__content\"><pre>BOMP(Bag_lst=[1, 50, 100], K_lst=[1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
       "     ignore_warning=True, random_seed=1, replace_flag=False,\n",
       "     signal_bag_percent=0.8)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BOMP(Bag_lst=[1, 50, 100], K_lst=[1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
       "     ignore_warning=True, random_seed=1, replace_flag=False,\n",
       "     signal_bag_percent=0.8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
