{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import product\n",
    "from datetime import datetime\n",
    "from algorithms import BOMP\n",
    "from data_generation import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_trials_npm_multi_noise_lvl(\n",
    "    n, p, m, noise_level_lst, model_name, fixed_params, param_grid, cv_num, trial_num\n",
    "):\n",
    "    # get the model\n",
    "\n",
    "    if model_name == \"BOMP\":\n",
    "        model = BOMP(**fixed_params)\n",
    "\n",
    "    res_log_npm = {\n",
    "        \"parameters\": {\n",
    "            \"n\": n,\n",
    "            \"p\": p,\n",
    "            \"m\": m,\n",
    "            \"noise_level_lst\": noise_level_lst,\n",
    "            \"model_name\": model_name,\n",
    "            \"cv_num\": cv_num,\n",
    "            \"trial_num\": trial_num,\n",
    "            \"param_grid\": param_grid,\n",
    "            \"fixed_params\": fixed_params,\n",
    "        },\n",
    "        \"noise_level_lowest_MSE\": [],\n",
    "        \"log\": [],\n",
    "    }\n",
    "    print(f\"Running trials for n = {n}, p = {p}, m = {m}\")\n",
    "    for noise_level in noise_level_lst:\n",
    "        print(\"Cross validating alpha under noise level: \", noise_level)\n",
    "        trials_loweset_cv_MSE_temp = []\n",
    "        trials_testing_score_temp = []\n",
    "        for trial_id in range(trial_num):\n",
    "            print(\"Trial: \", trial_id)\n",
    "            Data_Geneartor = GaussianDataGenerator(p, n, m, noise_level, trial_id)\n",
    "            (\n",
    "                true_signal,\n",
    "                dictionary,\n",
    "                true_indices,\n",
    "                true_coefficients,\n",
    "                perturbed_signal,\n",
    "            ) = Data_Geneartor.shuffle()\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                dictionary, perturbed_signal, test_size=0.2, random_state=trial_id\n",
    "            )\n",
    "            gs = GridSearchCV(\n",
    "                model,\n",
    "                param_grid,\n",
    "                cv=cv_num,\n",
    "                scoring=\"neg_mean_squared_error\",\n",
    "                n_jobs=-1,\n",
    "                verbose=0,\n",
    "            )\n",
    "            gs.fit(X_train, y_train)\n",
    "            cv_err_lst = -gs.cv_results_[\"mean_test_score\"]\n",
    "            param_lst = gs.cv_results_[\"params\"]\n",
    "            best_estimator = gs.best_estimator_\n",
    "            best_estimator.set_bag_lst([best_estimator.optimal_bag])\n",
    "            best_estimator.set_K_lst([best_estimator.optimal_k])\n",
    "            best_estimator.fit(X_train, y_train)\n",
    "            testing_error = mean_squared_error(y_test, best_estimator.predict(X_test))\n",
    "            trials_testing_score_temp.append(testing_error)\n",
    "            lowest_cv_error = np.min(cv_err_lst)\n",
    "            trials_loweset_cv_MSE_temp.append(lowest_cv_error)\n",
    "            best_params = gs.best_params_\n",
    "            reslog_one_trial = {\n",
    "                \"noise_level\": noise_level,\n",
    "                \"trial\": trial_id,\n",
    "                \"cv_error_lst\": cv_err_lst,\n",
    "                \"lowest_cv_error\": lowest_cv_error,\n",
    "                \"best_params\": best_params,\n",
    "                \"best_bag\": best_estimator.optimal_bag,\n",
    "                \"best_k\": best_estimator.optimal_k,\n",
    "                \"param_lst\": param_lst,\n",
    "                \"testing_error\": testing_error,\n",
    "            }\n",
    "            res_log_npm[\"log\"].append(reslog_one_trial)\n",
    "            print(\n",
    "                \"Trial: \",\n",
    "                trial_id,\n",
    "                \" Best params: \",\n",
    "                best_params,\n",
    "                \" Lowest Error: \",\n",
    "                lowest_cv_error,\n",
    "                \" Testing Error: \",\n",
    "                testing_error,\n",
    "            )\n",
    "        res_log_npm[\"noise_level_lowest_cv_MSE\"].append(\n",
    "            np.mean(trials_loweset_cv_MSE_temp)\n",
    "        )\n",
    "        res_log_npm[\"trials_testing_score\"].append(np.mean(trials_testing_score_temp))\n",
    "        print(\n",
    "            \"Noise level: \",\n",
    "            noise_level,\n",
    "            \" Avg Testing Lowest MSE: \",\n",
    "            np.mean(trials_testing_score_temp),\n",
    "        )\n",
    "    return res_log_npm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_params(config):\n",
    "    # all_params = OmegaConf.to_container(config, resolve=True)[\"MODEL\"]\n",
    "    all_params = config[\"MODEL\"]\n",
    "    param_grid = {}\n",
    "    fixed_params = {}\n",
    "\n",
    "    Bag_lst = all_params[\"Bag_lst\"]\n",
    "    K_lst = all_params[\"K_lst\"]\n",
    "\n",
    "    del all_params[\"Bag_lst\"]\n",
    "    del all_params[\"K_lst\"]\n",
    "\n",
    "    for param, value in all_params.items():\n",
    "        if isinstance(value, list):\n",
    "            param_grid[param] = value\n",
    "        else:\n",
    "            fixed_params[param] = value\n",
    "\n",
    "    fixed_params[\"Bag_lst\"] = Bag_lst\n",
    "    fixed_params[\"K_lst\"] = K_lst\n",
    "    return fixed_params, param_grid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "\"MODEL\": {\n",
    "    \"Bag_lst\": [1, 50, 100],\n",
    "    \"K_lst\": [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    \"agg_func\": \"weight\",\n",
    "    \"atom_bag_percent\": [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    \"ignore_warning\": True,\n",
    "    \"random_seed\": 1,\n",
    "    \"replace_flag\": False,\n",
    "    \"select_atom_percent\": 0,\n",
    "    \"signal_bag_percent\": [0.6, 0.8, 1],\n",
    "},\n",
    "\"TEST\": {\n",
    "    \"cv_num\": 5,\n",
    "    \"m\": 20,\n",
    "    \"model\": \"BOMP\",\n",
    "    \"n\": 600,\n",
    "    \"noise_levels\": [0.12,0.14],\n",
    "    \"p\": 1000,\n",
    "    \"trial_num\": 20,\n",
    "},\n",
    "\"filename\": \"BOMP_600_1000_20_nr_0713.yaml\",\n",
    "\"hydra\": {\n",
    "    \"hydra_logging\": {\n",
    "        \"level\": \"CRITICAL\"\n",
    "    },\n",
    "    \"job_logging\": {\n",
    "        \"level\": \"CRITICAL\"\n",
    "    },\n",
    "    \"run\": {\n",
    "        \"dir\": \"memory/0713/\"\n",
    "    }\n",
    "}\n",
    "}\n",
    "\n",
    "n_tmp = configs[\"TEST\"][\"n\"]\n",
    "p_tmp = configs[\"TEST\"][\"p\"]\n",
    "m_tmp = configs[\"TEST\"][\"m\"]\n",
    "noise_level_lst = configs[\"TEST\"][\"noise_levels\"]\n",
    "model_name = configs[\"TEST\"][\"model\"]\n",
    "cv_num = configs[\"TEST\"][\"cv_num\"]\n",
    "trial_num = configs[\"TEST\"][\"trial_num\"]\n",
    "\n",
    "# Get n, p, m, noise_level combinations\n",
    "if not isinstance(n_tmp, list):\n",
    "    n_tmp = [n_tmp]\n",
    "if not isinstance(p_tmp, list):\n",
    "    p_tmp = [p_tmp]\n",
    "if not isinstance(m_tmp, list):\n",
    "    m_tmp = [m_tmp]\n",
    "\n",
    "npm_lst = list(product(n_tmp, p_tmp, m_tmp))\n",
    "\n",
    "if not isinstance(noise_level_lst, list):\n",
    "    noise_level_lst = [noise_level_lst]\n",
    "\n",
    "# Get model parameters\n",
    "fixed_params, param_grid = get_model_params(configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.81511933e-02,  1.01722459e-01, -3.00705959e-01, -2.57130683e-01,\n",
       "        -4.31151317e-01, -6.76168481e-02,  5.90171082e-02, -8.35489350e-02,\n",
       "        -4.02525978e-02, -2.72826389e-01,  1.00383045e-01, -2.38160455e-02,\n",
       "        -5.76591471e-02,  7.73288011e-02,  8.95581979e-02,  1.79916256e-01,\n",
       "        -1.98328507e-01, -2.56895552e-02, -1.59716271e-01, -4.52044746e-01,\n",
       "        -6.86218994e-04, -1.95897634e-01, -1.13165087e-01,  1.48071296e-01,\n",
       "        -2.54993490e-01, -3.15419133e-01, -2.31398154e-01,  1.89817758e-01,\n",
       "        -2.46644257e-01, -1.28533603e-01, -1.09594686e-01, -1.32967121e-01,\n",
       "         1.37834383e-02,  2.34380424e-03,  3.47138167e-01,  2.40401239e-01,\n",
       "         3.25598053e-01, -1.30954191e-01, -1.56820863e-01, -1.31206749e-01,\n",
       "        -1.53254947e-01, -1.55380209e-01,  2.59314590e-02, -1.14410030e-01,\n",
       "        -1.46879773e-01,  3.61213519e-01, -8.66151012e-02,  1.66836982e-01,\n",
       "        -2.20509239e-01,  5.48171310e-03, -1.43460921e-02,  2.26123754e-01,\n",
       "        -8.63581090e-02,  1.59826649e-01, -2.85100720e-02,  1.91915287e-01,\n",
       "        -1.45094791e-01, -3.08975451e-01, -1.02015312e-01,  1.36585555e-01,\n",
       "         3.41313627e-01, -8.53617558e-02, -9.71100784e-02,  1.28519724e-01,\n",
       "         2.91296205e-02, -1.85116663e-01, -2.06773598e-01,  4.53202530e-02,\n",
       "         2.19579706e-01,  2.05206197e-01,  7.24182079e-02, -3.43542741e-01,\n",
       "        -1.25991102e-01,  1.85051089e-01,  9.92384062e-02, -8.40714693e-02,\n",
       "         1.18163370e-01, -2.03137248e-01,  6.99118830e-02,  1.72471856e-01,\n",
       "         2.65391645e-01,  2.55780205e-01,  1.62646625e-01, -2.87494000e-01,\n",
       "        -2.69625389e-01,  1.00489945e-01, -1.34007826e-01,  2.26969959e-01,\n",
       "         6.27021823e-02,  3.27147953e-01, -3.47424992e-02,  2.64478253e-01,\n",
       "        -1.05654589e-01,  8.57763630e-02,  8.95584401e-02, -3.40049519e-01,\n",
       "        -3.92007689e-02,  2.79565761e-01,  4.69384463e-01,  2.50254307e-01,\n",
       "         2.31099667e-01,  1.89400058e-01,  7.19152512e-02, -1.13826688e-01,\n",
       "        -1.18841631e-01,  2.11938828e-01, -6.19387181e-02,  1.07276913e-01,\n",
       "        -1.67966808e-01,  2.57854052e-02,  1.20082416e-02, -2.29793205e-01,\n",
       "        -1.26881315e-01,  9.85171618e-02,  7.60135843e-02,  2.25049312e-01,\n",
       "        -9.96843169e-02, -1.76907740e-01,  6.45566754e-02, -1.35052197e-01,\n",
       "        -1.80881736e-01, -1.94704806e-01,  3.31119631e-02,  1.73477199e-01,\n",
       "         1.00544742e-02,  2.62273950e-02,  5.26469794e-02, -1.04219426e-01,\n",
       "         3.43251770e-01, -1.77523956e-01, -7.24962853e-02,  3.15627835e-02,\n",
       "        -2.24303453e-01,  1.74413254e-01,  3.28881125e-01, -9.55816523e-02,\n",
       "         5.03340235e-01, -1.15309014e-03, -5.09538013e-02, -4.19125356e-01,\n",
       "        -2.34587292e-02, -8.20857053e-02,  4.15106532e-01,  1.21982093e-02,\n",
       "        -7.67622289e-02, -2.40429378e-01,  1.36238297e-01,  4.51429950e-01,\n",
       "         1.00306232e-02,  1.80561424e-01, -2.18539872e-01,  7.02498281e-02,\n",
       "         2.88406725e-01, -1.27437585e-01,  4.59358819e-02, -2.89617536e-02,\n",
       "        -1.81145003e-02, -3.83529126e-02,  4.20043435e-02, -7.25163428e-02,\n",
       "         2.46292025e-01, -1.42263682e-02,  1.21127387e-01, -7.11701025e-02,\n",
       "        -8.70907685e-02, -1.27548625e-01,  1.26808454e-01,  2.48557552e-01,\n",
       "         1.71025253e-02, -1.95249860e-01,  9.23545573e-02,  2.16577805e-01,\n",
       "         2.44450754e-01, -4.65180925e-02,  1.53088631e-01, -1.00150076e-01,\n",
       "         3.87741812e-01,  2.12015375e-01, -3.18073616e-01,  1.56849944e-02,\n",
       "        -8.10732965e-02,  1.68141028e-01,  3.85080568e-01,  1.83745918e-02,\n",
       "         1.90295307e-02,  2.14376251e-02, -2.06812264e-01, -1.40446579e-01,\n",
       "         7.97594504e-02, -1.66156004e-01, -2.86975012e-02, -4.10645302e-02,\n",
       "        -3.62852367e-01,  8.94847771e-02, -4.38798433e-01, -1.58523473e-01,\n",
       "         3.51640564e-01,  2.36486202e-01, -4.79338662e-02,  8.05168085e-03,\n",
       "        -8.51129745e-02, -1.11779572e-01, -4.05310241e-02,  1.90281032e-01,\n",
       "        -4.05017056e-03, -2.61537224e-01,  7.30442508e-03,  7.22506238e-02,\n",
       "        -1.03272685e-01, -2.65148207e-01, -4.31539993e-02, -5.93269180e-02,\n",
       "         4.57420980e-01,  1.57816222e-01,  4.00477981e-02, -1.42106717e-01,\n",
       "         4.28292194e-01,  2.25405845e-01, -1.95206531e-01, -1.02702891e-01,\n",
       "        -1.49836915e-02,  1.10644433e-01,  3.05223255e-01,  1.35299544e-02,\n",
       "        -1.36237423e-01, -2.55323391e-01, -2.07786977e-01,  1.73686764e-01,\n",
       "        -3.90079546e-01,  2.18437477e-02, -2.39378875e-01, -6.10903819e-02,\n",
       "         1.97967620e-01, -4.14950770e-02, -6.75080727e-01, -8.76489539e-02,\n",
       "         6.23365484e-03, -1.07561234e-01, -6.98056207e-02,  2.45463287e-01,\n",
       "         9.72564176e-02, -1.37418140e-01, -7.77740552e-02, -5.57717797e-02,\n",
       "         1.64004924e-01, -7.79556325e-02,  2.09627607e-01, -1.29739342e-02,\n",
       "        -7.06734877e-02, -3.48580416e-01,  8.47688751e-02,  1.71707014e-01,\n",
       "        -5.68564799e-02,  1.25101197e-01,  8.48211538e-02,  4.19256452e-02,\n",
       "        -4.14739527e-02,  2.30062357e-03, -8.35421966e-02,  2.15650015e-01,\n",
       "         1.27206713e-01,  2.59991779e-01,  1.77290866e-01,  1.53174220e-01,\n",
       "         1.93086739e-01, -3.48435805e-02,  1.72941430e-01, -6.73038087e-02,\n",
       "        -2.19683206e-02,  4.80701731e-02,  2.99041016e-02, -1.90479958e-01,\n",
       "        -5.30948892e-02,  4.06551531e-01, -1.51103608e-01, -9.82390321e-02,\n",
       "        -1.70886791e-01, -5.72264035e-02,  1.38820841e-01,  2.77770168e-02,\n",
       "        -1.96652561e-01, -4.10088326e-01, -4.66674666e-01,  3.07626487e-01,\n",
       "        -1.79187778e-02,  4.77229630e-03,  1.29570327e-01, -3.39271367e-01,\n",
       "        -1.96468097e-04,  3.45243993e-01, -4.26611734e-02,  4.62680272e-02,\n",
       "         2.04565979e-01,  6.59058191e-02, -1.74184605e-01, -1.19808175e-01,\n",
       "         1.42532039e-01,  7.55821774e-02, -1.38426336e-01, -9.73738244e-04,\n",
       "        -2.48532580e-01, -1.94357496e-01,  1.34044016e-01, -2.51308266e-01,\n",
       "         1.00549054e-01,  1.53977295e-01, -6.57380350e-02,  1.23867661e-01,\n",
       "        -1.15320025e-01,  3.30463015e-01, -3.61787719e-02, -2.74409072e-02,\n",
       "        -3.01643744e-01, -7.25050642e-02, -2.53052369e-01,  3.50562780e-02,\n",
       "        -4.77733419e-01, -3.51906321e-02, -1.29464322e-02, -4.47267235e-01,\n",
       "         2.32640639e-01,  1.67903919e-01, -1.80316728e-02,  5.88727033e-02,\n",
       "        -9.45206603e-03,  4.06168902e-01,  2.38827342e-01,  6.25978490e-02,\n",
       "        -1.91700728e-01, -3.76861866e-01,  1.60124417e-02,  2.44847134e-02,\n",
       "         7.65386559e-02, -2.63218516e-03,  1.53599264e-01,  3.37705043e-01,\n",
       "         1.47627320e-01,  2.38251789e-01,  3.00579690e-01,  8.24696882e-02,\n",
       "        -1.11046890e-01,  5.53973944e-01, -4.35086632e-02, -2.62467664e-02,\n",
       "         5.29586475e-02, -9.52920782e-02,  1.93753436e-01,  1.42278561e-02,\n",
       "         1.42451607e-01, -3.54437063e-02,  7.61208989e-02, -2.55292122e-01,\n",
       "         2.07418536e-01, -7.89044326e-02,  1.14677393e-01,  3.43741297e-01,\n",
       "        -1.46377329e-01, -2.66218461e-01,  1.70300593e-01, -9.08599869e-02,\n",
       "         1.43091713e-01, -1.41261504e-01,  2.88401218e-01, -1.23497854e-01,\n",
       "        -5.85490169e-01, -3.30683803e-02, -5.90423852e-02,  5.71130876e-02,\n",
       "         6.92820654e-02,  3.23857209e-01,  1.12605657e-02,  3.54716457e-01,\n",
       "        -1.85713970e-01, -4.77970871e-01, -3.89258064e-01, -1.78798130e-01,\n",
       "         2.24367833e-01, -1.19699653e-01, -2.52381848e-01, -6.21607435e-02,\n",
       "         3.50727823e-02,  7.69957855e-02,  1.20658645e-01, -1.46908654e-01,\n",
       "         8.27639596e-02,  3.04982033e-01, -1.52682920e-01,  1.99667649e-01,\n",
       "        -1.45642285e-01, -7.01976913e-02, -1.52910935e-01, -2.29792858e-02,\n",
       "        -3.73694935e-02,  1.04107872e-01, -1.85742431e-01, -1.13069941e-01,\n",
       "        -1.48492637e-01,  1.28802493e-01, -6.14086041e-02,  3.27526928e-01,\n",
       "        -6.59741793e-02, -9.49350697e-03,  7.34495359e-02, -2.09251505e-01,\n",
       "         3.59576170e-02,  7.96177177e-02, -1.57488718e-01, -5.01010825e-02,\n",
       "         1.22591314e-01, -1.12806116e-01, -2.18712534e-01,  6.72666551e-02,\n",
       "        -6.60523407e-02,  3.66386392e-01,  4.76271110e-01, -8.83667524e-02,\n",
       "         7.89442014e-02,  6.41328136e-01, -2.05710776e-01,  1.02909240e-02,\n",
       "        -3.73679324e-02, -3.83222379e-01,  2.32398672e-01, -1.76937897e-01,\n",
       "        -1.52414009e-01,  2.22275522e-01, -9.74752825e-02, -6.12544264e-02,\n",
       "         4.02789452e-02, -2.99279218e-02, -1.44958727e-01, -2.77894765e-01,\n",
       "        -1.01499338e-01, -4.28502590e-02,  1.89452138e-01,  3.21437924e-01,\n",
       "         1.07557496e-01, -6.64135528e-02, -5.98653526e-02,  4.92141404e-01,\n",
       "        -2.14423570e-02,  4.92941735e-02,  2.29699782e-01, -3.43303282e-01,\n",
       "         8.20951910e-02, -3.97182582e-01, -1.26235708e-01,  2.27711236e-02,\n",
       "         7.92684030e-02, -2.19848596e-01, -2.31009619e-03, -2.00589748e-01,\n",
       "        -9.19434452e-02, -1.32102900e-02,  2.50021453e-01,  3.06857434e-02,\n",
       "         1.09348096e-01,  1.17564587e-01, -2.44608846e-01,  7.54106916e-03,\n",
       "        -1.19543672e-01, -2.36694622e-01,  2.08748381e-01, -2.10397570e-01,\n",
       "        -2.86492644e-01,  2.53632970e-01, -1.29353438e-01, -5.03663524e-01,\n",
       "        -4.04538188e-01, -6.12956874e-02, -2.82136915e-01, -3.57623788e-01,\n",
       "         5.28642882e-01, -2.79068502e-01, -3.78291582e-01,  2.49726632e-01,\n",
       "         4.87683201e-01, -1.08154001e-01, -7.13086526e-02,  2.19749491e-01]),\n",
       " array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.11188155,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.12538236,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -0.17675691,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -0.42084269,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.10450068,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -0.1993095 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -0.17604266,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -0.25047409,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.26328623,  0.09149753,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.18801394,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.18654112,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.15273061,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.18855483,  0.        ,\n",
       "         0.        ,  0.        ,  0.        , -0.2344921 ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -0.16615049,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.24648369,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -0.18018214,\n",
       "         0.        ,  0.        , -0.13636019, -0.10668789,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.16054154,  0.        , -0.08539175,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.139886  ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.73933749,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.09535801,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.36587948,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.15387848,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.16892621,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.17488584,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.12162198,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.19961383,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.32203402,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -0.10970928,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        , -0.12988321,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.11641587,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.0980984 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -0.10869061,  0.        ,  0.        ,  1.11428035,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        , -0.19328098,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.15568106,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -0.08933063,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.24641371,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.20386099,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        , -0.10829496,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        , -0.11542212,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.26690106,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -1.99922543,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        , -0.74269839,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         2.36170421,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.62073453,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.12846468,  0.        ,\n",
       "         0.        , -0.19787226,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.08397597,  0.        ,  0.        ,  0.        ,\n",
       "         0.13091776,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.19787473,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -0.15360958,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        , -0.24271219,  0.        , -0.36621962,\n",
       "        -1.44276537, -0.49961181,  0.        , -0.23620571,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.08200369,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.10051726,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.11172531,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -0.18849281,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.19262976,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.18285521,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.27999205,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.29778123,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BOMP(**fixed_params)\n",
    "\n",
    "\n",
    "n = npm_lst[0][0]\n",
    "p = npm_lst[0][1]\n",
    "m = npm_lst[0][2]\n",
    "noise_level = noise_level_lst[0]\n",
    "trial_id = 1\n",
    "\n",
    "Data_Geneartor = GaussianDataGenerator(p, n, m, noise_level, trial_id)\n",
    "(\n",
    "    true_signal,\n",
    "    dictionary,\n",
    "    true_indices,\n",
    "    true_coefficients,\n",
    "    perturbed_signal,\n",
    ") = Data_Geneartor.shuffle()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dictionary, perturbed_signal, test_size=0.2, random_state=trial_id\n",
    ")\n",
    "temp = BOMP(atom_bag_percent=0.5,signal_bag_percent=0.6)\n",
    "temp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    }
   ],
   "source": [
    "model = BOMP(**fixed_params)\n",
    "\n",
    "\n",
    "n = npm_lst[0][0]\n",
    "p = npm_lst[0][1]\n",
    "m = npm_lst[0][2]\n",
    "noise_level = noise_level_lst[0]\n",
    "trial_id = 1\n",
    "\n",
    "Data_Geneartor = GaussianDataGenerator(p, n, m, noise_level, trial_id)\n",
    "(\n",
    "    true_signal,\n",
    "    dictionary,\n",
    "    true_indices,\n",
    "    true_coefficients,\n",
    "    perturbed_signal,\n",
    ") = Data_Geneartor.shuffle()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dictionary, perturbed_signal, test_size=0.2, random_state=trial_id\n",
    ")\n",
    "gs = GridSearchCV(\n",
    "    model,\n",
    "    param_grid,\n",
    "    cv=cv_num,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    ")\n",
    "gs.fit(X_train, y_train)\n",
    "cv_err_lst = -gs.cv_results_[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on GridSearchCV in module sklearn.model_selection._search object:\n",
      "\n",
      "class GridSearchCV(BaseSearchCV)\n",
      " |  GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |  \n",
      " |  Exhaustive search over specified parameter values for an estimator.\n",
      " |  \n",
      " |  Important members are fit, predict.\n",
      " |  \n",
      " |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
      " |  It also implements \"score_samples\", \"predict\", \"predict_proba\",\n",
      " |  \"decision_function\", \"transform\" and \"inverse_transform\" if they are\n",
      " |  implemented in the estimator used.\n",
      " |  \n",
      " |  The parameters of the estimator used to apply these methods are optimized\n",
      " |  by cross-validated grid-search over a parameter grid.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <grid_search>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : estimator object\n",
      " |      This is assumed to implement the scikit-learn estimator interface.\n",
      " |      Either estimator needs to provide a ``score`` function,\n",
      " |      or ``scoring`` must be passed.\n",
      " |  \n",
      " |  param_grid : dict or list of dictionaries\n",
      " |      Dictionary with parameters names (`str`) as keys and lists of\n",
      " |      parameter settings to try as values, or a list of such\n",
      " |      dictionaries, in which case the grids spanned by each dictionary\n",
      " |      in the list are explored. This enables searching over any sequence\n",
      " |      of parameter settings.\n",
      " |  \n",
      " |  scoring : str, callable, list, tuple or dict, default=None\n",
      " |      Strategy to evaluate the performance of the cross-validated model on\n",
      " |      the test set.\n",
      " |  \n",
      " |      If `scoring` represents a single score, one can use:\n",
      " |  \n",
      " |      - a single string (see :ref:`scoring_parameter`);\n",
      " |      - a callable (see :ref:`scoring`) that returns a single value.\n",
      " |  \n",
      " |      If `scoring` represents multiple scores, one can use:\n",
      " |  \n",
      " |      - a list or tuple of unique strings;\n",
      " |      - a callable returning a dictionary where the keys are the metric\n",
      " |        names and the values are the metric scores;\n",
      " |      - a dictionary with metric names as keys and callables a values.\n",
      " |  \n",
      " |      See :ref:`multimetric_grid_search` for an example.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      Number of jobs to run in parallel.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |      .. versionchanged:: v0.20\n",
      " |         `n_jobs` default changed from 1 to None\n",
      " |  \n",
      " |  refit : bool, str, or callable, default=True\n",
      " |      Refit an estimator using the best found parameters on the whole\n",
      " |      dataset.\n",
      " |  \n",
      " |      For multiple metric evaluation, this needs to be a `str` denoting the\n",
      " |      scorer that would be used to find the best parameters for refitting\n",
      " |      the estimator at the end.\n",
      " |  \n",
      " |      Where there are considerations other than maximum score in\n",
      " |      choosing a best estimator, ``refit`` can be set to a function which\n",
      " |      returns the selected ``best_index_`` given ``cv_results_``. In that\n",
      " |      case, the ``best_estimator_`` and ``best_params_`` will be set\n",
      " |      according to the returned ``best_index_`` while the ``best_score_``\n",
      " |      attribute will not be available.\n",
      " |  \n",
      " |      The refitted estimator is made available at the ``best_estimator_``\n",
      " |      attribute and permits using ``predict`` directly on this\n",
      " |      ``GridSearchCV`` instance.\n",
      " |  \n",
      " |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      " |      ``best_score_`` and ``best_params_`` will only be available if\n",
      " |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
      " |      scorer.\n",
      " |  \n",
      " |      See ``scoring`` parameter to know more about multiple metric\n",
      " |      evaluation.\n",
      " |  \n",
      " |      See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`\n",
      " |      to see how to design a custom selection strategy using a callable\n",
      " |      via `refit`.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |          Support for callable added.\n",
      " |  \n",
      " |  cv : int, cross-validation generator or an iterable, default=None\n",
      " |      Determines the cross-validation splitting strategy.\n",
      " |      Possible inputs for cv are:\n",
      " |  \n",
      " |      - None, to use the default 5-fold cross validation,\n",
      " |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      " |      - :term:`CV splitter`,\n",
      " |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |  \n",
      " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      " |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      " |      other cases, :class:`KFold` is used. These splitters are instantiated\n",
      " |      with `shuffle=False` so the splits will be the same across calls.\n",
      " |  \n",
      " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      " |      cross-validation strategies that can be used here.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      " |  \n",
      " |  verbose : int\n",
      " |      Controls the verbosity: the higher, the more messages.\n",
      " |  \n",
      " |      - >1 : the computation time for each fold and parameter candidate is\n",
      " |        displayed;\n",
      " |      - >2 : the score is also displayed;\n",
      " |      - >3 : the fold and candidate parameter indexes are also displayed\n",
      " |        together with the starting time of the computation.\n",
      " |  \n",
      " |  pre_dispatch : int, or str, default='2*n_jobs'\n",
      " |      Controls the number of jobs that get dispatched during parallel\n",
      " |      execution. Reducing this number can be useful to avoid an\n",
      " |      explosion of memory consumption when more jobs get dispatched\n",
      " |      than CPUs can process. This parameter can be:\n",
      " |  \n",
      " |          - None, in which case all the jobs are immediately\n",
      " |            created and spawned. Use this for lightweight and\n",
      " |            fast-running jobs, to avoid delays due to on-demand\n",
      " |            spawning of the jobs\n",
      " |  \n",
      " |          - An int, giving the exact number of total jobs that are\n",
      " |            spawned\n",
      " |  \n",
      " |          - A str, giving an expression as a function of n_jobs,\n",
      " |            as in '2*n_jobs'\n",
      " |  \n",
      " |  error_score : 'raise' or numeric, default=np.nan\n",
      " |      Value to assign to the score if an error occurs in estimator fitting.\n",
      " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      " |      step, which will always raise the error.\n",
      " |  \n",
      " |  return_train_score : bool, default=False\n",
      " |      If ``False``, the ``cv_results_`` attribute will not include training\n",
      " |      scores.\n",
      " |      Computing training scores is used to get insights on how different\n",
      " |      parameter settings impact the overfitting/underfitting trade-off.\n",
      " |      However computing the scores on the training set can be computationally\n",
      " |      expensive and is not strictly required to select the parameters that\n",
      " |      yield the best generalization performance.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |      .. versionchanged:: 0.21\n",
      " |          Default value was changed from ``True`` to ``False``\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cv_results_ : dict of numpy (masked) ndarrays\n",
      " |      A dict with keys as column headers and values as columns, that can be\n",
      " |      imported into a pandas ``DataFrame``.\n",
      " |  \n",
      " |      For instance the below given table\n",
      " |  \n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
      " |      +============+===========+============+=================+===+=========+\n",
      " |      |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |  \n",
      " |      will be represented by a ``cv_results_`` dict of::\n",
      " |  \n",
      " |          {\n",
      " |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
      " |                                       mask = [False False False False]...)\n",
      " |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
      " |                                      mask = [ True  True False False]...),\n",
      " |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
      " |                                       mask = [False False  True  True]...),\n",
      " |          'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
      " |          'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
      " |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
      " |          'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
      " |          'rank_test_score'    : [2, 4, 3, 1],\n",
      " |          'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
      " |          'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
      " |          'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
      " |          'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
      " |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
      " |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
      " |          'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
      " |          'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
      " |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
      " |          }\n",
      " |  \n",
      " |      NOTE\n",
      " |  \n",
      " |      The key ``'params'`` is used to store a list of parameter\n",
      " |      settings dicts for all the parameter candidates.\n",
      " |  \n",
      " |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      " |      ``std_score_time`` are all in seconds.\n",
      " |  \n",
      " |      For multi-metric evaluation, the scores for all the scorers are\n",
      " |      available in the ``cv_results_`` dict at the keys ending with that\n",
      " |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      " |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      " |  \n",
      " |  best_estimator_ : estimator\n",
      " |      Estimator that was chosen by the search, i.e. estimator\n",
      " |      which gave highest score (or smallest loss if specified)\n",
      " |      on the left out data. Not available if ``refit=False``.\n",
      " |  \n",
      " |      See ``refit`` parameter for more information on allowed values.\n",
      " |  \n",
      " |  best_score_ : float\n",
      " |      Mean cross-validated score of the best_estimator\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |      This attribute is not available if ``refit`` is a function.\n",
      " |  \n",
      " |  best_params_ : dict\n",
      " |      Parameter setting that gave the best results on the hold out data.\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  best_index_ : int\n",
      " |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      " |      candidate parameter setting.\n",
      " |  \n",
      " |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      " |      the parameter setting for the best model, that gives the highest\n",
      " |      mean score (``search.best_score_``).\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  scorer_ : function or a dict\n",
      " |      Scorer function used on the held out data to choose the best\n",
      " |      parameters for the model.\n",
      " |  \n",
      " |      For multi-metric evaluation, this attribute holds the validated\n",
      " |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      " |  \n",
      " |  n_splits_ : int\n",
      " |      The number of cross-validation splits (folds/iterations).\n",
      " |  \n",
      " |  refit_time_ : float\n",
      " |      Seconds used for refitting the best model on the whole dataset.\n",
      " |  \n",
      " |      This is present only if ``refit`` is not False.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  multimetric_ : bool\n",
      " |      Whether or not the scorers compute several metrics.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The classes labels. This is present only if ``refit`` is specified and\n",
      " |      the underlying estimator is a classifier.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`. Only defined if\n",
      " |      `best_estimator_` is defined (see the documentation for the `refit`\n",
      " |      parameter for more details) and that `best_estimator_` exposes\n",
      " |      `n_features_in_` when fit.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Only defined if\n",
      " |      `best_estimator_` is defined (see the documentation for the `refit`\n",
      " |      parameter for more details) and that `best_estimator_` exposes\n",
      " |      `feature_names_in_` when fit.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  ParameterGrid : Generates all the combinations of a hyperparameter grid.\n",
      " |  train_test_split : Utility function to split the data into a development\n",
      " |      set usable for fitting a GridSearchCV instance and an evaluation set\n",
      " |      for its final evaluation.\n",
      " |  sklearn.metrics.make_scorer : Make a scorer from a performance metric or\n",
      " |      loss function.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The parameters selected are those that maximize the score of the left out\n",
      " |  data, unless an explicit score is passed in which case it is used instead.\n",
      " |  \n",
      " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      " |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
      " |  reasons if individual jobs take very little time, but may raise errors if\n",
      " |  the dataset is large and not enough memory is available.  A workaround in\n",
      " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      " |  n_jobs`.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn import svm, datasets\n",
      " |  >>> from sklearn.model_selection import GridSearchCV\n",
      " |  >>> iris = datasets.load_iris()\n",
      " |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      " |  >>> svc = svm.SVC()\n",
      " |  >>> clf = GridSearchCV(svc, parameters)\n",
      " |  >>> clf.fit(iris.data, iris.target)\n",
      " |  GridSearchCV(estimator=SVC(),\n",
      " |               param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
      " |  >>> sorted(clf.cv_results_.keys())\n",
      " |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
      " |   'param_C', 'param_kernel', 'params',...\n",
      " |   'rank_test_score', 'split0_test_score',...\n",
      " |   'split2_test_score', ...\n",
      " |   'std_fit_time', 'std_score_time', 'std_test_score']\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GridSearchCV\n",
      " |      BaseSearchCV\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseSearchCV:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Call decision_function on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``decision_function``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_score : ndarray of shape (n_samples,) or (n_samples, n_classes)                 or (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Result of the decision function for `X` based on the estimator with\n",
      " |          the best found parameters.\n",
      " |  \n",
      " |  fit(self, X, y=None, *, groups=None, **fit_params)\n",
      " |      Run fit with all sets of parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Training vector, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      groups : array-like of shape (n_samples,), default=None\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      " |          instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n",
      " |      \n",
      " |      **fit_params : dict of str -> object\n",
      " |          Parameters passed to the `fit` method of the estimator.\n",
      " |      \n",
      " |          If a fit parameter is an array-like whose length is equal to\n",
      " |          `num_samples` then it will be split across CV groups along with `X`\n",
      " |          and `y`. For example, the :term:`sample_weight` parameter is split\n",
      " |          because `len(sample_weights) = len(X)`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Instance of fitted estimator.\n",
      " |  \n",
      " |  inverse_transform(self, Xt)\n",
      " |      Call inverse_transform on the estimator with the best found params.\n",
      " |      \n",
      " |      Only available if the underlying estimator implements\n",
      " |      ``inverse_transform`` and ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      Xt : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Result of the `inverse_transform` function for `Xt` based on the\n",
      " |          estimator with the best found parameters.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Call predict on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,)\n",
      " |          The predicted labels or values for `X` based on the estimator with\n",
      " |          the best found parameters.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Call predict_log_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_log_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      " |          Predicted class log-probabilities for `X` based on the estimator\n",
      " |          with the best found parameters. The order of the classes\n",
      " |          corresponds to that in the fitted attribute :term:`classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Call predict_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      " |          Predicted class probabilities for `X` based on the estimator with\n",
      " |          the best found parameters. The order of the classes corresponds\n",
      " |          to that in the fitted attribute :term:`classes_`.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Return the score on the given data, if the estimator has been refit.\n",
      " |      \n",
      " |      This uses the score defined by ``scoring`` where provided, and the\n",
      " |      ``best_estimator_.score`` method otherwise.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          The score defined by ``scoring`` if provided, and the\n",
      " |          ``best_estimator_.score`` method otherwise.\n",
      " |  \n",
      " |  score_samples(self, X)\n",
      " |      Call score_samples on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``score_samples``.\n",
      " |      \n",
      " |      .. versionadded:: 0.24\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : iterable\n",
      " |          Data to predict on. Must fulfill input requirements\n",
      " |          of the underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_score : ndarray of shape (n_samples,)\n",
      " |          The ``best_estimator_.score_samples`` method.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Call transform on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if the underlying estimator supports ``transform`` and\n",
      " |      ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Xt : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      " |          `X` transformed in the new space based on the estimator with\n",
      " |          the best found parameters.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseSearchCV:\n",
      " |  \n",
      " |  classes_\n",
      " |      Class labels.\n",
      " |      \n",
      " |      Only available when `refit=True` and the estimator is a classifier.\n",
      " |  \n",
      " |  n_features_in_\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |      \n",
      " |      Only available when `refit=True`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BOMP(Bag_lst=[1, 50, 100], K_lst=[1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
       "     ignore_warning=True, random_seed=1, replace_flag=False,\n",
       "     signal_bag_percent=0.8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BOMP</label><div class=\"sk-toggleable__content\"><pre>BOMP(Bag_lst=[1, 50, 100], K_lst=[1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
       "     ignore_warning=True, random_seed=1, replace_flag=False,\n",
       "     signal_bag_percent=0.8)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BOMP(Bag_lst=[1, 50, 100], K_lst=[1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
       "     ignore_warning=True, random_seed=1, replace_flag=False,\n",
       "     signal_bag_percent=0.8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
