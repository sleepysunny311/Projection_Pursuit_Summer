{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from sklearn.base import BaseEstimator\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from data_generation import GaussianDataGenerator\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtomBaggingBase(BaseEstimator):\n",
    "    # Submodel base\n",
    "    def __init__(\n",
    "        self,\n",
    "        K,\n",
    "        atom_bag_percent=1,\n",
    "        select_atom_percent=0,\n",
    "        random_seed=0,\n",
    "        ignore_warning=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "\n",
    "        This class is used to perform atom bagging\n",
    "        Each object of this class is a submodel\n",
    "\n",
    "        K (int): Number of iterations\n",
    "        atom_bag_percent (float): Percentage of the original dictionary\n",
    "        select_atom_percent (float): Percentage of the selected atoms\n",
    "        random_seed (int): Random seed\n",
    "        \"\"\"\n",
    "\n",
    "        self.K = K\n",
    "        self.atom_bag_percent = np.max([0, np.min([1, atom_bag_percent])])\n",
    "        self.select_atom_percent = np.max([0, np.min([1, select_atom_percent])])\n",
    "        self.atom_bag_flag = atom_bag_percent < 1\n",
    "        self.atom_weak_select_flag = select_atom_percent > 0\n",
    "\n",
    "        self.indices = []\n",
    "        self.s = None\n",
    "        self.phi = None\n",
    "        self.a = None\n",
    "        self.coefficients = None\n",
    "        self.r = None\n",
    "\n",
    "        self.random_seed = random_seed\n",
    "        self.ignore_warning = ignore_warning\n",
    "\n",
    "    def fit(self, phi, s):\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        self.indices = []\n",
    "        self.s = None\n",
    "        self.phi = None\n",
    "        self.a = None\n",
    "        self.coefficients = None\n",
    "        self.r = None\n",
    "\n",
    "    def fit(self, phi, s):\n",
    "        return None\n",
    "\n",
    "    def predict(self, phi_test):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        phi_test (numpy.ndarray): Test data\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray: Predicted output\n",
    "        \"\"\"\n",
    "\n",
    "        return phi_test @ self.coefficients\n",
    "\n",
    "    def score(self, phi_test, s_test):\n",
    "        s_pred = phi_test @ self.final_c\n",
    "        pred_mse = np.mean((s_pred - s_test) ** 2)\n",
    "        return pred_mse\n",
    "\n",
    "    def input_coefficients(self, coefficients):\n",
    "        self.coefficients = coefficients\n",
    "\n",
    "    def update_seed(self, random_seed):\n",
    "        self.random_seed = random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OMP_Explore(AtomBaggingBase):\n",
    "    def __init__(\n",
    "        self, K_lst, select_atom_percent=0, random_seed=None, ignore_warning=False\n",
    "    ):\n",
    "        self.K_lst = K_lst\n",
    "        self.random_seed = random_seed\n",
    "        self.select_atom_percent = select_atom_percent\n",
    "        if select_atom_percent == 0:\n",
    "            self.atom_weak_select_flag = False\n",
    "\n",
    "        self.indices = []\n",
    "        self.coefficients = None\n",
    "        self.ignore_warning = ignore_warning\n",
    "\n",
    "        self.coefficients_list = []\n",
    "        self.error_list = []\n",
    "\n",
    "    def fit(self, phi, s):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        s (numpy.ndarray): Input signal\n",
    "        phi (numpy.ndarray): Dictionary\n",
    "        \"\"\"\n",
    "        self.reset()\n",
    "        self.s = s\n",
    "        self.phi = phi\n",
    "        self.a = np.zeros_like(self.s)\n",
    "        self.coefficients = np.zeros(phi.shape[1])\n",
    "        self.r = self.s.copy()\n",
    "        if self.random_seed is not None:\n",
    "            np.random.seed(self.random_seed)\n",
    "\n",
    "        for k in range(np.max(self.K_lst)+1):\n",
    "            inner_products = (phi.T @ self.r).flatten()\n",
    "            # so that we will not select the same atom\n",
    "            inner_products[self.indices] = 0\n",
    "            if self.atom_weak_select_flag:\n",
    "                top_ind = np.argsort(np.abs(inner_products))[::-1][\n",
    "                    : int(phi.shape[1] * self.select_atom_percent)\n",
    "                ]\n",
    "                # randomly select one atom\n",
    "                lambda_k = np.random.choice(top_ind)\n",
    "            else:\n",
    "                lambda_k = np.argmax(np.abs(inner_products))\n",
    "\n",
    "            # Ordinary least squares\n",
    "            X = phi[:, self.indices + [lambda_k]]\n",
    "\n",
    "            try:\n",
    "                betas = np.linalg.inv(X.T @ X) @ X.T @ self.s\n",
    "            except:\n",
    "                if not self.ignore_warning:\n",
    "                    print(\"Singular matrix encountered in OMP\")\n",
    "                break\n",
    "\n",
    "            # Update indices\n",
    "            self.indices.append(lambda_k)\n",
    "\n",
    "            # Update Coefficients\n",
    "            self.coefficients = np.zeros(phi.shape[1])\n",
    "            self.coefficients[self.indices] = betas.flatten()\n",
    "\n",
    "            # Update Projection\n",
    "            self.a = X @ betas\n",
    "\n",
    "            # Update Residual\n",
    "            self.r = self.s - self.a\n",
    "            if k in self.K_lst:\n",
    "                self.coefficients_list.append(self.coefficients.copy())\n",
    "                self.error_list.append(np.sum(self.r**2))\n",
    "\n",
    "\n",
    "        minimal_k_index = np.argmin(self.error_list)\n",
    "\n",
    "        # Update Coefficients\n",
    "\n",
    "        self.coefficients = self.coefficients_list[minimal_k_index]\n",
    "\n",
    "        # Update Projection\n",
    "        self.a = phi @ self.coefficients\n",
    "\n",
    "        # Update Residual\n",
    "        self.r = self.s - self.a\n",
    "\n",
    "        return self.a, self.coefficients\n",
    "\n",
    "    def multi_score(self, phi_test, s_test):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        phi_test (numpy.ndarray): Test data\n",
    "        s_test (numpy.ndarray): Test labels\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray: Predicted output\n",
    "        \"\"\"\n",
    "        test_score = []\n",
    "        for i in range(len(self.K_lst)):\n",
    "            self.coefficients = self.coefficients_list[i]\n",
    "            projection = phi_test @ self.coefficients\n",
    "            residual = s_test - projection\n",
    "            test_score.append(np.mean(residual**2))\n",
    "        return test_score\n",
    "\n",
    "    def reset(self):\n",
    "        super().reset()\n",
    "        self.coefficients_list = []\n",
    "        self.error_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_split(true_signal, dictionary, cv_num):\n",
    "    true_signal = true_signal.ravel()\n",
    "    cv_signal = np.split(true_signal, cv_num)\n",
    "    cv_dictionary = np.split(dictionary, cv_num)\n",
    "    # Get the list of train and test set\n",
    "    cv_res = []\n",
    "    for i in range(cv_num):\n",
    "        train_signal = np.concatenate(cv_signal[:i] + cv_signal[i + 1 :], axis=0)\n",
    "        train_dictionary = np.concatenate(\n",
    "            cv_dictionary[:i] + cv_dictionary[i + 1 :], axis=0\n",
    "        )\n",
    "        test_signal = cv_signal[i]\n",
    "        test_dictionary = cv_dictionary[i]\n",
    "        cv_res.append((train_signal, train_dictionary, test_signal, test_dictionary))\n",
    "    return cv_res\n",
    "\n",
    "\n",
    "def cal_cv_error(algorithm, cv_num, signal, dictionary):\n",
    "    cv_res = cv_split(signal, dictionary, cv_num)\n",
    "    error_lst = []\n",
    "    for i in range(cv_num):\n",
    "        train_signal, train_dictionary, test_signal, test_dictionary = cv_res[i]\n",
    "        algorithm.fit(train_dictionary,train_signal)\n",
    "        error_lst.append(algorithm.multi_score(test_dictionary,test_signal))\n",
    "    return np.mean(error_lst,axis = 0)\n",
    "\n",
    "\n",
    "def cv_best_K(signal, dictionary, cv_num, K_lst):\n",
    "    K_cv_error = []\n",
    "    OMP_tmp = OMP_Explore(K_lst, ignore_warning=True)\n",
    "    K_cv_error = cal_cv_error(OMP_tmp, cv_num, signal, dictionary)\n",
    "    lowest_error = np.min(K_cv_error)\n",
    "    lowest_error_K = K_lst[np.argmin(K_cv_error)]\n",
    "    return lowest_error, lowest_error_K, K_cv_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating K under noise level:  0.1\n",
      "Trial:  0  Best K:  12  Lowest Error:  0.011804923923324655\n",
      "Trial:  1  Best K:  14  Lowest Error:  0.009751582425454444\n",
      "Trial:  2  Best K:  17  Lowest Error:  0.01051267407359402\n",
      "Trial:  3  Best K:  17  Lowest Error:  0.011083424058424541\n",
      "Trial:  4  Best K:  16  Lowest Error:  0.01062542302441949\n",
      "Trial:  5  Best K:  11  Lowest Error:  0.010547946303916568\n",
      "Trial:  6  Best K:  13  Lowest Error:  0.011492231874623084\n",
      "Trial:  7  Best K:  17  Lowest Error:  0.012630563987436455\n",
      "Trial:  8  Best K:  13  Lowest Error:  0.010954758886104447\n",
      "Trial:  9  Best K:  15  Lowest Error:  0.01034220334737489\n",
      "Average best K for noise level:  0.1  is:  14.5  with MSE:  0.010974573190467258\n",
      "Cross validating K under noise level:  0.3\n",
      "Trial:  0  Best K:  8  Lowest Error:  0.10426860801834041\n",
      "Trial:  1  Best K:  2  Lowest Error:  0.09556435060037786\n",
      "Trial:  2  Best K:  9  Lowest Error:  0.10275167040559799\n",
      "Trial:  3  Best K:  2  Lowest Error:  0.10707146772214685\n",
      "Trial:  4  Best K:  8  Lowest Error:  0.10505393877465394\n",
      "Trial:  5  Best K:  6  Lowest Error:  0.09090143627738945\n",
      "Trial:  6  Best K:  1  Lowest Error:  0.10617414297524848\n",
      "Trial:  7  Best K:  6  Lowest Error:  0.11787557449034973\n",
      "Trial:  8  Best K:  5  Lowest Error:  0.10538574870105788\n",
      "Trial:  9  Best K:  8  Lowest Error:  0.10498234710529764\n",
      "Average best K for noise level:  0.3  is:  5.5  with MSE:  0.10400292850704602\n",
      "Cross validating K under noise level:  0.5\n",
      "Trial:  0  Best K:  2  Lowest Error:  0.2960846008456509\n",
      "Trial:  1  Best K:  4  Lowest Error:  0.255307987115838\n",
      "Trial:  2  Best K:  2  Lowest Error:  0.2874253428349661\n",
      "Trial:  3  Best K:  2  Lowest Error:  0.2783849059656115\n",
      "Trial:  4  Best K:  2  Lowest Error:  0.27612429841755204\n",
      "Trial:  5  Best K:  2  Lowest Error:  0.2529568671615382\n",
      "Trial:  6  Best K:  1  Lowest Error:  0.28550085388998714\n",
      "Trial:  7  Best K:  2  Lowest Error:  0.3202424507187342\n",
      "Trial:  8  Best K:  2  Lowest Error:  0.28485011212407596\n",
      "Trial:  9  Best K:  1  Lowest Error:  0.2939237633206146\n",
      "Average best K for noise level:  0.5  is:  2.0  with MSE:  0.28308011823945683\n",
      "Finished!\n",
      "Log file saved to:  ./memory/OMPtest_002_01.pkl.pkl\n"
     ]
    }
   ],
   "source": [
    "output_path = \"./memory/\"  # your specified path here\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "\n",
    "def cv_best_K_noise_level_multi_trial(\n",
    "    N, d, m, noise_level_lst, cv_num, K_lst, trial_num, output_filename=None\n",
    "):\n",
    "    if output_filename is None:\n",
    "        output_filename = (\n",
    "            \"OMP\"\n",
    "            + str(N)\n",
    "            + \"_\"\n",
    "            + str(d)\n",
    "            + \"_\"\n",
    "            + str(m)\n",
    "            + \"_\"\n",
    "            + str(trial_num)\n",
    "            + \"_\"\n",
    "            + str(cv_num)\n",
    "            + \".pkl\"\n",
    "        )\n",
    "    else:\n",
    "        output_filename = \"OMP\" + output_filename + \".pkl\"\n",
    "    res_log = {\n",
    "        \"parameters\": {\n",
    "            \"N\": N,\n",
    "            \"d\": d,\n",
    "            \"m\": m,\n",
    "            \"noise_level_lst\": noise_level_lst,\n",
    "            \"cv_num\": cv_num,\n",
    "            \"trial_num\": trial_num,\n",
    "            \"K_lst\": K_lst,\n",
    "        },\n",
    "        \"noise_level_best_K\": [],\n",
    "        \"noise_level_lowest_MSE\": [],\n",
    "        \"log\": [],\n",
    "    }\n",
    "    noise_level_best_K = []\n",
    "    noise_level_lowest_MSE = []\n",
    "    for noise_level in noise_level_lst:\n",
    "        print(\"Cross validating K under noise level: \", noise_level)\n",
    "        trials_best_K_tmp = []\n",
    "        MSE_loweset_K_temp = []\n",
    "        for trial in range(trial_num):\n",
    "            Data_Geneartor = GaussianDataGenerator(N, d, m, noise_level, trial)\n",
    "            (\n",
    "                true_signal,\n",
    "                dictionary,\n",
    "                true_indices,\n",
    "                true_coefficients,\n",
    "                perturbed_signal,\n",
    "            ) = Data_Geneartor.shuffle()\n",
    "            lowest_error, lowest_error_K, cv_err_lst = cv_best_K(\n",
    "                perturbed_signal, dictionary, cv_num, K_lst\n",
    "            )\n",
    "            trials_best_K_tmp.append(lowest_error_K)\n",
    "            MSE_loweset_K_temp.append(lowest_error)\n",
    "            print(\n",
    "                \"Trial: \",\n",
    "                trial,\n",
    "                \" Best K: \",\n",
    "                lowest_error_K,\n",
    "                \" Lowest Error: \",\n",
    "                lowest_error,\n",
    "            )\n",
    "            log_tmp = {\n",
    "                \"noise_level\": noise_level,\n",
    "                \"trial\": trial,\n",
    "                \"data\": Data_Geneartor,\n",
    "                \"cv_error_lst\": cv_err_lst,\n",
    "                \"lowest_error\": lowest_error,\n",
    "                \"lowest_error_K\": lowest_error_K,\n",
    "            }\n",
    "            res_log[\"log\"].append(log_tmp)\n",
    "        noise_level_best_K.append(np.mean(trials_best_K_tmp))\n",
    "        noise_level_lowest_MSE.append(np.mean(MSE_loweset_K_temp))\n",
    "        print(\n",
    "            \"Average best K for noise level: \",\n",
    "            noise_level,\n",
    "            \" is: \",\n",
    "            np.mean(trials_best_K_tmp),\n",
    "            \" with MSE: \",\n",
    "            np.mean(MSE_loweset_K_temp),\n",
    "        )\n",
    "    res_log[\"noise_level_best_K\"] = noise_level_best_K\n",
    "    res_log[\"noise_level_lowest_MSE\"] = noise_level_lowest_MSE\n",
    "    with open(os.path.join(output_path, output_filename), \"wb\") as f:\n",
    "        pkl.dump(res_log, f)\n",
    "    print(\"Finished!\")\n",
    "    print(\"Log file saved to: \", os.path.join(output_path, output_filename))\n",
    "    return noise_level_best_K, noise_level_lowest_MSE, res_log\n",
    "\n",
    "\n",
    "noise_level_lst = [0.1, 0.3, 0.5]\n",
    "N = 1000\n",
    "d = 600\n",
    "m = 20\n",
    "trial_num = 10\n",
    "cv_num = 5\n",
    "K_lst = list(range(1, 21, 1))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    (\n",
    "        noise_level_best_K,\n",
    "        noise_level_lowest_MSE,\n",
    "        res_log,\n",
    "    ) = cv_best_K_noise_level_multi_trial(\n",
    "        N,\n",
    "        d,\n",
    "        m,\n",
    "        noise_level_lst,\n",
    "        cv_num,\n",
    "        K_lst,\n",
    "        trial_num,\n",
    "        output_filename=\"test_002_01.pkl\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
